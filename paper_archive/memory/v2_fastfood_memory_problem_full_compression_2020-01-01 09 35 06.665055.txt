Namespace(batch_size=50, cell='FastFoodGRU', compression_mode='full', hidden=512, lr=0.001, n_test=10000, n_train=600000, problem='memory', time_steps=150)
Baseline is 0.12232009068704916
torch.Size([512])
torch.Size([512])
torch.Size([512])
torch.Size([512, 10])
torch.Size([512])
torch.Size([512])
torch.Size([512])
torch.Size([512])
torch.Size([512, 10])
torch.Size([512])
torch.Size([512])
torch.Size([512])
torch.Size([512])
torch.Size([512, 10])
torch.Size([512])
torch.Size([10, 512])
torch.Size([10])
parameter total 26634
step 0 loss 2.171371 baseline: 0.12232009068704916 acc 0.112 wl 0 train True
step 50 loss 0.3484383 baseline: 0.12232009068704916 acc 0.0 wl 0 train True
step 100 loss 0.32197207 baseline: 0.12232009068704916 acc 0.0 wl 0 train True
step 150 loss 0.33927009 baseline: 0.12232009068704916 acc 0.0 wl 0 train True
step 200 loss 0.31824845 baseline: 0.12232009068704916 acc 0.0 wl 0 train True
step 250 loss 0.32534194 baseline: 0.12232009068704916 acc 0.0 wl 0 train True
step 300 loss 0.30776978 baseline: 0.12232009068704916 acc 0.0 wl 0 train True
step 350 loss 0.293876 baseline: 0.12232009068704916 acc 0.0 wl 0 train True
step 400 loss 0.3076917 baseline: 0.12232009068704916 acc 0.0 wl 0 train True
step 450 loss 0.24896637 baseline: 0.12232009068704916 acc 0.0 wl 0 train True
step 500 loss 0.2694037 baseline: 0.12232009068704916 acc 0.0 wl 0 train True
step 550 loss 0.24877709 baseline: 0.12232009068704916 acc 0.0 wl 0 train True
step 600 loss 0.20620771 baseline: 0.12232009068704916 acc 0.018 wl 0 train True
step 650 loss 0.21336676 baseline: 0.12232009068704916 acc 0.012 wl 0 train True
step 700 loss 0.16527592 baseline: 0.12232009068704916 acc 0.028 wl 0 train True
step 750 loss 0.1763379 baseline: 0.12232009068704916 acc 0.042 wl 0 train True
step 800 loss 0.14646412 baseline: 0.12232009068704916 acc 0.062 wl 0 train True
step 850 loss 0.13908723 baseline: 0.12232009068704916 acc 0.104 wl 0 train True
step 900 loss 0.14227934 baseline: 0.12232009068704916 acc 0.078 wl 0 train True
step 950 loss 0.14288694 baseline: 0.12232009068704916 acc 0.088 wl 0 train True
step 1000 loss 0.12625006 baseline: 0.12232009068704916 acc 0.126 wl 0 train True
step 1050 loss 0.12755862 baseline: 0.12232009068704916 acc 0.096 wl 0 train True
step 1100 loss 0.123678826 baseline: 0.12232009068704916 acc 0.112 wl 0 train True
step 1150 loss 0.12395565 baseline: 0.12232009068704916 acc 0.164 wl 0 train True
step 1200 loss 0.12363629 baseline: 0.12232009068704916 acc 0.108 wl 0 train True
step 1250 loss 0.12302894 baseline: 0.12232009068704916 acc 0.128 wl 0 train True
step 1300 loss 0.12392168 baseline: 0.12232009068704916 acc 0.11 wl 0 train True
step 1350 loss 0.123019576 baseline: 0.12232009068704916 acc 0.116 wl 0 train True
step 1400 loss 0.12336888 baseline: 0.12232009068704916 acc 0.132 wl 0 train True
step 1450 loss 0.12283137 baseline: 0.12232009068704916 acc 0.122 wl 0 train True
step 1500 loss 0.12295798 baseline: 0.12232009068704916 acc 0.118 wl 0 train True
step 1550 loss 0.12254923 baseline: 0.12232009068704916 acc 0.15 wl 0 train True
step 1600 loss 0.12362701 baseline: 0.12232009068704916 acc 0.132 wl 0 train True
step 1650 loss 0.1226597 baseline: 0.12232009068704916 acc 0.12 wl 0 train True
step 1700 loss 0.12357885 baseline: 0.12232009068704916 acc 0.08 wl 0 train True
step 1750 loss 0.122690074 baseline: 0.12232009068704916 acc 0.128 wl 0 train True
step 1800 loss 0.122479424 baseline: 0.12232009068704916 acc 0.126 wl 0 train True
step 1850 loss 0.123050496 baseline: 0.12232009068704916 acc 0.098 wl 0 train True
step 1900 loss 0.12240782 baseline: 0.12232009068704916 acc 0.112 wl 0 train True
step 1950 loss 0.122439384 baseline: 0.12232009068704916 acc 0.146 wl 0 train True
step 2000 loss 0.1229646 baseline: 0.12232009068704916 acc 0.124 wl 0 train True
step 2050 loss 0.12299937 baseline: 0.12232009068704916 acc 0.102 wl 0 train True
step 2100 loss 0.12245551 baseline: 0.12232009068704916 acc 0.112 wl 0 train True
step 2150 loss 0.12241082 baseline: 0.12232009068704916 acc 0.12 wl 0 train True
step 2200 loss 0.12265513 baseline: 0.12232009068704916 acc 0.13 wl 0 train True
step 2250 loss 0.12253927 baseline: 0.12232009068704916 acc 0.102 wl 0 train True
step 2300 loss 0.12255754 baseline: 0.12232009068704916 acc 0.106 wl 0 train True
step 2350 loss 0.122246094 baseline: 0.12232009068704916 acc 0.106 wl 0 train True
step 2400 loss 0.12208779 baseline: 0.12232009068704916 acc 0.152 wl 0 train True
step 2450 loss 0.12259391 baseline: 0.12232009068704916 acc 0.112 wl 0 train True
step 2500 loss 0.12227717 baseline: 0.12232009068704916 acc 0.126 wl 0 train True
step 2550 loss 0.1224041 baseline: 0.12232009068704916 acc 0.122 wl 0 train True
step 2600 loss 0.12257323 baseline: 0.12232009068704916 acc 0.102 wl 0 train True
step 2650 loss 0.12246015 baseline: 0.12232009068704916 acc 0.116 wl 0 train True
step 2700 loss 0.122379035 baseline: 0.12232009068704916 acc 0.112 wl 0 train True
step 2750 loss 0.1223461 baseline: 0.12232009068704916 acc 0.126 wl 0 train True
step 2800 loss 0.122430936 baseline: 0.12232009068704916 acc 0.13 wl 0 train True
step 2850 loss 0.12253373 baseline: 0.12232009068704916 acc 0.128 wl 0 train True
step 2900 loss 0.12264858 baseline: 0.12232009068704916 acc 0.11 wl 0 train True
step 2950 loss 0.122242905 baseline: 0.12232009068704916 acc 0.154 wl 0 train True
step 3000 loss 0.12233002 baseline: 0.12232009068704916 acc 0.148 wl 0 train True
step 3050 loss 0.122229666 baseline: 0.12232009068704916 acc 0.126 wl 0 train True
step 3100 loss 0.12198858 baseline: 0.12232009068704916 acc 0.154 wl 0 train True
step 3150 loss 0.12262398 baseline: 0.12232009068704916 acc 0.102 wl 0 train True
step 3200 loss 0.1223935 baseline: 0.12232009068704916 acc 0.124 wl 0 train True
step 3250 loss 0.1221431 baseline: 0.12232009068704916 acc 0.146 wl 0 train True
step 3300 loss 0.12232596 baseline: 0.12232009068704916 acc 0.128 wl 0 train True
step 3350 loss 0.12243691 baseline: 0.12232009068704916 acc 0.112 wl 0 train True
step 3400 loss 0.122775905 baseline: 0.12232009068704916 acc 0.126 wl 0 train True
step 3450 loss 0.12248858 baseline: 0.12232009068704916 acc 0.112 wl 0 train True
step 3500 loss 0.12224704 baseline: 0.12232009068704916 acc 0.152 wl 0 train True
step 3550 loss 0.12251729 baseline: 0.12232009068704916 acc 0.116 wl 0 train True
step 3600 loss 0.12217399 baseline: 0.12232009068704916 acc 0.146 wl 0 train True
step 3650 loss 0.122391835 baseline: 0.12232009068704916 acc 0.114 wl 0 train True
step 3700 loss 0.122592226 baseline: 0.12232009068704916 acc 0.124 wl 0 train True
step 3750 loss 0.12243293 baseline: 0.12232009068704916 acc 0.122 wl 0 train True
step 3800 loss 0.122521974 baseline: 0.12232009068704916 acc 0.112 wl 0 train True
step 3850 loss 0.12256483 baseline: 0.12232009068704916 acc 0.12 wl 0 train True
step 3900 loss 0.12223044 baseline: 0.12232009068704916 acc 0.136 wl 0 train True
step 3950 loss 0.12230309 baseline: 0.12232009068704916 acc 0.13 wl 0 train True
step 4000 loss 0.12250261 baseline: 0.12232009068704916 acc 0.108 wl 0 train True
step 4050 loss 0.12238072 baseline: 0.12232009068704916 acc 0.112 wl 0 train True
step 4100 loss 0.12242446 baseline: 0.12232009068704916 acc 0.14 wl 0 train True
step 4150 loss 0.12222563 baseline: 0.12232009068704916 acc 0.122 wl 0 train True
step 4200 loss 0.1228823 baseline: 0.12232009068704916 acc 0.116 wl 0 train True
step 4250 loss 0.12267085 baseline: 0.12232009068704916 acc 0.126 wl 0 train True
step 4300 loss 0.12224325 baseline: 0.12232009068704916 acc 0.118 wl 0 train True
step 4350 loss 0.1224113 baseline: 0.12232009068704916 acc 0.122 wl 0 train True
step 4400 loss 0.12265042 baseline: 0.12232009068704916 acc 0.12 wl 0 train True
step 4450 loss 0.122394174 baseline: 0.12232009068704916 acc 0.108 wl 0 train True
step 4500 loss 0.12241327 baseline: 0.12232009068704916 acc 0.118 wl 0 train True
step 4550 loss 0.12259487 baseline: 0.12232009068704916 acc 0.126 wl 0 train True
step 4600 loss 0.12239303 baseline: 0.12232009068704916 acc 0.104 wl 0 train True
step 4650 loss 0.12292255 baseline: 0.12232009068704916 acc 0.086 wl 0 train True
step 4700 loss 0.12235779 baseline: 0.12232009068704916 acc 0.128 wl 0 train True
step 4750 loss 0.122327894 baseline: 0.12232009068704916 acc 0.138 wl 0 train True
step 4800 loss 0.12241324 baseline: 0.12232009068704916 acc 0.132 wl 0 train True
step 4850 loss 0.12247068 baseline: 0.12232009068704916 acc 0.122 wl 0 train True
step 4900 loss 0.1222626 baseline: 0.12232009068704916 acc 0.152 wl 0 train True
step 4950 loss 0.12243368 baseline: 0.12232009068704916 acc 0.136 wl 0 train True
step 5000 loss 0.12275474 baseline: 0.12232009068704916 acc 0.092 wl 0 train True
step 5050 loss 0.1225332 baseline: 0.12232009068704916 acc 0.104 wl 0 train True
step 5100 loss 0.1222848 baseline: 0.12232009068704916 acc 0.118 wl 0 train True
step 5150 loss 0.12264668 baseline: 0.12232009068704916 acc 0.108 wl 0 train True
step 5200 loss 0.122467816 baseline: 0.12232009068704916 acc 0.116 wl 0 train True
step 5250 loss 0.12242535 baseline: 0.12232009068704916 acc 0.144 wl 0 train True
step 5300 loss 0.12245739 baseline: 0.12232009068704916 acc 0.106 wl 0 train True
step 5350 loss 0.12237496 baseline: 0.12232009068704916 acc 0.118 wl 0 train True
step 5400 loss 0.12258987 baseline: 0.12232009068704916 acc 0.11 wl 0 train True
step 5450 loss 0.122292794 baseline: 0.12232009068704916 acc 0.126 wl 0 train True
step 5500 loss 0.12263677 baseline: 0.12232009068704916 acc 0.118 wl 0 train True
step 5550 loss 0.122318916 baseline: 0.12232009068704916 acc 0.142 wl 0 train True
step 5600 loss 0.122356504 baseline: 0.12232009068704916 acc 0.136 wl 0 train True
step 5650 loss 0.12228638 baseline: 0.12232009068704916 acc 0.114 wl 0 train True
step 5700 loss 0.12221908 baseline: 0.12232009068704916 acc 0.14 wl 0 train True
step 5750 loss 0.12247805 baseline: 0.12232009068704916 acc 0.126 wl 0 train True
step 5800 loss 0.122528896 baseline: 0.12232009068704916 acc 0.134 wl 0 train True
step 5850 loss 0.12234474 baseline: 0.12232009068704916 acc 0.132 wl 0 train True
step 5900 loss 0.12235524 baseline: 0.12232009068704916 acc 0.112 wl 0 train True
step 5950 loss 0.12242019 baseline: 0.12232009068704916 acc 0.124 wl 0 train True
step 6000 loss 0.12239704 baseline: 0.12232009068704916 acc 0.126 wl 0 train True
step 6050 loss 0.12246585 baseline: 0.12232009068704916 acc 0.108 wl 0 train True
step 6100 loss 0.12252434 baseline: 0.12232009068704916 acc 0.11 wl 0 train True
step 6150 loss 0.12239397 baseline: 0.12232009068704916 acc 0.126 wl 0 train True
step 6200 loss 0.122098446 baseline: 0.12232009068704916 acc 0.138 wl 0 train True
step 6250 loss 0.122299016 baseline: 0.12232009068704916 acc 0.142 wl 0 train True
step 6300 loss 0.12241304 baseline: 0.12232009068704916 acc 0.106 wl 0 train True
step 6350 loss 0.12235646 baseline: 0.12232009068704916 acc 0.14 wl 0 train True
step 6400 loss 0.122402675 baseline: 0.12232009068704916 acc 0.124 wl 0 train True
step 6450 loss 0.12231374 baseline: 0.12232009068704916 acc 0.14 wl 0 train True
step 6500 loss 0.12227591 baseline: 0.12232009068704916 acc 0.14 wl 0 train True
step 6550 loss 0.12226748 baseline: 0.12232009068704916 acc 0.144 wl 0 train True
step 6600 loss 0.122306384 baseline: 0.12232009068704916 acc 0.138 wl 0 train True
step 6650 loss 0.1224931 baseline: 0.12232009068704916 acc 0.112 wl 0 train True
step 6700 loss 0.12237145 baseline: 0.12232009068704916 acc 0.128 wl 0 train True
step 6750 loss 0.122380555 baseline: 0.12232009068704916 acc 0.1 wl 0 train True
step 6800 loss 0.12239475 baseline: 0.12232009068704916 acc 0.132 wl 0 train True
step 6850 loss 0.122542135 baseline: 0.12232009068704916 acc 0.112 wl 0 train True
step 6900 loss 0.12235636 baseline: 0.12232009068704916 acc 0.134 wl 0 train True
step 6950 loss 0.12228949 baseline: 0.12232009068704916 acc 0.142 wl 0 train True
step 7000 loss 0.122441895 baseline: 0.12232009068704916 acc 0.13 wl 0 train True
step 7050 loss 0.12242211 baseline: 0.12232009068704916 acc 0.104 wl 0 train True
step 7100 loss 0.12217407 baseline: 0.12232009068704916 acc 0.16 wl 0 train True
step 7150 loss 0.12253704 baseline: 0.12232009068704916 acc 0.11 wl 0 train True
step 7200 loss 0.12233452 baseline: 0.12232009068704916 acc 0.14 wl 0 train True
step 7250 loss 0.12236304 baseline: 0.12232009068704916 acc 0.126 wl 0 train True
step 7300 loss 0.122259036 baseline: 0.12232009068704916 acc 0.12 wl 0 train True
step 7350 loss 0.12207616 baseline: 0.12232009068704916 acc 0.164 wl 0 train True
step 7400 loss 0.122529164 baseline: 0.12232009068704916 acc 0.12 wl 0 train True
step 7450 loss 0.12238004 baseline: 0.12232009068704916 acc 0.11 wl 0 train True
step 7500 loss 0.122386485 baseline: 0.12232009068704916 acc 0.12 wl 0 train True
step 7550 loss 0.122472875 baseline: 0.12232009068704916 acc 0.118 wl 0 train True
step 7600 loss 0.12228948 baseline: 0.12232009068704916 acc 0.138 wl 0 train True
step 7650 loss 0.122445226 baseline: 0.12232009068704916 acc 0.102 wl 0 train True
step 7700 loss 0.12243267 baseline: 0.12232009068704916 acc 0.12 wl 0 train True
step 7750 loss 0.12214129 baseline: 0.12232009068704916 acc 0.136 wl 0 train True
step 7800 loss 0.12246794 baseline: 0.12232009068704916 acc 0.114 wl 0 train True
step 7850 loss 0.122491725 baseline: 0.12232009068704916 acc 0.13 wl 0 train True
step 7900 loss 0.12222761 baseline: 0.12232009068704916 acc 0.152 wl 0 train True
step 7950 loss 0.122283764 baseline: 0.12232009068704916 acc 0.116 wl 0 train True
step 8000 loss 0.12251686 baseline: 0.12232009068704916 acc 0.108 wl 0 train True
step 8050 loss 0.12231453 baseline: 0.12232009068704916 acc 0.11 wl 0 train True
step 8100 loss 0.12245049 baseline: 0.12232009068704916 acc 0.132 wl 0 train True
step 8150 loss 0.122498475 baseline: 0.12232009068704916 acc 0.12 wl 0 train True
step 8200 loss 0.122314885 baseline: 0.12232009068704916 acc 0.12 wl 0 train True
step 8250 loss 0.12237468 baseline: 0.12232009068704916 acc 0.13 wl 0 train True
step 8300 loss 0.12241706 baseline: 0.12232009068704916 acc 0.128 wl 0 train True
step 8350 loss 0.12233972 baseline: 0.12232009068704916 acc 0.132 wl 0 train True
step 8400 loss 0.12239792 baseline: 0.12232009068704916 acc 0.126 wl 0 train True
step 8450 loss 0.12239229 baseline: 0.12232009068704916 acc 0.118 wl 0 train True
step 8500 loss 0.12231356 baseline: 0.12232009068704916 acc 0.13 wl 0 train True
step 8550 loss 0.1222692 baseline: 0.12232009068704916 acc 0.142 wl 0 train True
step 8600 loss 0.12248729 baseline: 0.12232009068704916 acc 0.104 wl 0 train True
step 8650 loss 0.1222155 baseline: 0.12232009068704916 acc 0.15 wl 0 train True
step 8700 loss 0.12237553 baseline: 0.12232009068704916 acc 0.118 wl 0 train True
step 8750 loss 0.12233574 baseline: 0.12232009068704916 acc 0.126 wl 0 train True
step 8800 loss 0.12231162 baseline: 0.12232009068704916 acc 0.134 wl 0 train True
step 8850 loss 0.122248374 baseline: 0.12232009068704916 acc 0.126 wl 0 train True
step 8900 loss 0.122246094 baseline: 0.12232009068704916 acc 0.128 wl 0 train True
step 8950 loss 0.122359134 baseline: 0.12232009068704916 acc 0.12 wl 0 train True
step 9000 loss 0.12246357 baseline: 0.12232009068704916 acc 0.12 wl 0 train True
step 9050 loss 0.12224648 baseline: 0.12232009068704916 acc 0.114 wl 0 train True
step 9100 loss 0.122461006 baseline: 0.12232009068704916 acc 0.122 wl 0 train True
step 9150 loss 0.122332275 baseline: 0.12232009068704916 acc 0.152 wl 0 train True
step 9200 loss 0.12236025 baseline: 0.12232009068704916 acc 0.11 wl 0 train True
step 9250 loss 0.12226929 baseline: 0.12232009068704916 acc 0.15 wl 0 train True
step 9300 loss 0.12230857 baseline: 0.12232009068704916 acc 0.136 wl 0 train True
step 9350 loss 0.12246545 baseline: 0.12232009068704916 acc 0.106 wl 0 train True
step 9400 loss 0.12240356 baseline: 0.12232009068704916 acc 0.11 wl 0 train True
step 9450 loss 0.12233937 baseline: 0.12232009068704916 acc 0.132 wl 0 train True
step 9500 loss 0.12236123 baseline: 0.12232009068704916 acc 0.134 wl 0 train True
step 9550 loss 0.122395046 baseline: 0.12232009068704916 acc 0.098 wl 0 train True
step 9600 loss 0.12245419 baseline: 0.12232009068704916 acc 0.12 wl 0 train True
step 9650 loss 0.122293904 baseline: 0.12232009068704916 acc 0.142 wl 0 train True
step 9700 loss 0.12225422 baseline: 0.12232009068704916 acc 0.15 wl 0 train True
step 9750 loss 0.12229137 baseline: 0.12232009068704916 acc 0.146 wl 0 train True
step 9800 loss 0.122301325 baseline: 0.12232009068704916 acc 0.126 wl 0 train True
step 9850 loss 0.12232768 baseline: 0.12232009068704916 acc 0.14 wl 0 train True
step 9900 loss 0.12239113 baseline: 0.12232009068704916 acc 0.102 wl 0 train True
step 9950 loss 0.12242357 baseline: 0.12232009068704916 acc 0.124 wl 0 train True
step 10000 loss 0.122581 baseline: 0.12232009068704916 acc 0.116 wl 0 train True
step 10050 loss 0.12238606 baseline: 0.12232009068704916 acc 0.112 wl 0 train True
step 10100 loss 0.12224147 baseline: 0.12232009068704916 acc 0.122 wl 0 train True
step 10150 loss 0.12235518 baseline: 0.12232009068704916 acc 0.104 wl 0 train True
step 10200 loss 0.12226666 baseline: 0.12232009068704916 acc 0.142 wl 0 train True
step 10250 loss 0.12234553 baseline: 0.12232009068704916 acc 0.134 wl 0 train True
step 10300 loss 0.12242228 baseline: 0.12232009068704916 acc 0.12 wl 0 train True
step 10350 loss 0.12222513 baseline: 0.12232009068704916 acc 0.136 wl 0 train True
step 10400 loss 0.122224994 baseline: 0.12232009068704916 acc 0.114 wl 0 train True
step 10450 loss 0.122324035 baseline: 0.12232009068704916 acc 0.138 wl 0 train True
step 10500 loss 0.12240658 baseline: 0.12232009068704916 acc 0.124 wl 0 train True
step 10550 loss 0.122449316 baseline: 0.12232009068704916 acc 0.122 wl 0 train True
step 10600 loss 0.12235237 baseline: 0.12232009068704916 acc 0.116 wl 0 train True
step 10650 loss 0.12236756 baseline: 0.12232009068704916 acc 0.112 wl 0 train True
step 10700 loss 0.122517034 baseline: 0.12232009068704916 acc 0.102 wl 0 train True
step 10750 loss 0.12240632 baseline: 0.12232009068704916 acc 0.13 wl 0 train True
step 10800 loss 0.12230403 baseline: 0.12232009068704916 acc 0.118 wl 0 train True
step 10850 loss 0.12240694 baseline: 0.12232009068704916 acc 0.118 wl 0 train True
step 10900 loss 0.12226969 baseline: 0.12232009068704916 acc 0.132 wl 0 train True
step 10950 loss 0.12238264 baseline: 0.12232009068704916 acc 0.114 wl 0 train True
step 11000 loss 0.12232287 baseline: 0.12232009068704916 acc 0.132 wl 0 train True
step 11050 loss 0.12235883 baseline: 0.12232009068704916 acc 0.11 wl 0 train True
step 11100 loss 0.122329146 baseline: 0.12232009068704916 acc 0.136 wl 0 train True
step 11150 loss 0.1223088 baseline: 0.12232009068704916 acc 0.136 wl 0 train True
step 11200 loss 0.12228638 baseline: 0.12232009068704916 acc 0.13 wl 0 train True
step 11250 loss 0.122198805 baseline: 0.12232009068704916 acc 0.148 wl 0 train True
step 11300 loss 0.12229353 baseline: 0.12232009068704916 acc 0.132 wl 0 train True
step 11350 loss 0.12240173 baseline: 0.12232009068704916 acc 0.118 wl 0 train True
step 11400 loss 0.1224078 baseline: 0.12232009068704916 acc 0.118 wl 0 train True
step 11450 loss 0.122415215 baseline: 0.12232009068704916 acc 0.108 wl 0 train True
step 11500 loss 0.122483194 baseline: 0.12232009068704916 acc 0.11 wl 0 train True
step 11550 loss 0.12258265 baseline: 0.12232009068704916 acc 0.124 wl 0 train True
step 11600 loss 0.12236617 baseline: 0.12232009068704916 acc 0.13 wl 0 train True
step 11650 loss 0.122301385 baseline: 0.12232009068704916 acc 0.134 wl 0 train True
step 11700 loss 0.12214417 baseline: 0.12232009068704916 acc 0.174 wl 0 train True
step 11750 loss 0.12221598 baseline: 0.12232009068704916 acc 0.096 wl 0 train True
step 11800 loss 0.12108347 baseline: 0.12232009068704916 acc 0.158 wl 0 train True
step 11850 loss 0.12134013 baseline: 0.12232009068704916 acc 0.16 wl 0 train True
step 11900 loss 0.12078086 baseline: 0.12232009068704916 acc 0.2 wl 0 train True
step 11950 loss 0.12075561 baseline: 0.12232009068704916 acc 0.154 wl 0 train True
training done... testing ...
step 0 loss 0.119945586 baseline: 0.12232009068704916 acc 0.18 wl 0 train False
step 50 loss 0.120603085 baseline: 0.12232009068704916 acc 0.17 wl 0 train False
step 100 loss 0.12068741 baseline: 0.12232009068704916 acc 0.144 wl 0 train False
step 150 loss 0.11919589 baseline: 0.12232009068704916 acc 0.176 wl 0 train False
test_el_total 100000.0 test_acc_sum 16440.0
test loss mean 0.120388165 test acc mean 0.1644 pt 26634
time: 2020-01-01 11:49:21.169444 experiment took 8053.683222293854 [s]

Namespace(batch_size=50, cell='GRU', compression_mode='state', hidden=512, lr=0.001, n_test=10000, n_train=600000, problem='memory', time_steps=150)
Baseline is 0.12232009068704916
torch.Size([512, 512])
torch.Size([512, 10])
torch.Size([512])
torch.Size([512, 512])
torch.Size([512, 10])
torch.Size([512])
torch.Size([512, 512])
torch.Size([512, 10])
torch.Size([512])
torch.Size([10, 512])
torch.Size([10])
parameter total 808458
step 0 loss 2.3446863 baseline: 0.12232009068704916 acc 0.136 wl 0 train True
step 50 loss 0.12993659 baseline: 0.12232009068704916 acc 0.116 wl 0 train True
step 100 loss 0.12699372 baseline: 0.12232009068704916 acc 0.138 wl 0 train True
step 150 loss 0.12504044 baseline: 0.12232009068704916 acc 0.194 wl 0 train True
step 200 loss 0.11948931 baseline: 0.12232009068704916 acc 0.238 wl 0 train True
step 250 loss 0.11344264 baseline: 0.12232009068704916 acc 0.24 wl 0 train True
step 300 loss 0.10710846 baseline: 0.12232009068704916 acc 0.24 wl 0 train True
step 350 loss 0.1020703 baseline: 0.12232009068704916 acc 0.332 wl 0 train True
step 400 loss 0.09233133 baseline: 0.12232009068704916 acc 0.392 wl 0 train True
step 450 loss 0.085451566 baseline: 0.12232009068704916 acc 0.408 wl 0 train True
step 500 loss 0.076419964 baseline: 0.12232009068704916 acc 0.494 wl 0 train True
step 550 loss 0.073759034 baseline: 0.12232009068704916 acc 0.498 wl 0 train True
step 600 loss 0.05840248 baseline: 0.12232009068704916 acc 0.61 wl 0 train True
step 650 loss 0.059040975 baseline: 0.12232009068704916 acc 0.586 wl 0 train True
step 700 loss 0.054207746 baseline: 0.12232009068704916 acc 0.628 wl 0 train True
step 750 loss 0.04420741 baseline: 0.12232009068704916 acc 0.696 wl 0 train True
step 800 loss 0.042678006 baseline: 0.12232009068704916 acc 0.698 wl 0 train True
step 850 loss 0.038159113 baseline: 0.12232009068704916 acc 0.732 wl 0 train True
step 900 loss 0.04101304 baseline: 0.12232009068704916 acc 0.692 wl 0 train True
step 950 loss 0.030647773 baseline: 0.12232009068704916 acc 0.786 wl 0 train True
step 1000 loss 0.027149534 baseline: 0.12232009068704916 acc 0.8 wl 0 train True
step 1050 loss 0.050941076 baseline: 0.12232009068704916 acc 0.63 wl 0 train True
step 1100 loss 0.031952 baseline: 0.12232009068704916 acc 0.79 wl 0 train True
step 1150 loss 0.021260116 baseline: 0.12232009068704916 acc 0.878 wl 0 train True
step 1200 loss 0.02009898 baseline: 0.12232009068704916 acc 0.844 wl 0 train True
step 1250 loss 0.018480573 baseline: 0.12232009068704916 acc 0.872 wl 0 train True
step 1300 loss 0.012705092 baseline: 0.12232009068704916 acc 0.928 wl 0 train True
step 1350 loss 0.013258965 baseline: 0.12232009068704916 acc 0.916 wl 0 train True
step 1400 loss 0.007836829 baseline: 0.12232009068704916 acc 0.96 wl 0 train True
step 1450 loss 0.019868327 baseline: 0.12232009068704916 acc 0.864 wl 0 train True
step 1500 loss 0.011716223 baseline: 0.12232009068704916 acc 0.926 wl 0 train True
step 1550 loss 0.0063648317 baseline: 0.12232009068704916 acc 0.966 wl 0 train True
step 1600 loss 0.0049527297 baseline: 0.12232009068704916 acc 0.978 wl 0 train True
step 1650 loss 0.0045776847 baseline: 0.12232009068704916 acc 0.984 wl 0 train True
step 1700 loss 0.00474304 baseline: 0.12232009068704916 acc 0.974 wl 0 train True
step 1750 loss 0.002877746 baseline: 0.12232009068704916 acc 0.994 wl 0 train True
step 1800 loss 0.005211786 baseline: 0.12232009068704916 acc 0.974 wl 0 train True
step 1850 loss 0.001716884 baseline: 0.12232009068704916 acc 0.998 wl 0 train True
step 1900 loss 0.018581606 baseline: 0.12232009068704916 acc 0.89 wl 0 train True
step 1950 loss 0.0011300223 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 2000 loss 0.0017445444 baseline: 0.12232009068704916 acc 0.994 wl 0 train True
step 2050 loss 0.12757318 baseline: 0.12232009068704916 acc 0.48 wl 0 train True
step 2100 loss 0.302245 baseline: 0.12232009068704916 acc 0.028 wl 0 train True
step 2150 loss 0.18753883 baseline: 0.12232009068704916 acc 0.044 wl 0 train True
step 2200 loss 0.16381863 baseline: 0.12232009068704916 acc 0.09 wl 0 train True
step 2250 loss 0.14123498 baseline: 0.12232009068704916 acc 0.14 wl 0 train True
step 2300 loss 0.13041997 baseline: 0.12232009068704916 acc 0.148 wl 0 train True
step 2350 loss 0.12734145 baseline: 0.12232009068704916 acc 0.17 wl 0 train True
step 2400 loss 0.12614916 baseline: 0.12232009068704916 acc 0.136 wl 0 train True
step 2450 loss 0.12384126 baseline: 0.12232009068704916 acc 0.164 wl 0 train True
step 2500 loss 0.1232712 baseline: 0.12232009068704916 acc 0.164 wl 0 train True
step 2550 loss 0.121223144 baseline: 0.12232009068704916 acc 0.19 wl 0 train True
step 2600 loss 0.122939125 baseline: 0.12232009068704916 acc 0.156 wl 0 train True
step 2650 loss 0.11897537 baseline: 0.12232009068704916 acc 0.198 wl 0 train True
step 2700 loss 0.11940357 baseline: 0.12232009068704916 acc 0.188 wl 0 train True
step 2750 loss 0.11763289 baseline: 0.12232009068704916 acc 0.214 wl 0 train True
step 2800 loss 0.11805054 baseline: 0.12232009068704916 acc 0.218 wl 0 train True
step 2850 loss 0.117603555 baseline: 0.12232009068704916 acc 0.21 wl 0 train True
step 2900 loss 0.116222434 baseline: 0.12232009068704916 acc 0.238 wl 0 train True
step 2950 loss 0.11648053 baseline: 0.12232009068704916 acc 0.228 wl 0 train True
step 3000 loss 0.11547685 baseline: 0.12232009068704916 acc 0.246 wl 0 train True
step 3050 loss 0.114006445 baseline: 0.12232009068704916 acc 0.23 wl 0 train True
step 3100 loss 0.11477558 baseline: 0.12232009068704916 acc 0.226 wl 0 train True
step 3150 loss 0.112366796 baseline: 0.12232009068704916 acc 0.27 wl 0 train True
step 3200 loss 0.11172632 baseline: 0.12232009068704916 acc 0.28 wl 0 train True
step 3250 loss 0.11051678 baseline: 0.12232009068704916 acc 0.292 wl 0 train True
step 3300 loss 0.10925876 baseline: 0.12232009068704916 acc 0.276 wl 0 train True
step 3350 loss 0.10723458 baseline: 0.12232009068704916 acc 0.3 wl 0 train True
step 3400 loss 0.10416762 baseline: 0.12232009068704916 acc 0.33 wl 0 train True
step 3450 loss 0.10204315 baseline: 0.12232009068704916 acc 0.342 wl 0 train True
step 3500 loss 0.09839031 baseline: 0.12232009068704916 acc 0.374 wl 0 train True
step 3550 loss 0.09426193 baseline: 0.12232009068704916 acc 0.396 wl 0 train True
step 3600 loss 0.099417716 baseline: 0.12232009068704916 acc 0.358 wl 0 train True
step 3650 loss 0.08823686 baseline: 0.12232009068704916 acc 0.416 wl 0 train True
step 3700 loss 0.085010596 baseline: 0.12232009068704916 acc 0.43 wl 0 train True
step 3750 loss 0.08552964 baseline: 0.12232009068704916 acc 0.44 wl 0 train True
step 3800 loss 0.0741016 baseline: 0.12232009068704916 acc 0.542 wl 0 train True
step 3850 loss 0.07522754 baseline: 0.12232009068704916 acc 0.518 wl 0 train True
step 3900 loss 0.06479354 baseline: 0.12232009068704916 acc 0.586 wl 0 train True
step 3950 loss 0.063641876 baseline: 0.12232009068704916 acc 0.588 wl 0 train True
step 4000 loss 0.05057319 baseline: 0.12232009068704916 acc 0.658 wl 0 train True
step 4050 loss 0.042426452 baseline: 0.12232009068704916 acc 0.728 wl 0 train True
step 4100 loss 0.039155986 baseline: 0.12232009068704916 acc 0.744 wl 0 train True
step 4150 loss 0.035201892 baseline: 0.12232009068704916 acc 0.778 wl 0 train True
step 4200 loss 0.03457498 baseline: 0.12232009068704916 acc 0.772 wl 0 train True
step 4250 loss 0.025291203 baseline: 0.12232009068704916 acc 0.846 wl 0 train True
step 4300 loss 0.017317185 baseline: 0.12232009068704916 acc 0.884 wl 0 train True
step 4350 loss 0.07271111 baseline: 0.12232009068704916 acc 0.606 wl 0 train True
step 4400 loss 0.0108666215 baseline: 0.12232009068704916 acc 0.936 wl 0 train True
step 4450 loss 0.009740023 baseline: 0.12232009068704916 acc 0.942 wl 0 train True
step 4500 loss 0.006567145 baseline: 0.12232009068704916 acc 0.958 wl 0 train True
step 4550 loss 0.0073539163 baseline: 0.12232009068704916 acc 0.968 wl 0 train True
step 4600 loss 0.0035044253 baseline: 0.12232009068704916 acc 0.986 wl 0 train True
step 4650 loss 0.0024640895 baseline: 0.12232009068704916 acc 0.994 wl 0 train True
step 4700 loss 0.029589979 baseline: 0.12232009068704916 acc 0.842 wl 0 train True
step 4750 loss 0.0031033554 baseline: 0.12232009068704916 acc 0.988 wl 0 train True
step 4800 loss 0.0014676965 baseline: 0.12232009068704916 acc 0.994 wl 0 train True
step 4850 loss 0.15804082 baseline: 0.12232009068704916 acc 0.458 wl 0 train True
step 4900 loss 0.001589018 baseline: 0.12232009068704916 acc 0.996 wl 0 train True
step 4950 loss 0.0015760134 baseline: 0.12232009068704916 acc 0.994 wl 0 train True
step 5000 loss 0.0012786868 baseline: 0.12232009068704916 acc 0.994 wl 0 train True
step 5050 loss 0.0011587034 baseline: 0.12232009068704916 acc 0.996 wl 0 train True
step 5100 loss 0.0018862318 baseline: 0.12232009068704916 acc 0.992 wl 0 train True
step 5150 loss 0.0011371374 baseline: 0.12232009068704916 acc 0.996 wl 0 train True
step 5200 loss 0.0004469992 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 5250 loss 0.00030396247 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 5300 loss 0.002301382 baseline: 0.12232009068704916 acc 0.984 wl 0 train True
step 5350 loss 0.00082460226 baseline: 0.12232009068704916 acc 0.998 wl 0 train True
step 5400 loss 0.00042830646 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 5450 loss 0.000329835 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 5500 loss 0.0003053162 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 5550 loss 0.0007969196 baseline: 0.12232009068704916 acc 0.996 wl 0 train True
step 5600 loss 0.0006259842 baseline: 0.12232009068704916 acc 0.998 wl 0 train True
step 5650 loss 0.00015496265 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 5700 loss 0.00021589559 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 5750 loss 0.0818812 baseline: 0.12232009068704916 acc 0.746 wl 0 train True
step 5800 loss 0.0013649373 baseline: 0.12232009068704916 acc 0.998 wl 0 train True
step 5850 loss 0.0008013755 baseline: 0.12232009068704916 acc 0.998 wl 0 train True
step 5900 loss 0.0004103921 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 5950 loss 0.00020078682 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 6000 loss 0.00020295783 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 6050 loss 0.00015189227 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 6100 loss 0.00011557876 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 6150 loss 0.00020979562 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 6200 loss 0.00011556199 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 6250 loss 0.00031077123 baseline: 0.12232009068704916 acc 0.998 wl 0 train True
step 6300 loss 0.0015442951 baseline: 0.12232009068704916 acc 0.99 wl 0 train True
step 6350 loss 0.00024304519 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 6400 loss 8.249698e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 6450 loss 7.2466515e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 6500 loss 5.451079e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 6550 loss 0.0014200052 baseline: 0.12232009068704916 acc 0.994 wl 0 train True
step 6600 loss 0.0004320926 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 6650 loss 0.00028363385 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 6700 loss 0.00013974874 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 6750 loss 0.0010391787 baseline: 0.12232009068704916 acc 0.996 wl 0 train True
step 6800 loss 0.00083301385 baseline: 0.12232009068704916 acc 0.998 wl 0 train True
step 6850 loss 0.00017929189 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 6900 loss 0.00014203497 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 6950 loss 0.00034026528 baseline: 0.12232009068704916 acc 0.998 wl 0 train True
step 7000 loss 2.8041615e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 7050 loss 3.9206843e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 7100 loss 1.7193626e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 7150 loss 0.00064206205 baseline: 0.12232009068704916 acc 0.998 wl 0 train True
step 7200 loss 0.0002626626 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 7250 loss 0.0001865437 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 7300 loss 0.00012796053 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 7350 loss 8.788827e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 7400 loss 0.0001350856 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 7450 loss 3.3267974e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 7500 loss 0.0003337524 baseline: 0.12232009068704916 acc 0.998 wl 0 train True
step 7550 loss 4.1150317e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 7600 loss 4.0714825e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 7650 loss 5.307467e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 7700 loss 0.0010362243 baseline: 0.12232009068704916 acc 0.996 wl 0 train True
step 7750 loss 0.0002128246 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 7800 loss 0.000109553395 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 7850 loss 3.6493526e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 7900 loss 0.0001509653 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 7950 loss 2.4919285e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 8000 loss 2.1114462e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 8050 loss 0.00012544637 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 8100 loss 7.394263e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 8150 loss 0.00011084826 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 8200 loss 2.2545086e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 8250 loss 2.4375355e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 8300 loss 4.8025187e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 8350 loss 0.00035250612 baseline: 0.12232009068704916 acc 0.998 wl 0 train True
step 8400 loss 0.00010079445 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 8450 loss 4.1065497e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 8500 loss 2.8184722e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 8550 loss 0.00025801233 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 8600 loss 7.684455e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 8650 loss 2.2125132e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 8700 loss 0.0005671316 baseline: 0.12232009068704916 acc 0.996 wl 0 train True
step 8750 loss 5.617355e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 8800 loss 5.481989e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 8850 loss 2.713052e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 8900 loss 0.00014914882 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 8950 loss 1.9431283e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 9000 loss 2.1189746e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 9050 loss 0.0005082211 baseline: 0.12232009068704916 acc 0.998 wl 0 train True
step 9100 loss 5.9237536e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 9150 loss 4.2042226e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 9200 loss 1.201237e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 9250 loss 7.006718e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 9300 loss 1.6194062e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 9350 loss 0.044620905 baseline: 0.12232009068704916 acc 0.794 wl 0 train True
step 9400 loss 8.975814e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 9450 loss 2.5110301e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 9500 loss 1.8094624e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 9550 loss 1.4325423e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 9600 loss 0.00017943146 baseline: 0.12232009068704916 acc 0.998 wl 0 train True
step 9650 loss 0.0001750315 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 9700 loss 2.6257907e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 9750 loss 3.4028333e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 9800 loss 0.00070426933 baseline: 0.12232009068704916 acc 0.994 wl 0 train True
step 9850 loss 3.544033e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 9900 loss 1.7334209e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 9950 loss 1.0432636e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 10000 loss 0.00021276328 baseline: 0.12232009068704916 acc 0.998 wl 0 train True
step 10050 loss 3.9694056e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 10100 loss 1.2302175e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 10150 loss 7.3968775e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 10200 loss 1.7099717e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 10250 loss 4.7275993e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 10300 loss 7.979337e-06 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 10350 loss 1.8947378e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 10400 loss 7.4074687e-06 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 10450 loss 0.00036980808 baseline: 0.12232009068704916 acc 0.998 wl 0 train True
step 10500 loss 0.000107884465 baseline: 0.12232009068704916 acc 0.998 wl 0 train True
step 10550 loss 1.412818e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 10600 loss 2.5350626e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 10650 loss 7.049785e-06 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 10700 loss 5.323522e-06 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 10750 loss 2.0535413e-06 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 10800 loss 8.619477e-06 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 10850 loss 1.7807119e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 10900 loss 0.0002500193 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 10950 loss 0.00013261447 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 11000 loss 3.0545514e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 11050 loss 6.60815e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 11100 loss 9.859276e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 11150 loss 1.2834661e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 11200 loss 8.63726e-06 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 11250 loss 1.5805974e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 11300 loss 1.8708677e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 11350 loss 7.5150656e-06 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 11400 loss 0.00012560553 baseline: 0.12232009068704916 acc 0.998 wl 0 train True
step 11450 loss 2.7274187e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 11500 loss 9.677663e-06 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 11550 loss 2.79987e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 11600 loss 0.0006849564 baseline: 0.12232009068704916 acc 0.996 wl 0 train True
step 11650 loss 6.6533146e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 11700 loss 1.22086585e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 11750 loss 5.466461e-06 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 11800 loss 3.977046e-06 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 11850 loss 7.0693072e-06 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
step 11900 loss 0.00035318828 baseline: 0.12232009068704916 acc 0.996 wl 0 train True
step 11950 loss 1.7857272e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train True
training done... testing ...
step 0 loss 4.5893277e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train False
step 50 loss 7.8055324e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train False
step 100 loss 5.2751428e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train False
step 150 loss 4.954826e-05 baseline: 0.12232009068704916 acc 1.0 wl 0 train False
test_el_total 100000.0 test_acc_sum 99985.0
test loss mean 4.834332e-05 test acc mean 0.99985 pt 808458
time: 2020-01-06 18:15:18.981331 experiment took 3817.120301961899 [s]

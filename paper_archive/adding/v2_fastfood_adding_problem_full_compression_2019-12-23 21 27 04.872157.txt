Namespace(batch_size=50, cell='FastFoodGRU', compression_mode='full', hidden=512, lr=0.001, n_test=10000, n_train=600000, problem='adding', time_steps=150)
torch.Size([512])
torch.Size([512])
torch.Size([512])
torch.Size([512, 2])
torch.Size([512])
torch.Size([512])
torch.Size([512])
torch.Size([512])
torch.Size([512, 2])
torch.Size([512])
torch.Size([512])
torch.Size([512])
torch.Size([512])
torch.Size([512, 2])
torch.Size([512])
torch.Size([1, 512])
torch.Size([1])
parameter total 9729
step 0 loss 1.2855749 baseline: 0.167 acc 0.0 wl 0 train True
step 50 loss 0.3551556 baseline: 0.167 acc 0.04 wl 0 train True
step 100 loss 0.1861957 baseline: 0.167 acc 0.08 wl 0 train True
step 150 loss 0.1833543 baseline: 0.167 acc 0.08 wl 0 train True
step 200 loss 0.23087044 baseline: 0.167 acc 0.02 wl 0 train True
step 250 loss 0.16983037 baseline: 0.167 acc 0.12 wl 0 train True
step 300 loss 0.17970787 baseline: 0.167 acc 0.12 wl 0 train True
step 350 loss 0.22636272 baseline: 0.167 acc 0.04 wl 0 train True
step 400 loss 0.11781155 baseline: 0.167 acc 0.1 wl 0 train True
step 450 loss 0.16053566 baseline: 0.167 acc 0.14 wl 0 train True
step 500 loss 0.1610933 baseline: 0.167 acc 0.04 wl 0 train True
step 550 loss 0.12899923 baseline: 0.167 acc 0.12 wl 0 train True
step 600 loss 0.15505078 baseline: 0.167 acc 0.02 wl 0 train True
step 650 loss 0.1855302 baseline: 0.167 acc 0.04 wl 0 train True
step 700 loss 0.20162308 baseline: 0.167 acc 0.14 wl 0 train True
step 750 loss 0.2516915 baseline: 0.167 acc 0.02 wl 0 train True
step 800 loss 0.26506698 baseline: 0.167 acc 0.04 wl 0 train True
step 850 loss 0.17504597 baseline: 0.167 acc 0.1 wl 0 train True
step 900 loss 0.17396683 baseline: 0.167 acc 0.08 wl 0 train True
step 950 loss 0.19929184 baseline: 0.167 acc 0.04 wl 0 train True
step 1000 loss 0.167146 baseline: 0.167 acc 0.04 wl 0 train True
step 1050 loss 0.21254574 baseline: 0.167 acc 0.02 wl 0 train True
step 1100 loss 0.1920084 baseline: 0.167 acc 0.06 wl 0 train True
step 1150 loss 0.16640493 baseline: 0.167 acc 0.14 wl 0 train True
step 1200 loss 0.16956656 baseline: 0.167 acc 0.14 wl 0 train True
step 1250 loss 0.14576548 baseline: 0.167 acc 0.16 wl 0 train True
step 1300 loss 0.21652302 baseline: 0.167 acc 0.1 wl 0 train True
step 1350 loss 0.13613349 baseline: 0.167 acc 0.12 wl 0 train True
step 1400 loss 0.24647534 baseline: 0.167 acc 0.12 wl 0 train True
step 1450 loss 0.16722469 baseline: 0.167 acc 0.1 wl 0 train True
step 1500 loss 0.17682141 baseline: 0.167 acc 0.06 wl 0 train True
step 1550 loss 0.14924248 baseline: 0.167 acc 0.08 wl 0 train True
step 1600 loss 0.11995519 baseline: 0.167 acc 0.04 wl 0 train True
step 1650 loss 0.25310317 baseline: 0.167 acc 0.04 wl 0 train True
step 1700 loss 0.14003077 baseline: 0.167 acc 0.26 wl 0 train True
step 1750 loss 0.15945719 baseline: 0.167 acc 0.06 wl 0 train True
step 1800 loss 0.13711114 baseline: 0.167 acc 0.2 wl 0 train True
step 1850 loss 0.15950215 baseline: 0.167 acc 0.1 wl 0 train True
step 1900 loss 0.18104202 baseline: 0.167 acc 0.06 wl 0 train True
step 1950 loss 0.16366997 baseline: 0.167 acc 0.12 wl 0 train True
step 2000 loss 0.124072626 baseline: 0.167 acc 0.06 wl 0 train True
step 2050 loss 0.15343145 baseline: 0.167 acc 0.12 wl 0 train True
step 2100 loss 0.17396177 baseline: 0.167 acc 0.16 wl 0 train True
step 2150 loss 0.16426784 baseline: 0.167 acc 0.12 wl 0 train True
step 2200 loss 0.21822645 baseline: 0.167 acc 0.04 wl 0 train True
step 2250 loss 0.18473753 baseline: 0.167 acc 0.1 wl 0 train True
step 2300 loss 0.14587183 baseline: 0.167 acc 0.04 wl 0 train True
step 2350 loss 0.16390915 baseline: 0.167 acc 0.12 wl 0 train True
step 2400 loss 0.12237661 baseline: 0.167 acc 0.08 wl 0 train True
step 2450 loss 0.14043084 baseline: 0.167 acc 0.18 wl 0 train True
step 2500 loss 0.1952661 baseline: 0.167 acc 0.08 wl 0 train True
step 2550 loss 0.17417143 baseline: 0.167 acc 0.1 wl 0 train True
step 2600 loss 0.17935637 baseline: 0.167 acc 0.1 wl 0 train True
step 2650 loss 0.17800869 baseline: 0.167 acc 0.14 wl 0 train True
step 2700 loss 0.2035366 baseline: 0.167 acc 0.04 wl 0 train True
step 2750 loss 0.10991569 baseline: 0.167 acc 0.12 wl 0 train True
step 2800 loss 0.17573257 baseline: 0.167 acc 0.06 wl 0 train True
step 2850 loss 0.15162334 baseline: 0.167 acc 0.08 wl 0 train True
step 2900 loss 0.10932954 baseline: 0.167 acc 0.2 wl 0 train True
step 2950 loss 0.2048701 baseline: 0.167 acc 0.08 wl 0 train True
step 3000 loss 0.22096717 baseline: 0.167 acc 0.04 wl 0 train True
step 3050 loss 0.16515492 baseline: 0.167 acc 0.1 wl 0 train True
step 3100 loss 0.19585015 baseline: 0.167 acc 0.1 wl 0 train True
step 3150 loss 0.20230205 baseline: 0.167 acc 0.06 wl 0 train True
step 3200 loss 0.2061356 baseline: 0.167 acc 0.06 wl 0 train True
step 3250 loss 0.13328205 baseline: 0.167 acc 0.1 wl 0 train True
step 3300 loss 0.16062321 baseline: 0.167 acc 0.1 wl 0 train True
step 3350 loss 0.2787081 baseline: 0.167 acc 0.02 wl 0 train True
step 3400 loss 0.13446748 baseline: 0.167 acc 0.14 wl 0 train True
step 3450 loss 0.14145678 baseline: 0.167 acc 0.06 wl 0 train True
step 3500 loss 0.12763837 baseline: 0.167 acc 0.1 wl 0 train True
step 3550 loss 0.12056433 baseline: 0.167 acc 0.14 wl 0 train True
step 3600 loss 0.16296537 baseline: 0.167 acc 0.08 wl 0 train True
step 3650 loss 0.23130456 baseline: 0.167 acc 0.08 wl 0 train True
step 3700 loss 0.15896693 baseline: 0.167 acc 0.04 wl 0 train True
step 3750 loss 0.24775666 baseline: 0.167 acc 0.1 wl 0 train True
step 3800 loss 0.14951752 baseline: 0.167 acc 0.18 wl 0 train True
step 3850 loss 0.1985246 baseline: 0.167 acc 0.16 wl 0 train True
step 3900 loss 0.17010844 baseline: 0.167 acc 0.1 wl 0 train True
step 3950 loss 0.18088588 baseline: 0.167 acc 0.16 wl 0 train True
step 4000 loss 0.18617141 baseline: 0.167 acc 0.1 wl 0 train True
step 4050 loss 0.13854715 baseline: 0.167 acc 0.16 wl 0 train True
step 4100 loss 0.15836854 baseline: 0.167 acc 0.16 wl 0 train True
step 4150 loss 0.22661638 baseline: 0.167 acc 0.1 wl 0 train True
step 4200 loss 0.20904984 baseline: 0.167 acc 0.0 wl 0 train True
step 4250 loss 0.17513928 baseline: 0.167 acc 0.1 wl 0 train True
step 4300 loss 0.2022488 baseline: 0.167 acc 0.1 wl 0 train True
step 4350 loss 0.21286686 baseline: 0.167 acc 0.02 wl 0 train True
step 4400 loss 0.17046589 baseline: 0.167 acc 0.08 wl 0 train True
step 4450 loss 0.1831381 baseline: 0.167 acc 0.12 wl 0 train True
step 4500 loss 0.26814628 baseline: 0.167 acc 0.04 wl 0 train True
step 4550 loss 0.17899786 baseline: 0.167 acc 0.14 wl 0 train True
step 4600 loss 0.1698968 baseline: 0.167 acc 0.04 wl 0 train True
step 4650 loss 0.18879324 baseline: 0.167 acc 0.06 wl 0 train True
step 4700 loss 0.15751284 baseline: 0.167 acc 0.14 wl 0 train True
step 4750 loss 0.17592458 baseline: 0.167 acc 0.16 wl 0 train True
step 4800 loss 0.22173788 baseline: 0.167 acc 0.16 wl 0 train True
step 4850 loss 0.1986578 baseline: 0.167 acc 0.14 wl 0 train True
step 4900 loss 0.14605886 baseline: 0.167 acc 0.16 wl 0 train True
step 4950 loss 0.19976464 baseline: 0.167 acc 0.14 wl 0 train True
step 5000 loss 0.15393625 baseline: 0.167 acc 0.06 wl 0 train True
step 5050 loss 0.17660858 baseline: 0.167 acc 0.1 wl 0 train True
step 5100 loss 0.17142215 baseline: 0.167 acc 0.18 wl 0 train True
step 5150 loss 0.16670772 baseline: 0.167 acc 0.08 wl 0 train True
step 5200 loss 0.21492058 baseline: 0.167 acc 0.06 wl 0 train True
step 5250 loss 0.14980118 baseline: 0.167 acc 0.12 wl 0 train True
step 5300 loss 0.1713953 baseline: 0.167 acc 0.1 wl 0 train True
step 5350 loss 0.17918415 baseline: 0.167 acc 0.08 wl 0 train True
step 5400 loss 0.1576553 baseline: 0.167 acc 0.12 wl 0 train True
step 5450 loss 0.23576225 baseline: 0.167 acc 0.08 wl 0 train True
step 5500 loss 0.13893148 baseline: 0.167 acc 0.12 wl 0 train True
step 5550 loss 0.1925454 baseline: 0.167 acc 0.08 wl 0 train True
step 5600 loss 0.20476177 baseline: 0.167 acc 0.1 wl 0 train True
step 5650 loss 0.12516695 baseline: 0.167 acc 0.16 wl 0 train True
step 5700 loss 0.19459248 baseline: 0.167 acc 0.08 wl 0 train True
step 5750 loss 0.16350907 baseline: 0.167 acc 0.08 wl 0 train True
step 5800 loss 0.1838871 baseline: 0.167 acc 0.04 wl 0 train True
step 5850 loss 0.1634214 baseline: 0.167 acc 0.1 wl 0 train True
step 5900 loss 0.18957335 baseline: 0.167 acc 0.12 wl 0 train True
step 5950 loss 0.14120041 baseline: 0.167 acc 0.16 wl 0 train True
step 6000 loss 0.17988804 baseline: 0.167 acc 0.12 wl 0 train True
step 6050 loss 0.12940061 baseline: 0.167 acc 0.08 wl 0 train True
step 6100 loss 0.1569027 baseline: 0.167 acc 0.14 wl 0 train True
step 6150 loss 0.19681497 baseline: 0.167 acc 0.12 wl 0 train True
step 6200 loss 0.14967053 baseline: 0.167 acc 0.12 wl 0 train True
step 6250 loss 0.16435535 baseline: 0.167 acc 0.12 wl 0 train True
step 6300 loss 0.13015603 baseline: 0.167 acc 0.12 wl 0 train True
step 6350 loss 0.15280576 baseline: 0.167 acc 0.14 wl 0 train True
step 6400 loss 0.19615597 baseline: 0.167 acc 0.08 wl 0 train True
step 6450 loss 0.19513007 baseline: 0.167 acc 0.06 wl 0 train True
step 6500 loss 0.13799211 baseline: 0.167 acc 0.14 wl 0 train True
step 6550 loss 0.16404587 baseline: 0.167 acc 0.08 wl 0 train True
step 6600 loss 0.15657818 baseline: 0.167 acc 0.04 wl 0 train True
step 6650 loss 0.13231978 baseline: 0.167 acc 0.08 wl 0 train True
step 6700 loss 0.14733449 baseline: 0.167 acc 0.1 wl 0 train True
step 6750 loss 0.112911284 baseline: 0.167 acc 0.14 wl 0 train True
step 6800 loss 0.18981498 baseline: 0.167 acc 0.12 wl 0 train True
step 6850 loss 0.1388083 baseline: 0.167 acc 0.16 wl 0 train True
step 6900 loss 0.17015253 baseline: 0.167 acc 0.02 wl 0 train True
step 6950 loss 0.13191319 baseline: 0.167 acc 0.06 wl 0 train True
step 7000 loss 0.108607575 baseline: 0.167 acc 0.04 wl 0 train True
step 7050 loss 0.12425953 baseline: 0.167 acc 0.1 wl 0 train True
step 7100 loss 0.11664831 baseline: 0.167 acc 0.12 wl 0 train True
step 7150 loss 0.11402243 baseline: 0.167 acc 0.04 wl 0 train True
step 7200 loss 0.07676826 baseline: 0.167 acc 0.08 wl 0 train True
step 7250 loss 0.10923256 baseline: 0.167 acc 0.14 wl 0 train True
step 7300 loss 0.09124794 baseline: 0.167 acc 0.12 wl 0 train True
step 7350 loss 0.08281841 baseline: 0.167 acc 0.2 wl 0 train True
step 7400 loss 0.11314689 baseline: 0.167 acc 0.08 wl 0 train True
step 7450 loss 0.071085304 baseline: 0.167 acc 0.1 wl 0 train True
step 7500 loss 0.0713844 baseline: 0.167 acc 0.14 wl 0 train True
step 7550 loss 0.090109885 baseline: 0.167 acc 0.14 wl 0 train True
step 7600 loss 0.0699849 baseline: 0.167 acc 0.1 wl 0 train True
step 7650 loss 0.16652775 baseline: 0.167 acc 0.12 wl 0 train True
step 7700 loss 0.07773238 baseline: 0.167 acc 0.14 wl 0 train True
step 7750 loss 0.11882078 baseline: 0.167 acc 0.08 wl 0 train True
step 7800 loss 0.08104532 baseline: 0.167 acc 0.14 wl 0 train True
step 7850 loss 0.06532569 baseline: 0.167 acc 0.12 wl 0 train True
step 7900 loss 0.06640716 baseline: 0.167 acc 0.14 wl 0 train True
step 7950 loss 0.09200668 baseline: 0.167 acc 0.1 wl 0 train True
step 8000 loss 0.057456624 baseline: 0.167 acc 0.18 wl 0 train True
step 8050 loss 0.07287161 baseline: 0.167 acc 0.14 wl 0 train True
step 8100 loss 0.037149526 baseline: 0.167 acc 0.18 wl 0 train True
step 8150 loss 0.06911863 baseline: 0.167 acc 0.08 wl 0 train True
step 8200 loss 0.058060113 baseline: 0.167 acc 0.1 wl 0 train True
step 8250 loss 0.065170966 baseline: 0.167 acc 0.1 wl 0 train True
step 8300 loss 0.05029319 baseline: 0.167 acc 0.24 wl 0 train True
step 8350 loss 0.05990645 baseline: 0.167 acc 0.06 wl 0 train True
step 8400 loss 0.058189284 baseline: 0.167 acc 0.22 wl 0 train True
step 8450 loss 0.06726622 baseline: 0.167 acc 0.12 wl 0 train True
step 8500 loss 0.04685513 baseline: 0.167 acc 0.12 wl 0 train True
step 8550 loss 0.04500214 baseline: 0.167 acc 0.2 wl 0 train True
step 8600 loss 0.035996947 baseline: 0.167 acc 0.24 wl 0 train True
step 8650 loss 0.06335924 baseline: 0.167 acc 0.2 wl 0 train True
step 8700 loss 0.05152959 baseline: 0.167 acc 0.2 wl 0 train True
step 8750 loss 0.04152091 baseline: 0.167 acc 0.2 wl 0 train True
step 8800 loss 0.06216644 baseline: 0.167 acc 0.04 wl 0 train True
step 8850 loss 0.038911935 baseline: 0.167 acc 0.26 wl 0 train True
step 8900 loss 0.042144675 baseline: 0.167 acc 0.12 wl 0 train True
step 8950 loss 0.03670918 baseline: 0.167 acc 0.24 wl 0 train True
step 9000 loss 0.03411203 baseline: 0.167 acc 0.26 wl 0 train True
step 9050 loss 0.049486887 baseline: 0.167 acc 0.14 wl 0 train True
step 9100 loss 0.051746372 baseline: 0.167 acc 0.18 wl 0 train True
step 9150 loss 0.023562383 baseline: 0.167 acc 0.28 wl 0 train True
step 9200 loss 0.034065958 baseline: 0.167 acc 0.2 wl 0 train True
step 9250 loss 0.0264521 baseline: 0.167 acc 0.2 wl 0 train True
step 9300 loss 0.02512028 baseline: 0.167 acc 0.2 wl 0 train True
step 9350 loss 0.029206801 baseline: 0.167 acc 0.14 wl 0 train True
step 9400 loss 0.058900848 baseline: 0.167 acc 0.28 wl 0 train True
step 9450 loss 0.027486539 baseline: 0.167 acc 0.3 wl 0 train True
step 9500 loss 0.03132057 baseline: 0.167 acc 0.28 wl 0 train True
step 9550 loss 0.023076143 baseline: 0.167 acc 0.18 wl 0 train True
step 9600 loss 0.020729566 baseline: 0.167 acc 0.2 wl 0 train True
step 9650 loss 0.03217521 baseline: 0.167 acc 0.2 wl 0 train True
step 9700 loss 0.02927872 baseline: 0.167 acc 0.28 wl 0 train True
step 9750 loss 0.024229111 baseline: 0.167 acc 0.24 wl 0 train True
step 9800 loss 0.016565897 baseline: 0.167 acc 0.36 wl 0 train True
step 9850 loss 0.026756931 baseline: 0.167 acc 0.12 wl 0 train True
step 9900 loss 0.021079874 baseline: 0.167 acc 0.22 wl 0 train True
step 9950 loss 0.014736928 baseline: 0.167 acc 0.26 wl 0 train True
step 10000 loss 0.023245068 baseline: 0.167 acc 0.28 wl 0 train True
step 10050 loss 0.029014435 baseline: 0.167 acc 0.24 wl 0 train True
step 10100 loss 0.021985956 baseline: 0.167 acc 0.14 wl 0 train True
step 10150 loss 0.026092067 baseline: 0.167 acc 0.2 wl 0 train True
step 10200 loss 0.017406369 baseline: 0.167 acc 0.34 wl 0 train True
step 10250 loss 0.013410333 baseline: 0.167 acc 0.3 wl 0 train True
step 10300 loss 0.0177758 baseline: 0.167 acc 0.26 wl 0 train True
step 10350 loss 0.01750651 baseline: 0.167 acc 0.2 wl 0 train True
step 10400 loss 0.018020792 baseline: 0.167 acc 0.38 wl 0 train True
step 10450 loss 0.0118676 baseline: 0.167 acc 0.4 wl 0 train True
step 10500 loss 0.01959179 baseline: 0.167 acc 0.24 wl 0 train True
step 10550 loss 0.012348784 baseline: 0.167 acc 0.34 wl 0 train True
step 10600 loss 0.012172032 baseline: 0.167 acc 0.32 wl 0 train True
step 10650 loss 0.011036768 baseline: 0.167 acc 0.44 wl 0 train True
step 10700 loss 0.01469917 baseline: 0.167 acc 0.3 wl 0 train True
step 10750 loss 0.013054087 baseline: 0.167 acc 0.36 wl 0 train True
step 10800 loss 0.011159176 baseline: 0.167 acc 0.32 wl 0 train True
step 10850 loss 0.01711072 baseline: 0.167 acc 0.36 wl 0 train True
step 10900 loss 0.010528754 baseline: 0.167 acc 0.52 wl 0 train True
step 10950 loss 0.009934977 baseline: 0.167 acc 0.4 wl 0 train True
step 11000 loss 0.016938774 baseline: 0.167 acc 0.14 wl 0 train True
step 11050 loss 0.010402748 baseline: 0.167 acc 0.42 wl 0 train True
step 11100 loss 0.012788499 baseline: 0.167 acc 0.22 wl 0 train True
step 11150 loss 0.013837416 baseline: 0.167 acc 0.3 wl 0 train True
step 11200 loss 0.010175454 baseline: 0.167 acc 0.4 wl 0 train True
step 11250 loss 0.015561457 baseline: 0.167 acc 0.44 wl 0 train True
step 11300 loss 0.0154019585 baseline: 0.167 acc 0.36 wl 0 train True
step 11350 loss 0.009951284 baseline: 0.167 acc 0.42 wl 0 train True
step 11400 loss 0.013890781 baseline: 0.167 acc 0.46 wl 0 train True
step 11450 loss 0.011072037 baseline: 0.167 acc 0.48 wl 0 train True
step 11500 loss 0.0121191405 baseline: 0.167 acc 0.44 wl 0 train True
step 11550 loss 0.011322135 baseline: 0.167 acc 0.32 wl 0 train True
step 11600 loss 0.012655172 baseline: 0.167 acc 0.44 wl 0 train True
step 11650 loss 0.009456809 baseline: 0.167 acc 0.38 wl 0 train True
step 11700 loss 0.009382767 baseline: 0.167 acc 0.32 wl 0 train True
step 11750 loss 0.0057972395 baseline: 0.167 acc 0.54 wl 0 train True
step 11800 loss 0.008669489 baseline: 0.167 acc 0.3 wl 0 train True
step 11850 loss 0.0064834184 baseline: 0.167 acc 0.46 wl 0 train True
step 11900 loss 0.009054729 baseline: 0.167 acc 0.36 wl 0 train True
step 11950 loss 0.0067205257 baseline: 0.167 acc 0.44 wl 0 train True
training done... testing ...
step 0 loss 0.010732592 baseline: 0.167 acc 0.42 wl 0 train False
step 50 loss 0.007559694 baseline: 0.167 acc 0.54 wl 0 train False
step 100 loss 0.005512742 baseline: 0.167 acc 0.5 wl 0 train False
step 150 loss 0.010054607 baseline: 0.167 acc 0.38 wl 0 train False
test_el_total 10000 test_acc_sum 4491.0
test loss mean 0.0071729394 test acc mean 0.4491 pt 9729
time: 2019-12-24 00:11:52.855067 experiment took 9886.995616674423 [s]

@article{Chang2000,
author = {Chang, S Grace and Member, Student and Yu, Bin and Member, Senior and Vetterli, Martin},
file = {:home/moritz/Documents/Mendeley Desktop/Chang et al. - 2000 - Adaptive Wavelet Thresholding for Image Denoising and CompressionXplore Full-Text PDF.pdf:pdf},
number = {9},
pages = {1532--1546},
title = {{Adaptive Wavelet Thresholding for Image Denoising and CompressionXplore Full-Text PDF:}},
url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp={\&}arnumber=862633},
volume = {9},
year = {2000}
}
@article{Wisdom2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1611.00035v1},
author = {Wisdom, Scott and Powers, Thomas and Hershey, John R and Roux, Jonathan Le and Atlas, Les},
eprint = {arXiv:1611.00035v1},
file = {:home/moritz/Documents/Mendeley Desktop/Wisdom et al. - 2016 - Full-Capacity Unitary Recurrent Neural Networks arXiv 1611 . 00035v1 stat . ML 31 Oct 2016.pdf:pdf},
number = {Nips},
pages = {1--9},
title = {{Full-Capacity Unitary Recurrent Neural Networks arXiv : 1611 . 00035v1 [ stat . ML ] 31 Oct 2016}},
year = {2016}
}
@article{Arjovsky2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1511.06464v4},
author = {Arjovsky, Martin and Shah, Amar and Bengio, Yoshua},
eprint = {arXiv:1511.06464v4},
file = {:home/moritz/Documents/Mendeley Desktop/Arjovsky, Shah, Bengio - 2016 - Unitary Evolution Recurrent Neural Networks.pdf:pdf},
title = {{Unitary Evolution Recurrent Neural Networks}},
volume = {48},
year = {2016}
}
@article{Kingsbury2001,
abstract = {This paper describes a form of discrete wavelet transform, which generates complex coefficients by using a dual tree of wavelet filters to obtain their real and imaginary parts. This introduces limited redundancy (2 m :1 for m-dimensional signals) and allows the transform to provide approximate shift invariance and directionally selective filters (properties lacking in the traditional wavelet transform) while preserving the usual properties of perfect reconstruction and computational efficiency with good well-balanced frequency responses. Here we analyze why the new transform can be designed to be shift invariant and describe how to estimate the accuracy of this approximation and design suitable filters to achieve this. We discuss two different variants of the new transform, based on odd/even and quarter-sample shift (Q-shift) filters, respectively. We then describe briefly how the dual tree may be extended for images and other multi-dimensional signals, and finally summarize a range of applications of the transform that take advantage of its unique properties. {\textcopyright} 2001 Academic Press.},
author = {Kingsbury, Nick},
doi = {10.1006/acha.2000.0343},
file = {:home/moritz/Documents/Mendeley Desktop/Kingsbury - 2001 - Complex Wavelets for Shift Invariant Analysis and Filtering of Signals.pdf:pdf},
issn = {10635203},
journal = {Applied and Computational Harmonic Analysis},
number = {3},
pages = {234--253},
title = {{Complex Wavelets for Shift Invariant Analysis and Filtering of Signals}},
volume = {10},
year = {2001}
}
@article{JulienFauqueur,
author = {{Julien Fauqueur}, Nick Kingsbury and Ryan Anderson and Signal},
file = {:home/moritz/Documents/Mendeley Desktop/Julien Fauqueur, Signal - Unknown - MULTISCALE KEYPOINT DETECTION USING THE DUAL-TREE COMPLEXWAVELET TRANSFORM.pdf:pdf},
journal = {Information Fusion},
title = {{MULTISCALE KEYPOINT DETECTION USING THE DUAL-TREE COMPLEXWAVELET TRANSFORM}}
}
@article{Strang1994,
author = {Strang, Gilbert},
file = {:home/moritz/Documents/Mendeley Desktop/Strang - 1994 - Wavelets.pdf:pdf},
number = {3},
pages = {250--255},
title = {{Wavelets}},
volume = {82},
year = {1994}
}
@article{Selesnick2005,
author = {Selesnick, Ivan W and Baraniuk, Richard G and Kingsbury, Nick G},
file = {:home/moritz/Documents/Mendeley Desktop/Selesnick, Baraniuk, Kingsbury - 2005 - The Dual-Tree Complex Wavelet Transform.PDF:PDF},
number = {November 2005},
pages = {123--151},
title = {{The Dual-Tree Complex Wavelet Transform}},
year = {2005}
}
@inproceedings{yang2015deep,
archivePrefix = {arXiv},
arxivId = {arXiv:1412.7149v4},
author = {{Yang, Zichao and Moczulski, Marcin and Denil, Misha and de Freitas, Nando and Smola, Alex and Song, Le and Wang}, Ziyu and Song, Le and Wang, Ziyu},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
eprint = {arXiv:1412.7149v4},
file = {:home/moritz/Documents/Mendeley Desktop/Yang, Zichao and Moczulski, Marcin and Denil, Misha and de Freitas, Nando and Smola, Alex and Song, Le and Wang, Song, Wang - 2015 - Dee.pdf:pdf},
pages = {1476----1483},
title = {{Deep Fried Convnets}},
year = {2015}
}
@misc{Strang1997,
author = {Strang, Gilbert and Nguyen, Truong},
file = {:home/moritz/Documents/Mendeley Desktop/Strang, Nguyen - 1997 - Wavelets and Filter Banks.pdf:pdf},
pages = {520},
title = {{Wavelets and Filter Banks}},
year = {1997}
}
@article{Claypoole1998,
abstract = {This paper develops new algorithms for adapted multiscale analysis and signal adaptive wavelet transforms. We construct our adaptive transforms with the lifting scheme, which decomposes the wavelet transform into prediction and update stages. We adapt the prediction stage to the signal structure and design the update stage to preserve the desirable properties of the wavelet transform. We incorporate this adaptivity into the redundant and nonredundant transforms; the resulting transforms are scale and spatially adaptive. We study applications to signal estimation; our new transforms show improved denoising performance over existing (nonadaptive) orthogonal transforms. {\textcopyright} 1999 IEEE.},
author = {Claypoole, Roger L. and Baraniuk, Richard G. and Nowak, Robert D.},
doi = {10.1109/ICASSP.1998.681737},
file = {:home/moritz/Documents/Mendeley Desktop/Claypoole, Baraniuk, Nowak - 1998 - Adaptive wavelet transforms via lifting.pdf:pdf},
isbn = {0780344286},
issn = {15206149},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
pages = {1513--1516},
title = {{Adaptive wavelet transforms via lifting}},
volume = {3},
year = {1998}
}
@article{Arena2002,
abstract = {In the paper it is proposed the use of a complex valued Multi-layer Perceptron neural network (MLP) with complex activation functions and complex connection strengths in order to perform the estimation of chaotic time series. In particular, the Ikeda map is taken into consideration. A comparison between the behavior of the real MLP and the complex one is also reported, showing that the complex valued MLP requires a smaller topology as well as a lower number of parameters in order to reach comparable performance.},
author = {Arena, P. and Fortuna, L. and Xibilia, M.G.},
doi = {10.1109/iscas.1994.409519},
file = {:home/moritz/Documents/Mendeley Desktop/Arena, Fortuna, Xibilia - 2002 - Predicting complex chaotic time series via complex valued MLPs.pdf:pdf},
pages = {29--32},
title = {{Predicting complex chaotic time series via complex valued MLPs}},
year = {2002}
}
@article{Balle2016,
abstract = {We describe an image compression method, consisting of a nonlinear analysis transformation, a uniform quantizer, and a nonlinear synthesis transformation. The transforms are constructed in three successive stages of convolutional linear filters and nonlinear activation functions. Unlike most convolutional neural networks, the joint nonlinearity is chosen to implement a form of local gain control, inspired by those used to model biological neurons. Using a variant of stochastic gradient descent, we jointly optimize the entire model for rate-distortion performance over a database of training images, introducing a continuous proxy for the discontinuous loss function arising from the quantizer. Under certain conditions, the relaxed loss function may be interpreted as the log likelihood of a generative model, as implemented by a variational autoencoder. Unlike these models, however, the compression model must operate at any given point along the rate-distortion curve, as specified by a trade-off parameter. Across an independent set of test images, we find that the optimized method generally exhibits better rate-distortion performance than the standard JPEG and JPEG 2000 compression methods. More importantly, we observe a dramatic improvement in visual quality for all images at all bit rates, which is supported by objective quality estimates using MS-SSIM.},
archivePrefix = {arXiv},
arxivId = {1611.01704},
author = {Ball{\'{e}}, Johannes and Laparra, Valero and Simoncelli, Eero P.},
eprint = {1611.01704},
file = {:home/moritz/Documents/Mendeley Desktop/Ball{\'{e}}, Laparra, Simoncelli - 2016 - End-to-end Optimized Image Compression.pdf:pdf},
title = {{End-to-end Optimized Image Compression}},
url = {http://arxiv.org/abs/1611.01704},
year = {2016}
}
@article{Knight2019,
author = {Knight, Marina I. and Nunes, Matthew A.},
doi = {10.1007/s11222-018-9820-8},
file = {:home/moritz/Documents/Mendeley Desktop/Knight, Nunes - 2019 - Long memory estimation for complex-valued time series.pdf:pdf},
issn = {15731375},
journal = {Statistics and Computing},
keywords = {Complex-valued time series,Hurst exponent,Irregular sampling,Long-range dependence,Wavelets},
number = {3},
pages = {517--536},
publisher = {Springer US},
title = {{Long memory estimation for complex-valued time series}},
url = {https://doi.org/10.1007/s11222-018-9820-8},
volume = {29},
year = {2019}
}
@article{Recoskie2018,
abstract = {In this work we propose a method for learning wavelet filters directly from data. We accomplish this by framing the discrete wavelet transform as a modified convolutional neural network. We introduce an autoencoder wavelet transform network that is trained using gradient descent. We show that the model is capable of learning structured wavelet filters from synthetic and real data. The learned wavelets are shown to be similar to traditional wavelets that are derived using Fourier methods. Our method is simple to implement and easily incorporated into neural network architectures. A major advantage to our model is that we can learn from raw audio data.},
archivePrefix = {arXiv},
arxivId = {1802.02961},
author = {Recoskie, Daniel and Mann, Richard},
eprint = {1802.02961},
file = {:home/moritz/Documents/Mendeley Desktop/Recoskie, Mann - 2018 - Learning Sparse Wavelet Representations.pdf:pdf},
pages = {1--7},
title = {{Learning Sparse Wavelet Representations}},
url = {http://arxiv.org/abs/1802.02961},
year = {2018}
}
@book{Mallat,
author = {Mallat, Stephane and Peyr{\'{e}}, Gabriel},
file = {:home/moritz/Documents/Mendeley Desktop/Mallat, Peyr{\'{e}} - Unknown - A Wavelet Tour of Signal Processing The Sparse Way.pdf:pdf},
isbn = {9780123743701},
title = {{A Wavelet Tour of Signal Processing: The Sparse Way}}
}
@article{Torrence1995,
author = {Torrence, Christopher and Compo, Gilbert P},
file = {:home/moritz/Documents/Mendeley Desktop/Torrence, Compo - 1995 - A Practical Guide to Wavelet Analysis.pdf:pdf},
title = {{A Practical Guide to Wavelet Analysis}},
year = {1995}
}
@article{Ehrlich,
archivePrefix = {arXiv},
arxivId = {arXiv:1812.11690v2},
author = {Ehrlich, Max and Davis, Larry},
eprint = {arXiv:1812.11690v2},
file = {:home/moritz/Documents/Mendeley Desktop/Ehrlich, Davis - Unknown - Deep Residual Learning in the JPEG Transform Domain.pdf:pdf},
title = {{Deep Residual Learning in the JPEG Transform Domain}}
}
@article{Xu2019,
author = {Xu, Bingbing and Shen, Huawei and Cao, Qi and Qiu, Yunqi and Cheng, Xueqi},
file = {:home/moritz/Documents/Mendeley Desktop/Xu et al. - 2019 - GRAPH WAVELET NEURAL NETWORK.pdf:pdf},
pages = {1--13},
title = {{GRAPH WAVELET NEURAL NETWORK}},
year = {2019}
}
@article{Recoskie,
archivePrefix = {arXiv},
arxivId = {arXiv:1806.01793v1},
author = {Recoskie, Daniel and Mann, Richard},
eprint = {arXiv:1806.01793v1},
file = {:home/moritz/Documents/Mendeley Desktop/Recoskie, Mann - Unknown - Gradient-based Filter Design for the Dual-tree Wavelet Transform.pdf:pdf},
pages = {1--19},
title = {{Gradient-based Filter Design for the Dual-tree Wavelet Transform}}
}
@article{Mallat1989,
author = {Mallat, Stephane G},
file = {:home/moritz/Documents/Mendeley Desktop/Mallat - 1989 - Multiresolution approximations and wavelet orthonormal bases of l2(r).pdf:pdf},
keywords = {air,and darpa,and phrases,approximation theory,army daag-29-84-k-0061,dcr-8410771,dcr82-19196 a02,f49620-85-k-0018,force,in part by nsf-cer,nsf,onr n0014-85-k-0807,orthonormal bases,this work is supported,wavelets},
number = {1},
pages = {69--87},
title = {{Multiresolution approximations and wavelet orthonormal bases of l2(r)}},
volume = {315},
year = {1989}
}
@article{Strang1993,
abstract = {This note is a very basic introduction to wavelets. It starts with an orthogonal basis of piecewise constant functions, constructed by dilation and translation. The ``wavelet transform'' maps each {\$}f(x){\$} to its coefficients with respect to this basis. The mathematics is simple and the transform is fast (faster than the Fast Fourier Transform, which we briefly explain), but approximation by piecewise constants is poor. To improve this first wavelet, we are led to dilation equations and their unusual solutions. Higher-order wavelets are constructed, and it is surprisingly quick to compute with them --- always indirectly and recursively. We comment informally on the contest between these transforms in signal processing, especially for video and image compression (including high-definition television). So far the Fourier Transform --- or its 8 by 8 windowed version, the Discrete Cosine Transform --- is often chosen. But wavelets are already competitive, and they are ahead for fingerprints. We present a sample of this developing theory.},
author = {Strang, Gilbert},
doi = {10.1090/S0273-0979-1993-00390-2},
file = {:home/moritz/Documents/Mendeley Desktop/Strang - 1993 - Wavelet transforms versus fourier transforms.pdf:pdf},
issn = {02730979},
journal = {Bulletin of the American Mathematical Society},
keywords = {Dilation,Fourier transform,Orthogonal basis,Wavelets},
number = {2},
pages = {288--305},
title = {{Wavelet transforms versus fourier transforms}},
volume = {28},
year = {1993}
}
@inproceedings{wolter-2018-neurips,
     author = {Wolter, Moritz and Yao, Angela},
      title = {Complex Gated Recurrent Neural Networks},
  booktitle = {Advances in Neural Information Processing Systems 31},
       year = {2018},
}
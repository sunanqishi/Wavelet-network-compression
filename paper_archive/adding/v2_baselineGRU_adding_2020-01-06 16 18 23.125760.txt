Namespace(batch_size=50, cell='GRU', compression_mode='state', hidden=512, lr=0.001, n_test=10000, n_train=600000, problem='adding', time_steps=150)
torch.Size([512, 512])
torch.Size([512, 2])
torch.Size([512])
torch.Size([512, 512])
torch.Size([512, 2])
torch.Size([512])
torch.Size([512, 512])
torch.Size([512, 2])
torch.Size([512])
torch.Size([1, 512])
torch.Size([1])
parameter total 791553
step 0 loss 1.5012442 baseline: 0.167 acc 0.0 wl 0 train True
step 50 loss 0.17161909 baseline: 0.167 acc 0.12 wl 0 train True
step 100 loss 0.16672112 baseline: 0.167 acc 0.08 wl 0 train True
step 150 loss 0.1616516 baseline: 0.167 acc 0.12 wl 0 train True
step 200 loss 0.12999037 baseline: 0.167 acc 0.08 wl 0 train True
step 250 loss 0.053938493 baseline: 0.167 acc 0.16 wl 0 train True
step 300 loss 0.025685525 baseline: 0.167 acc 0.22 wl 0 train True
step 350 loss 0.019735215 baseline: 0.167 acc 0.12 wl 0 train True
step 400 loss 0.00435037 baseline: 0.167 acc 0.72 wl 0 train True
step 450 loss 0.09772015 baseline: 0.167 acc 0.04 wl 0 train True
step 500 loss 0.010183007 baseline: 0.167 acc 0.44 wl 0 train True
step 550 loss 0.025499143 baseline: 0.167 acc 0.16 wl 0 train True
step 600 loss 0.009703096 baseline: 0.167 acc 0.4 wl 0 train True
step 650 loss 0.005455551 baseline: 0.167 acc 0.54 wl 0 train True
step 700 loss 0.0073964093 baseline: 0.167 acc 0.4 wl 0 train True
step 750 loss 0.008108932 baseline: 0.167 acc 0.28 wl 0 train True
step 800 loss 0.012449527 baseline: 0.167 acc 0.24 wl 0 train True
step 850 loss 0.0024416149 baseline: 0.167 acc 0.72 wl 0 train True
step 900 loss 0.032744423 baseline: 0.167 acc 0.0 wl 0 train True
step 950 loss 0.0031072926 baseline: 0.167 acc 0.64 wl 0 train True
step 1000 loss 0.005211228 baseline: 0.167 acc 0.34 wl 0 train True
step 1050 loss 0.008698184 baseline: 0.167 acc 0.26 wl 0 train True
step 1100 loss 0.008459441 baseline: 0.167 acc 0.16 wl 0 train True
step 1150 loss 0.008202868 baseline: 0.167 acc 0.3 wl 0 train True
step 1200 loss 0.006135291 baseline: 0.167 acc 0.48 wl 0 train True
step 1250 loss 0.0022551767 baseline: 0.167 acc 0.64 wl 0 train True
step 1300 loss 0.011376595 baseline: 0.167 acc 0.14 wl 0 train True
step 1350 loss 0.002817151 baseline: 0.167 acc 0.6 wl 0 train True
step 1400 loss 0.012268859 baseline: 0.167 acc 0.24 wl 0 train True
step 1450 loss 0.0010714652 baseline: 0.167 acc 0.86 wl 0 train True
step 1500 loss 0.0016036284 baseline: 0.167 acc 0.78 wl 0 train True
step 1550 loss 0.0023524412 baseline: 0.167 acc 0.72 wl 0 train True
step 1600 loss 0.0004826352 baseline: 0.167 acc 0.96 wl 0 train True
step 1650 loss 0.004850361 baseline: 0.167 acc 0.68 wl 0 train True
step 1700 loss 0.010584836 baseline: 0.167 acc 0.22 wl 0 train True
step 1750 loss 0.00039527108 baseline: 0.167 acc 1.0 wl 0 train True
step 1800 loss 0.00538964 baseline: 0.167 acc 0.3 wl 0 train True
step 1850 loss 0.005713811 baseline: 0.167 acc 0.28 wl 0 train True
step 1900 loss 0.0062206173 baseline: 0.167 acc 0.32 wl 0 train True
step 1950 loss 0.0018708173 baseline: 0.167 acc 0.82 wl 0 train True
step 2000 loss 0.004291037 baseline: 0.167 acc 0.4 wl 0 train True
step 2050 loss 0.0014866525 baseline: 0.167 acc 0.82 wl 0 train True
step 2100 loss 0.0013544324 baseline: 0.167 acc 0.8 wl 0 train True
step 2150 loss 0.00087041425 baseline: 0.167 acc 0.94 wl 0 train True
step 2200 loss 0.0004668518 baseline: 0.167 acc 0.98 wl 0 train True
step 2250 loss 0.0035989017 baseline: 0.167 acc 0.94 wl 0 train True
step 2300 loss 0.0006643288 baseline: 0.167 acc 0.98 wl 0 train True
step 2350 loss 0.0006583573 baseline: 0.167 acc 0.96 wl 0 train True
step 2400 loss 0.0040457305 baseline: 0.167 acc 0.5 wl 0 train True
step 2450 loss 0.0034883434 baseline: 0.167 acc 0.6 wl 0 train True
step 2500 loss 0.0018642426 baseline: 0.167 acc 0.72 wl 0 train True
step 2550 loss 0.002908974 baseline: 0.167 acc 0.56 wl 0 train True
step 2600 loss 0.007074554 baseline: 0.167 acc 0.4 wl 0 train True
step 2650 loss 0.004153916 baseline: 0.167 acc 0.46 wl 0 train True
step 2700 loss 0.0028420705 baseline: 0.167 acc 0.58 wl 0 train True
step 2750 loss 0.035020843 baseline: 0.167 acc 0.02 wl 0 train True
step 2800 loss 0.0021494678 baseline: 0.167 acc 0.82 wl 0 train True
step 2850 loss 0.004452406 baseline: 0.167 acc 0.38 wl 0 train True
step 2900 loss 0.0034533625 baseline: 0.167 acc 0.46 wl 0 train True
step 2950 loss 0.0009860791 baseline: 0.167 acc 0.88 wl 0 train True
step 3000 loss 0.0033633623 baseline: 0.167 acc 0.48 wl 0 train True
step 3050 loss 0.0036882597 baseline: 0.167 acc 0.4 wl 0 train True
step 3100 loss 0.0018823919 baseline: 0.167 acc 0.82 wl 0 train True
step 3150 loss 0.0006201982 baseline: 0.167 acc 0.96 wl 0 train True
step 3200 loss 0.00038113893 baseline: 0.167 acc 1.0 wl 0 train True
step 3250 loss 0.0028921363 baseline: 0.167 acc 0.52 wl 0 train True
step 3300 loss 0.0027964062 baseline: 0.167 acc 0.56 wl 0 train True
step 3350 loss 0.0038008937 baseline: 0.167 acc 0.52 wl 0 train True
step 3400 loss 0.0029704357 baseline: 0.167 acc 0.52 wl 0 train True
step 3450 loss 0.020231036 baseline: 0.167 acc 0.1 wl 0 train True
step 3500 loss 0.001684767 baseline: 0.167 acc 0.78 wl 0 train True
step 3550 loss 0.002513206 baseline: 0.167 acc 0.54 wl 0 train True
step 3600 loss 0.002909336 baseline: 0.167 acc 0.62 wl 0 train True
step 3650 loss 0.0020955831 baseline: 0.167 acc 0.78 wl 0 train True
step 3700 loss 0.0017752481 baseline: 0.167 acc 0.72 wl 0 train True
step 3750 loss 0.00059257814 baseline: 0.167 acc 0.96 wl 0 train True
step 3800 loss 0.003930208 baseline: 0.167 acc 0.44 wl 0 train True
step 3850 loss 0.003978527 baseline: 0.167 acc 0.32 wl 0 train True
step 3900 loss 0.016148021 baseline: 0.167 acc 0.02 wl 0 train True
step 3950 loss 0.0013058621 baseline: 0.167 acc 0.9 wl 0 train True
step 4000 loss 0.0023019263 baseline: 0.167 acc 0.64 wl 0 train True
step 4050 loss 0.0002761378 baseline: 0.167 acc 0.98 wl 0 train True
step 4100 loss 0.004511318 baseline: 0.167 acc 0.24 wl 0 train True
step 4150 loss 0.00051539 baseline: 0.167 acc 1.0 wl 0 train True
step 4200 loss 0.0023311349 baseline: 0.167 acc 0.66 wl 0 train True
step 4250 loss 0.0002845572 baseline: 0.167 acc 0.98 wl 0 train True
step 4300 loss 0.0065187113 baseline: 0.167 acc 0.24 wl 0 train True
step 4350 loss 0.00884181 baseline: 0.167 acc 0.0 wl 0 train True
step 4400 loss 0.0013743243 baseline: 0.167 acc 0.78 wl 0 train True
step 4450 loss 0.002897603 baseline: 0.167 acc 0.42 wl 0 train True
step 4500 loss 0.0075884424 baseline: 0.167 acc 0.08 wl 0 train True
step 4550 loss 0.0013011476 baseline: 0.167 acc 0.94 wl 0 train True
step 4600 loss 0.0047017424 baseline: 0.167 acc 0.42 wl 0 train True
step 4650 loss 0.0021194397 baseline: 0.167 acc 0.64 wl 0 train True
step 4700 loss 0.00022158823 baseline: 0.167 acc 1.0 wl 0 train True
step 4750 loss 0.00030962858 baseline: 0.167 acc 1.0 wl 0 train True
step 4800 loss 9.728605e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 4850 loss 0.008317203 baseline: 0.167 acc 0.26 wl 0 train True
step 4900 loss 0.002249799 baseline: 0.167 acc 0.66 wl 0 train True
step 4950 loss 0.00063507416 baseline: 0.167 acc 0.98 wl 0 train True
step 5000 loss 0.0010477216 baseline: 0.167 acc 0.92 wl 0 train True
step 5050 loss 0.0008727619 baseline: 0.167 acc 0.96 wl 0 train True
step 5100 loss 9.2465205e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 5150 loss 0.00014141858 baseline: 0.167 acc 1.0 wl 0 train True
step 5200 loss 0.00011630729 baseline: 0.167 acc 1.0 wl 0 train True
step 5250 loss 0.0013054983 baseline: 0.167 acc 0.94 wl 0 train True
step 5300 loss 0.00058089296 baseline: 0.167 acc 0.96 wl 0 train True
step 5350 loss 0.00041132778 baseline: 0.167 acc 0.98 wl 0 train True
step 5400 loss 0.00029061033 baseline: 0.167 acc 1.0 wl 0 train True
step 5450 loss 0.0009845538 baseline: 0.167 acc 0.96 wl 0 train True
step 5500 loss 0.00011372705 baseline: 0.167 acc 1.0 wl 0 train True
step 5550 loss 0.0001577163 baseline: 0.167 acc 1.0 wl 0 train True
step 5600 loss 0.00052014197 baseline: 0.167 acc 0.98 wl 0 train True
step 5650 loss 0.0018317428 baseline: 0.167 acc 0.76 wl 0 train True
step 5700 loss 0.00041519833 baseline: 0.167 acc 1.0 wl 0 train True
step 5750 loss 0.00015152623 baseline: 0.167 acc 1.0 wl 0 train True
step 5800 loss 0.0003094692 baseline: 0.167 acc 1.0 wl 0 train True
step 5850 loss 0.0018311241 baseline: 0.167 acc 0.66 wl 0 train True
step 5900 loss 0.00036554076 baseline: 0.167 acc 1.0 wl 0 train True
step 5950 loss 0.0001145703 baseline: 0.167 acc 1.0 wl 0 train True
step 6000 loss 0.0015812084 baseline: 0.167 acc 0.82 wl 0 train True
step 6050 loss 0.00035763904 baseline: 0.167 acc 1.0 wl 0 train True
step 6100 loss 0.00010880901 baseline: 0.167 acc 1.0 wl 0 train True
step 6150 loss 0.0002112525 baseline: 0.167 acc 1.0 wl 0 train True
step 6200 loss 0.0006569553 baseline: 0.167 acc 0.98 wl 0 train True
step 6250 loss 0.000111532194 baseline: 0.167 acc 1.0 wl 0 train True
step 6300 loss 0.00010504745 baseline: 0.167 acc 1.0 wl 0 train True
step 6350 loss 0.0068951654 baseline: 0.167 acc 0.16 wl 0 train True
step 6400 loss 0.000107256375 baseline: 0.167 acc 1.0 wl 0 train True
step 6450 loss 5.6723886e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 6500 loss 0.000102706625 baseline: 0.167 acc 1.0 wl 0 train True
step 6550 loss 0.00056547485 baseline: 0.167 acc 0.98 wl 0 train True
step 6600 loss 6.411422e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 6650 loss 0.00049835455 baseline: 0.167 acc 1.0 wl 0 train True
step 6700 loss 0.001242735 baseline: 0.167 acc 0.96 wl 0 train True
step 6750 loss 0.00025576068 baseline: 0.167 acc 1.0 wl 0 train True
step 6800 loss 7.432149e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 6850 loss 0.0001296195 baseline: 0.167 acc 1.0 wl 0 train True
step 6900 loss 0.00016678157 baseline: 0.167 acc 1.0 wl 0 train True
step 6950 loss 0.0004711359 baseline: 0.167 acc 0.94 wl 0 train True
step 7000 loss 0.0005548052 baseline: 0.167 acc 0.98 wl 0 train True
step 7050 loss 7.66368e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 7100 loss 0.000116707015 baseline: 0.167 acc 1.0 wl 0 train True
step 7150 loss 0.00019249847 baseline: 0.167 acc 1.0 wl 0 train True
step 7200 loss 0.0004426878 baseline: 0.167 acc 1.0 wl 0 train True
step 7250 loss 0.00054636446 baseline: 0.167 acc 1.0 wl 0 train True
step 7300 loss 6.2439445e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 7350 loss 0.0001063541 baseline: 0.167 acc 1.0 wl 0 train True
step 7400 loss 0.0006793256 baseline: 0.167 acc 0.96 wl 0 train True
step 7450 loss 0.00046256438 baseline: 0.167 acc 0.98 wl 0 train True
step 7500 loss 8.32109e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 7550 loss 0.00030020878 baseline: 0.167 acc 1.0 wl 0 train True
step 7600 loss 0.0008159839 baseline: 0.167 acc 0.96 wl 0 train True
step 7650 loss 0.00028039076 baseline: 0.167 acc 1.0 wl 0 train True
step 7700 loss 0.00026774243 baseline: 0.167 acc 1.0 wl 0 train True
step 7750 loss 0.002069021 baseline: 0.167 acc 0.64 wl 0 train True
step 7800 loss 0.0011460329 baseline: 0.167 acc 0.9 wl 0 train True
step 7850 loss 0.00018620816 baseline: 0.167 acc 0.98 wl 0 train True
step 7900 loss 8.04572e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 7950 loss 0.0070167696 baseline: 0.167 acc 0.06 wl 0 train True
step 8000 loss 0.00066220335 baseline: 0.167 acc 1.0 wl 0 train True
step 8050 loss 0.0021800122 baseline: 0.167 acc 0.66 wl 0 train True
step 8100 loss 0.0014873471 baseline: 0.167 acc 0.88 wl 0 train True
step 8150 loss 0.00090188277 baseline: 0.167 acc 0.9 wl 0 train True
step 8200 loss 0.000103036466 baseline: 0.167 acc 1.0 wl 0 train True
step 8250 loss 0.00019796964 baseline: 0.167 acc 1.0 wl 0 train True
step 8300 loss 0.00058712804 baseline: 0.167 acc 0.98 wl 0 train True
step 8350 loss 0.0031453357 baseline: 0.167 acc 0.48 wl 0 train True
step 8400 loss 0.0027680276 baseline: 0.167 acc 0.5 wl 0 train True
step 8450 loss 0.0006216653 baseline: 0.167 acc 1.0 wl 0 train True
step 8500 loss 0.00070287747 baseline: 0.167 acc 1.0 wl 0 train True
step 8550 loss 7.826492e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 8600 loss 9.043902e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 8650 loss 0.001161679 baseline: 0.167 acc 0.88 wl 0 train True
step 8700 loss 7.147235e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 8750 loss 0.00019725644 baseline: 0.167 acc 1.0 wl 0 train True
step 8800 loss 5.2627296e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 8850 loss 0.0012399218 baseline: 0.167 acc 0.88 wl 0 train True
step 8900 loss 0.0007356392 baseline: 0.167 acc 0.98 wl 0 train True
step 8950 loss 0.003616224 baseline: 0.167 acc 0.46 wl 0 train True
step 9000 loss 0.002801705 baseline: 0.167 acc 0.6 wl 0 train True
step 9050 loss 0.002009504 baseline: 0.167 acc 0.6 wl 0 train True
step 9100 loss 0.0031980085 baseline: 0.167 acc 0.34 wl 0 train True
step 9150 loss 0.00044536666 baseline: 0.167 acc 1.0 wl 0 train True
step 9200 loss 0.000112262496 baseline: 0.167 acc 0.98 wl 0 train True
step 9250 loss 0.00020933963 baseline: 0.167 acc 1.0 wl 0 train True
step 9300 loss 0.00016860224 baseline: 0.167 acc 1.0 wl 0 train True
step 9350 loss 9.5302574e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 9400 loss 0.0008248818 baseline: 0.167 acc 0.96 wl 0 train True
step 9450 loss 0.0013235769 baseline: 0.167 acc 0.94 wl 0 train True
step 9500 loss 0.001066981 baseline: 0.167 acc 0.92 wl 0 train True
step 9550 loss 0.0010306074 baseline: 0.167 acc 0.9 wl 0 train True
step 9600 loss 6.9710746e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 9650 loss 0.0016989815 baseline: 0.167 acc 0.74 wl 0 train True
step 9700 loss 0.011180951 baseline: 0.167 acc 0.04 wl 0 train True
step 9750 loss 6.214718e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 9800 loss 0.0005959623 baseline: 0.167 acc 0.98 wl 0 train True
step 9850 loss 2.3570146e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 9900 loss 6.797342e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 9950 loss 0.0007593373 baseline: 0.167 acc 0.98 wl 0 train True
step 10000 loss 0.00036873325 baseline: 0.167 acc 1.0 wl 0 train True
step 10050 loss 0.00070432085 baseline: 0.167 acc 0.98 wl 0 train True
step 10100 loss 0.008624795 baseline: 0.167 acc 0.14 wl 0 train True
step 10150 loss 7.044319e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 10200 loss 0.0017491541 baseline: 0.167 acc 0.74 wl 0 train True
step 10250 loss 0.0029217384 baseline: 0.167 acc 0.52 wl 0 train True
step 10300 loss 0.0068833623 baseline: 0.167 acc 0.3 wl 0 train True
step 10350 loss 6.589705e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 10400 loss 0.0013044053 baseline: 0.167 acc 0.9 wl 0 train True
step 10450 loss 0.0037464423 baseline: 0.167 acc 0.28 wl 0 train True
step 10500 loss 0.00021401062 baseline: 0.167 acc 1.0 wl 0 train True
step 10550 loss 8.483393e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 10600 loss 0.00013317086 baseline: 0.167 acc 1.0 wl 0 train True
step 10650 loss 9.212071e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 10700 loss 0.00040264346 baseline: 0.167 acc 1.0 wl 0 train True
step 10750 loss 0.00017826393 baseline: 0.167 acc 1.0 wl 0 train True
step 10800 loss 0.00034190193 baseline: 0.167 acc 1.0 wl 0 train True
step 10850 loss 0.00018336416 baseline: 0.167 acc 1.0 wl 0 train True
step 10900 loss 0.0002318896 baseline: 0.167 acc 1.0 wl 0 train True
step 10950 loss 4.0563584e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 11000 loss 0.002937811 baseline: 0.167 acc 0.52 wl 0 train True
step 11050 loss 0.00069417094 baseline: 0.167 acc 0.98 wl 0 train True
step 11100 loss 3.7606467e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 11150 loss 0.0007392041 baseline: 0.167 acc 0.98 wl 0 train True
step 11200 loss 0.0017453639 baseline: 0.167 acc 0.74 wl 0 train True
step 11250 loss 6.340822e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 11300 loss 0.0005863315 baseline: 0.167 acc 0.98 wl 0 train True
step 11350 loss 0.0008683941 baseline: 0.167 acc 0.96 wl 0 train True
step 11400 loss 0.00014237333 baseline: 0.167 acc 1.0 wl 0 train True
step 11450 loss 2.80681e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 11500 loss 5.234106e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 11550 loss 5.2196046e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 11600 loss 0.00011557732 baseline: 0.167 acc 1.0 wl 0 train True
step 11650 loss 0.00016325865 baseline: 0.167 acc 1.0 wl 0 train True
step 11700 loss 3.0264655e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 11750 loss 0.00027424924 baseline: 0.167 acc 1.0 wl 0 train True
step 11800 loss 5.738439e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 11850 loss 3.9172006e-05 baseline: 0.167 acc 1.0 wl 0 train True
step 11900 loss 0.00040116842 baseline: 0.167 acc 1.0 wl 0 train True
step 11950 loss 0.00037708067 baseline: 0.167 acc 1.0 wl 0 train True
training done... testing ...
step 0 loss 0.00059439935 baseline: 0.167 acc 0.96 wl 0 train False
step 50 loss 0.0004361702 baseline: 0.167 acc 1.0 wl 0 train False
step 100 loss 0.00043910072 baseline: 0.167 acc 1.0 wl 0 train False
step 150 loss 0.00048435625 baseline: 0.167 acc 1.0 wl 0 train False
test_el_total 10000 test_acc_sum 9923.0
test loss mean 0.00049120403 test acc mean 0.9923 pt 791553
time: 2020-01-06 17:11:34.067991 experiment took 3190.1697540283203 [s]

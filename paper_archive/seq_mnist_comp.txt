Namespace(batch_size=256, cell='WaveletGRU', clip=1, compression_mode='state_reset', epochs=100, hidden=58, lr=0.001, problem='MNIST', wave_dropout=0.0)
state+reset gate compression
wavelet dropout: 0.0
wavelet dropout: 0.0
Creating a Wavelet GRU, do not forget to add the wavelet-loss.
torch.Size([58, 58])
torch.Size([58, 1])
torch.Size([58])
torch.Size([58])
torch.Size([141])
torch.Size([58])
torch.Size([12])
torch.Size([12])
torch.Size([12])
torch.Size([12])
torch.Size([58, 1])
torch.Size([58])
torch.Size([58])
torch.Size([141])
torch.Size([58])
torch.Size([12])
torch.Size([12])
torch.Size([12])
torch.Size([12])
torch.Size([58, 1])
torch.Size([58])
torch.Size([10, 58])
torch.Size([10])
parameter total 4912
e 0 step 0 loss 2.3610427 acc 0.09375 wl 1.2142509e-13 train True
e 0 step 50 loss 2.2206469 acc 0.19140625 wl 0.00034851595 train True
e 0 step 100 loss 1.8795323 acc 0.29296875 wl 0.00387005 train True
e 0 step 150 loss 1.8045707 acc 0.375 wl 0.001548986 train True
e 0 step 200 loss 1.6753093 acc 0.3984375 wl 0.0019022566 train True
epoch 0 testing...
e -1 step 0 loss 1.8005944 acc 0.3203125 wl 0.0018524309 train False
test_true_total 3295.0 test_elements_total 10000
test loss mean 1.7721186 test acc 0.3295 pt 4912
e 1 step 250 loss 1.7081633 acc 0.37890625 wl 0.0022756264 train True
e 1 step 300 loss 1.5385178 acc 0.4140625 wl 0.0016334128 train True
e 1 step 350 loss 1.5488229 acc 0.38671875 wl 0.0016903841 train True
e 1 step 400 loss 1.6027117 acc 0.4140625 wl 0.0023504193 train True
e 1 step 450 loss 1.4357573 acc 0.41015625 wl 0.00232652 train True
e 2 step 500 loss 1.5737287 acc 0.4140625 wl 0.0021782096 train True
e 2 step 550 loss 1.4234363 acc 0.44921875 wl 0.0019606452 train True
e 2 step 600 loss 1.3570842 acc 0.48828125 wl 0.0015274197 train True
e 2 step 650 loss 1.3733807 acc 0.48046875 wl 0.0011943288 train True
e 2 step 700 loss 1.0678529 acc 0.58203125 wl 0.0014009398 train True
e 3 step 750 loss 1.3173465 acc 0.45703125 wl 0.0014676681 train True
e 3 step 800 loss 1.3423636 acc 0.44921875 wl 0.0009874749 train True
e 3 step 850 loss 1.2981125 acc 0.48046875 wl 0.0010611686 train True
e 3 step 900 loss 1.1879861 acc 0.53125 wl 0.00097213103 train True
e 4 step 950 loss 1.2441044 acc 0.4609375 wl 0.0015931608 train True
e 4 step 1000 loss 1.2106159 acc 0.52734375 wl 0.0016274876 train True
e 4 step 1050 loss 1.1723946 acc 0.57421875 wl 0.0023945337 train True
e 4 step 1100 loss 1.1472895 acc 0.53515625 wl 0.0029145048 train True
e 4 step 1150 loss 0.9533357 acc 0.62109375 wl 0.003897436 train True
e 5 step 1200 loss 0.9300939 acc 0.6953125 wl 0.0032364682 train True
e 5 step 1250 loss 0.9460524 acc 0.703125 wl 0.0039073266 train True
e 5 step 1300 loss 1.0130463 acc 0.67578125 wl 0.0030052653 train True
e 5 step 1350 loss 0.98971057 acc 0.6328125 wl 0.0032945236 train True
e 5 step 1400 loss 0.8931374 acc 0.66796875 wl 0.0038482905 train True
e 6 step 1450 loss 0.9693301 acc 0.66796875 wl 0.003726114 train True
e 6 step 1500 loss 0.9493958 acc 0.66015625 wl 0.0042882296 train True
e 6 step 1550 loss 0.9031846 acc 0.703125 wl 0.003789149 train True
e 6 step 1600 loss 0.760693 acc 0.75 wl 0.0039274963 train True
e 7 step 1650 loss 0.83392256 acc 0.7109375 wl 0.00348543 train True
e 7 step 1700 loss 0.9605467 acc 0.6796875 wl 0.0041428367 train True
e 7 step 1750 loss 0.66701955 acc 0.73828125 wl 0.004309568 train True
e 7 step 1800 loss 0.7833446 acc 0.69921875 wl 0.0041024154 train True
e 7 step 1850 loss 0.70677745 acc 0.765625 wl 0.003596662 train True
e 8 step 1900 loss 0.73056287 acc 0.75390625 wl 0.0036186918 train True
e 8 step 1950 loss 0.5894611 acc 0.76953125 wl 0.0041508726 train True
e 8 step 2000 loss 0.6089602 acc 0.77734375 wl 0.0034949696 train True
e 8 step 2050 loss 0.672024 acc 0.7734375 wl 0.0035987813 train True
e 8 step 2100 loss 0.5634973 acc 0.81640625 wl 0.0035949317 train True
e 9 step 2150 loss 0.52366614 acc 0.84375 wl 0.003601843 train True
e 9 step 2200 loss 0.6871034 acc 0.74609375 wl 0.0035036455 train True
e 9 step 2250 loss 0.73207927 acc 0.75 wl 0.0029299455 train True
e 9 step 2300 loss 0.7363124 acc 0.76171875 wl 0.0028591347 train True
e 10 step 2350 loss 0.6410209 acc 0.80859375 wl 0.0020269006 train True
e 10 step 2400 loss 0.6462466 acc 0.7734375 wl 0.0021696712 train True
e 10 step 2450 loss 0.5644532 acc 0.80078125 wl 0.0025354277 train True
e 10 step 2500 loss 0.5629418 acc 0.8046875 wl 0.002469017 train True
e 10 step 2550 loss 0.55841297 acc 0.77734375 wl 0.002392292 train True
epoch 10 testing...
e -1 step 0 loss 0.8354167 acc 0.734375 wl 0.00186084 train False
test_true_total 7898.0 test_elements_total 10000
test loss mean 0.61101854 test acc 0.7898 pt 4912
e 11 step 2600 loss 0.52734077 acc 0.8046875 wl 0.0018836824 train True
e 11 step 2650 loss 0.49288103 acc 0.88671875 wl 0.0018849779 train True
e 11 step 2700 loss 0.55541825 acc 0.80078125 wl 0.0019177548 train True
e 11 step 2750 loss 0.64034235 acc 0.75390625 wl 0.0018527979 train True
e 11 step 2800 loss 0.51785123 acc 0.85546875 wl 0.001973608 train True
e 12 step 2850 loss 0.53935546 acc 0.8359375 wl 0.0017585673 train True
e 12 step 2900 loss 0.47000098 acc 0.83203125 wl 0.0022577848 train True
e 12 step 2950 loss 0.5209416 acc 0.828125 wl 0.001508607 train True
e 12 step 3000 loss 0.6165683 acc 0.7734375 wl 0.0017547122 train True
e 12 step 3050 loss 0.23002404 acc 0.9140625 wl 0.0015772249 train True
e 13 step 3100 loss 0.75230217 acc 0.74609375 wl 0.0017236661 train True
e 13 step 3150 loss 0.5785271 acc 0.828125 wl 0.0017189578 train True
e 13 step 3200 loss 0.66079193 acc 0.7734375 wl 0.0014801074 train True
e 13 step 3250 loss 0.36759624 acc 0.8671875 wl 0.00192864 train True
e 14 step 3300 loss 0.3947997 acc 0.87109375 wl 0.0013441892 train True
e 14 step 3350 loss 0.48472467 acc 0.828125 wl 0.0017476985 train True
e 14 step 3400 loss 0.63281715 acc 0.78515625 wl 0.0015317566 train True
e 14 step 3450 loss 0.49036202 acc 0.8046875 wl 0.0014416962 train True
e 14 step 3500 loss 0.57211065 acc 0.796875 wl 0.0017951623 train True
e 15 step 3550 loss 0.39522812 acc 0.875 wl 0.0012422227 train True
e 15 step 3600 loss 0.49323314 acc 0.8515625 wl 0.0016354921 train True
e 15 step 3650 loss 0.44622484 acc 0.84375 wl 0.0013635386 train True
e 15 step 3700 loss 0.58769304 acc 0.7890625 wl 0.00094845874 train True
e 15 step 3750 loss 0.5276712 acc 0.80078125 wl 0.001188345 train True
e 16 step 3800 loss 0.49289098 acc 0.80078125 wl 0.0013346327 train True
e 16 step 3850 loss 0.5012208 acc 0.83984375 wl 0.0011916807 train True
e 16 step 3900 loss 0.45870873 acc 0.84375 wl 0.0011540556 train True
e 16 step 3950 loss 0.5285277 acc 0.83203125 wl 0.0011872047 train True
e 17 step 4000 loss 0.43516725 acc 0.84765625 wl 0.0011430074 train True
e 17 step 4050 loss 0.5323121 acc 0.8359375 wl 0.0013690868 train True
e 17 step 4100 loss 0.41640732 acc 0.85546875 wl 0.0009781249 train True
e 17 step 4150 loss 0.4112289 acc 0.87890625 wl 0.0011603882 train True
e 17 step 4200 loss 0.4191305 acc 0.8984375 wl 0.0007326207 train True
e 18 step 4250 loss 0.41861174 acc 0.8671875 wl 0.0007209847 train True
e 18 step 4300 loss 0.3838674 acc 0.86328125 wl 0.0010852098 train True
e 18 step 4350 loss 0.37764615 acc 0.8828125 wl 0.0012792428 train True
e 18 step 4400 loss 0.41481644 acc 0.86328125 wl 0.0010912952 train True
e 18 step 4450 loss 0.32959706 acc 0.9140625 wl 0.00071514596 train True
e 19 step 4500 loss 0.24327444 acc 0.8984375 wl 0.0008343333 train True
e 19 step 4550 loss 0.3264031 acc 0.8671875 wl 0.001233367 train True
e 19 step 4600 loss 0.4664263 acc 0.8671875 wl 0.0013901613 train True
e 19 step 4650 loss 0.4598625 acc 0.86328125 wl 0.0008225667 train True
e 20 step 4700 loss 0.36853775 acc 0.89453125 wl 0.0009818454 train True
e 20 step 4750 loss 0.5173753 acc 0.83984375 wl 0.0011593619 train True
e 20 step 4800 loss 0.3728847 acc 0.8671875 wl 0.0007617125 train True
e 20 step 4850 loss 0.37280017 acc 0.8828125 wl 0.00082770584 train True
e 20 step 4900 loss 0.32776147 acc 0.87890625 wl 0.0010614556 train True
epoch 20 testing...
e -1 step 0 loss 0.55218035 acc 0.78515625 wl 0.0012293892 train False
test_true_total 8550.0 test_elements_total 10000
test loss mean 0.41051492 test acc 0.855 pt 4912
e 21 step 4950 loss 0.2963492 acc 0.8828125 wl 0.0006679354 train True
e 21 step 5000 loss 0.36834028 acc 0.890625 wl 0.0010810763 train True
e 21 step 5050 loss 0.3716619 acc 0.8359375 wl 0.000915829 train True
e 21 step 5100 loss 0.45962766 acc 0.82421875 wl 0.001430097 train True
e 21 step 5150 loss 0.35377386 acc 0.89453125 wl 0.00075329334 train True
e 22 step 5200 loss 0.45861006 acc 0.828125 wl 0.0008360533 train True
e 22 step 5250 loss 0.26246926 acc 0.90234375 wl 0.00070414273 train True
e 22 step 5300 loss 0.3769695 acc 0.875 wl 0.0009804968 train True
e 22 step 5350 loss 0.5023106 acc 0.83984375 wl 0.00060602906 train True
e 22 step 5400 loss 0.10933426 acc 0.98046875 wl 0.00065167 train True
e 23 step 5450 loss 0.54857576 acc 0.8046875 wl 0.0008377741 train True
e 23 step 5500 loss 0.42297226 acc 0.8671875 wl 0.0008898857 train True
e 23 step 5550 loss 0.492494 acc 0.84765625 wl 0.00087926246 train True
e 23 step 5600 loss 0.2825779 acc 0.890625 wl 0.000999119 train True
e 24 step 5650 loss 0.31450036 acc 0.8828125 wl 0.0007885263 train True
e 24 step 5700 loss 0.33507273 acc 0.8984375 wl 0.0007188147 train True
e 24 step 5750 loss 0.45198083 acc 0.8515625 wl 0.0008129447 train True
e 24 step 5800 loss 0.3974508 acc 0.84375 wl 0.0007574754 train True
e 24 step 5850 loss 0.30135491 acc 0.87890625 wl 0.0008251226 train True
e 25 step 5900 loss 0.3160341 acc 0.91015625 wl 0.00081253645 train True
e 25 step 5950 loss 0.3285956 acc 0.87890625 wl 0.001250687 train True
e 25 step 6000 loss 0.35322347 acc 0.87890625 wl 0.0010391113 train True
e 25 step 6050 loss 0.4129538 acc 0.85546875 wl 0.0009977678 train True
e 25 step 6100 loss 0.4416289 acc 0.86328125 wl 0.0008177203 train True
e 26 step 6150 loss 0.4353549 acc 0.8515625 wl 0.0010637974 train True
e 26 step 6200 loss 0.2972105 acc 0.91015625 wl 0.0008948927 train True
e 26 step 6250 loss 0.32374883 acc 0.8671875 wl 0.0010917975 train True
e 26 step 6300 loss 0.3600013 acc 0.875 wl 0.0009868565 train True
e 27 step 6350 loss 0.33192107 acc 0.90234375 wl 0.00072393555 train True
e 27 step 6400 loss 0.38325483 acc 0.87890625 wl 0.00081229466 train True
e 27 step 6450 loss 0.3064038 acc 0.8671875 wl 0.00078122324 train True
e 27 step 6500 loss 0.30481407 acc 0.87890625 wl 0.0009896635 train True
e 27 step 6550 loss 0.31474665 acc 0.9375 wl 0.00091904926 train True
e 28 step 6600 loss 0.28917855 acc 0.9140625 wl 0.0008416211 train True
e 28 step 6650 loss 0.25880173 acc 0.91796875 wl 0.0015859632 train True
e 28 step 6700 loss 0.2929676 acc 0.91015625 wl 0.00090677175 train True
e 28 step 6750 loss 0.30304533 acc 0.921875 wl 0.00074138027 train True
e 28 step 6800 loss 0.29927176 acc 0.91015625 wl 0.0009465781 train True
e 29 step 6850 loss 0.19858487 acc 0.9375 wl 0.00081760203 train True
e 29 step 6900 loss 0.26303658 acc 0.9140625 wl 0.0010023442 train True
e 29 step 6950 loss 0.3968579 acc 0.8671875 wl 0.0013418316 train True
e 29 step 7000 loss 0.43024915 acc 0.86328125 wl 0.000906371 train True
e 30 step 7050 loss 0.2680844 acc 0.9296875 wl 0.0012851009 train True
e 30 step 7100 loss 0.3377159 acc 0.890625 wl 0.0010217562 train True
e 30 step 7150 loss 0.28882518 acc 0.9140625 wl 0.0012137864 train True
e 30 step 7200 loss 0.2701702 acc 0.9140625 wl 0.00084916514 train True
e 30 step 7250 loss 0.21851107 acc 0.9375 wl 0.0010783654 train True
epoch 30 testing...
e -1 step 0 loss 0.3512952 acc 0.875 wl 0.0013832409 train False
test_true_total 8958.0 test_elements_total 10000
test loss mean 0.31109613 test acc 0.8958 pt 4912
e 31 step 7300 loss 0.23494045 acc 0.90625 wl 0.001230217 train True
e 31 step 7350 loss 0.26399574 acc 0.921875 wl 0.001185456 train True
e 31 step 7400 loss 0.2740736 acc 0.90625 wl 0.0012951529 train True
e 31 step 7450 loss 0.3864159 acc 0.85546875 wl 0.0012567481 train True
e 31 step 7500 loss 0.26314548 acc 0.921875 wl 0.001075886 train True
e 32 step 7550 loss 0.23406632 acc 0.9140625 wl 0.0008693447 train True
e 32 step 7600 loss 0.20397232 acc 0.9296875 wl 0.0009457968 train True
e 32 step 7650 loss 0.24975893 acc 0.91796875 wl 0.0012012627 train True
e 32 step 7700 loss 0.43180367 acc 0.89453125 wl 0.0010432483 train True
e 32 step 7750 loss 0.062082715 acc 0.98828125 wl 0.0010477647 train True
e 33 step 7800 loss 0.4651039 acc 0.8515625 wl 0.001180408 train True
e 33 step 7850 loss 0.32713693 acc 0.890625 wl 0.0012956884 train True
e 33 step 7900 loss 0.33938414 acc 0.88671875 wl 0.0009666368 train True
e 33 step 7950 loss 0.1475124 acc 0.9609375 wl 0.0010620647 train True
e 34 step 8000 loss 0.24432497 acc 0.9140625 wl 0.00090414775 train True
e 34 step 8050 loss 0.21623394 acc 0.93359375 wl 0.0011250635 train True
e 34 step 8100 loss 0.32422578 acc 0.8828125 wl 0.0010222793 train True
e 34 step 8150 loss 0.23151553 acc 0.94140625 wl 0.00095980556 train True
e 34 step 8200 loss 0.17984517 acc 0.94921875 wl 0.0010990076 train True
e 35 step 8250 loss 0.22220637 acc 0.93359375 wl 0.0010048464 train True
e 35 step 8300 loss 0.28744707 acc 0.9140625 wl 0.0010984227 train True
e 35 step 8350 loss 0.24220616 acc 0.90625 wl 0.0009533482 train True
e 35 step 8400 loss 0.28800824 acc 0.91796875 wl 0.0010103638 train True
e 35 step 8450 loss 0.32901275 acc 0.890625 wl 0.0011021681 train True
e 36 step 8500 loss 0.24079663 acc 0.91796875 wl 0.00101263 train True
e 36 step 8550 loss 0.30852142 acc 0.91015625 wl 0.0009197609 train True
e 36 step 8600 loss 0.22029077 acc 0.92578125 wl 0.00092587725 train True
e 36 step 8650 loss 0.24840127 acc 0.9375 wl 0.000977502 train True
e 37 step 8700 loss 0.27314574 acc 0.91015625 wl 0.0012405637 train True
e 37 step 8750 loss 0.23707217 acc 0.92578125 wl 0.0011044653 train True
e 37 step 8800 loss 0.20662221 acc 0.93359375 wl 0.0014126549 train True
e 37 step 8850 loss 0.20729615 acc 0.94921875 wl 0.0008798474 train True
e 37 step 8900 loss 0.22482902 acc 0.94921875 wl 0.0011167269 train True
e 38 step 8950 loss 0.34483933 acc 0.91015625 wl 0.00095090095 train True
e 38 step 9000 loss 0.10167613 acc 0.96875 wl 0.00080811157 train True
e 38 step 9050 loss 0.16793373 acc 0.953125 wl 0.00091719226 train True
e 38 step 9100 loss 0.20086274 acc 0.94921875 wl 0.0007849403 train True
e 38 step 9150 loss 0.2335867 acc 0.94140625 wl 0.0007905463 train True
e 39 step 9200 loss 0.10605229 acc 0.96484375 wl 0.0009521192 train True
e 39 step 9250 loss 0.15551648 acc 0.953125 wl 0.0008393573 train True
e 39 step 9300 loss 0.28745833 acc 0.921875 wl 0.0008061994 train True
e 39 step 9350 loss 0.29785237 acc 0.9140625 wl 0.00088582095 train True
e 40 step 9400 loss 0.19667362 acc 0.9453125 wl 0.0010100082 train True
e 40 step 9450 loss 0.24006295 acc 0.9375 wl 0.0012266134 train True
e 40 step 9500 loss 0.1816158 acc 0.95703125 wl 0.0013585361 train True
e 40 step 9550 loss 0.13266549 acc 0.953125 wl 0.00093027327 train True
e 40 step 9600 loss 0.1817483 acc 0.95703125 wl 0.0010026908 train True
epoch 40 testing...
e -1 step 0 loss 0.23142539 acc 0.92578125 wl 0.0010527674 train False
test_true_total 9377.0 test_elements_total 10000
test loss mean 0.20719619 test acc 0.9377 pt 4912
e 41 step 9650 loss 0.14182866 acc 0.95703125 wl 0.00095182366 train True
e 41 step 9700 loss 0.17606568 acc 0.95703125 wl 0.00072684884 train True
e 41 step 9750 loss 0.17256197 acc 0.953125 wl 0.0008814961 train True
e 41 step 9800 loss 0.17113933 acc 0.9375 wl 0.0006906344 train True
e 41 step 9850 loss 0.2268369 acc 0.94140625 wl 0.00091933773 train True
e 42 step 9900 loss 0.1484299 acc 0.9453125 wl 0.00075956935 train True
e 42 step 9950 loss 0.14696151 acc 0.95703125 wl 0.0008931561 train True
e 42 step 10000 loss 0.20973775 acc 0.94140625 wl 0.0008866946 train True
e 42 step 10050 loss 0.25264442 acc 0.93359375 wl 0.00091985095 train True
e 42 step 10100 loss 0.04132851 acc 0.9921875 wl 0.0008721483 train True
e 43 step 10150 loss 0.35305306 acc 0.875 wl 0.0008178462 train True
e 43 step 10200 loss 0.19692944 acc 0.93359375 wl 0.00073119777 train True
e 43 step 10250 loss 0.21521398 acc 0.9296875 wl 0.00056086504 train True
e 43 step 10300 loss 0.08656851 acc 0.9765625 wl 0.0009219161 train True
e 44 step 10350 loss 0.15179528 acc 0.94921875 wl 0.0007545523 train True
e 44 step 10400 loss 0.15533057 acc 0.94140625 wl 0.0006981524 train True
e 44 step 10450 loss 0.21961145 acc 0.94921875 wl 0.0007627262 train True
e 44 step 10500 loss 0.14399646 acc 0.9453125 wl 0.00072639517 train True
e 44 step 10550 loss 0.14803913 acc 0.9609375 wl 0.0009785733 train True
e 45 step 10600 loss 0.15299053 acc 0.94921875 wl 0.00079108926 train True
e 45 step 10650 loss 0.17113657 acc 0.9375 wl 0.0007768586 train True
e 45 step 10700 loss 0.16556548 acc 0.94921875 wl 0.0008138408 train True
e 45 step 10750 loss 0.2059485 acc 0.9375 wl 0.0006449934 train True
e 45 step 10800 loss 0.2658237 acc 0.91015625 wl 0.00089999527 train True
e 46 step 10850 loss 0.15784283 acc 0.9453125 wl 0.0007446377 train True
e 46 step 10900 loss 0.25245202 acc 0.9296875 wl 0.0005482937 train True
e 46 step 10950 loss 0.13482858 acc 0.9609375 wl 0.00046827854 train True
e 46 step 11000 loss 0.1541948 acc 0.953125 wl 0.0008923199 train True
e 47 step 11050 loss 0.16940928 acc 0.9453125 wl 0.0008837837 train True
e 47 step 11100 loss 0.13181067 acc 0.95703125 wl 0.00068346027 train True
e 47 step 11150 loss 0.10952002 acc 0.9609375 wl 0.0009871824 train True
e 47 step 11200 loss 0.117044166 acc 0.9609375 wl 0.0007527108 train True
e 47 step 11250 loss 0.16870944 acc 0.953125 wl 0.00056523393 train True
e 48 step 11300 loss 0.27329317 acc 0.9375 wl 0.0008566226 train True
e 48 step 11350 loss 0.070939995 acc 0.98828125 wl 0.0007563895 train True
e 48 step 11400 loss 0.10957162 acc 0.9609375 wl 0.0009036904 train True
e 48 step 11450 loss 0.11834781 acc 0.97265625 wl 0.00061970635 train True
e 48 step 11500 loss 0.17075619 acc 0.953125 wl 0.000565698 train True
e 49 step 11550 loss 0.109130144 acc 0.97265625 wl 0.00068567187 train True
e 49 step 11600 loss 0.11350318 acc 0.9609375 wl 0.00066905434 train True
e 49 step 11650 loss 0.1930853 acc 0.9453125 wl 0.000705704 train True
e 49 step 11700 loss 0.24388506 acc 0.9140625 wl 0.0006587746 train True
e 50 step 11750 loss 0.11968134 acc 0.97265625 wl 0.0007838453 train True
e 50 step 11800 loss 0.17118159 acc 0.94140625 wl 0.0010491202 train True
e 50 step 11850 loss 0.14685206 acc 0.95703125 wl 0.00091625156 train True
e 50 step 11900 loss 0.11697683 acc 0.96875 wl 0.0006485464 train True
e 50 step 11950 loss 0.12962523 acc 0.9609375 wl 0.0007772872 train True
epoch 50 testing...
e -1 step 0 loss 0.1545813 acc 0.9453125 wl 0.0006540981 train False
test_true_total 9445.0 test_elements_total 10000
test loss mean 0.18729556 test acc 0.9445 pt 4912
e 51 step 12000 loss 0.08343949 acc 0.9609375 wl 0.0013589257 train True
e 51 step 12050 loss 0.12382029 acc 0.97265625 wl 0.00065497996 train True
e 51 step 12100 loss 0.14169353 acc 0.96875 wl 0.0009000009 train True
e 51 step 12150 loss 0.11026822 acc 0.96875 wl 0.00044726807 train True
e 51 step 12200 loss 0.14770591 acc 0.95703125 wl 0.0007878707 train True
e 52 step 12250 loss 0.10686889 acc 0.96484375 wl 0.0005716166 train True
e 52 step 12300 loss 0.14025022 acc 0.953125 wl 0.0005956729 train True
e 52 step 12350 loss 0.16041213 acc 0.96875 wl 0.0005241052 train True
e 52 step 12400 loss 0.20274027 acc 0.9375 wl 0.0009708764 train True
e 52 step 12450 loss 0.015517859 acc 1.0 wl 0.0005681168 train True
e 53 step 12500 loss 0.30883718 acc 0.88671875 wl 0.00057416304 train True
e 53 step 12550 loss 0.16894424 acc 0.953125 wl 0.0010325215 train True
e 53 step 12600 loss 0.12914106 acc 0.96484375 wl 0.00041613058 train True
e 53 step 12650 loss 0.08744584 acc 0.97265625 wl 0.0004101204 train True
e 54 step 12700 loss 0.114904776 acc 0.96484375 wl 0.00080501917 train True
e 54 step 12750 loss 0.121950164 acc 0.953125 wl 0.000602253 train True
e 54 step 12800 loss 0.19409832 acc 0.9453125 wl 0.0004888551 train True
e 54 step 12850 loss 0.10711814 acc 0.95703125 wl 0.0007193077 train True
e 54 step 12900 loss 0.16662836 acc 0.9609375 wl 0.00052877376 train True
e 55 step 12950 loss 0.12850332 acc 0.9765625 wl 0.00075983605 train True
e 55 step 13000 loss 0.15289499 acc 0.9453125 wl 0.0005917632 train True
e 55 step 13050 loss 0.1363567 acc 0.95703125 wl 0.000893897 train True
e 55 step 13100 loss 0.15806162 acc 0.94140625 wl 0.00051826204 train True
e 55 step 13150 loss 0.21602657 acc 0.921875 wl 0.00043044332 train True
e 56 step 13200 loss 0.12043944 acc 0.96484375 wl 0.0012119146 train True
e 56 step 13250 loss 0.14524995 acc 0.94921875 wl 0.00046692806 train True
e 56 step 13300 loss 0.084365696 acc 0.98046875 wl 0.0006725446 train True
e 56 step 13350 loss 0.1290699 acc 0.97265625 wl 0.00083964283 train True
e 57 step 13400 loss 0.15106562 acc 0.953125 wl 0.0005080983 train True
e 57 step 13450 loss 0.109147236 acc 0.96484375 wl 0.00072203926 train True
e 57 step 13500 loss 0.097804256 acc 0.9609375 wl 0.0007554117 train True
e 57 step 13550 loss 0.13354753 acc 0.9609375 wl 0.00042818655 train True
e 57 step 13600 loss 0.119672544 acc 0.96484375 wl 0.00044052897 train True
e 58 step 13650 loss 0.20215736 acc 0.94921875 wl 0.0007130664 train True
e 58 step 13700 loss 0.05296912 acc 0.98828125 wl 0.0004962127 train True
e 58 step 13750 loss 0.09702551 acc 0.96484375 wl 0.0007092976 train True
e 58 step 13800 loss 0.13043332 acc 0.96484375 wl 0.00054151774 train True
e 58 step 13850 loss 0.16590041 acc 0.94921875 wl 0.00047468592 train True
e 59 step 13900 loss 0.08032811 acc 0.98828125 wl 0.00090863457 train True
e 59 step 13950 loss 0.08445689 acc 0.9765625 wl 0.0006408606 train True
e 59 step 14000 loss 0.15131274 acc 0.953125 wl 0.0006976103 train True
e 59 step 14050 loss 0.2308162 acc 0.93359375 wl 0.0008781954 train True
e 60 step 14100 loss 0.11263125 acc 0.96875 wl 0.0005883542 train True
e 60 step 14150 loss 0.17449568 acc 0.9453125 wl 0.0010581198 train True
e 60 step 14200 loss 0.11679977 acc 0.98046875 wl 0.0006580476 train True
e 60 step 14250 loss 0.083606586 acc 0.9765625 wl 0.00048183562 train True
e 60 step 14300 loss 0.13294224 acc 0.96875 wl 0.00076522736 train True
epoch 60 testing...
e -1 step 0 loss 0.13111624 acc 0.953125 wl 0.00061001413 train False
test_true_total 9502.0 test_elements_total 10000
test loss mean 0.17093001 test acc 0.9502 pt 4912
e 61 step 14350 loss 0.062961414 acc 0.9765625 wl 0.0006766502 train True
e 61 step 14400 loss 0.11052455 acc 0.97265625 wl 0.0006509648 train True
e 61 step 14450 loss 0.12106839 acc 0.96484375 wl 0.00061144575 train True
e 61 step 14500 loss 0.14103477 acc 0.953125 wl 0.00037793198 train True
e 61 step 14550 loss 0.12464771 acc 0.97265625 wl 0.00045894686 train True
e 62 step 14600 loss 0.10419067 acc 0.9609375 wl 0.0005842182 train True
e 62 step 14650 loss 0.11393553 acc 0.9609375 wl 0.0006116978 train True
e 62 step 14700 loss 0.12363193 acc 0.97265625 wl 0.00042306914 train True
e 62 step 14750 loss 0.13007347 acc 0.96484375 wl 0.0007949185 train True
e 62 step 14800 loss 0.017666783 acc 0.9921875 wl 0.0005010622 train True
e 63 step 14850 loss 0.20268884 acc 0.9140625 wl 0.00065531716 train True
e 63 step 14900 loss 0.16099563 acc 0.94921875 wl 0.0014389777 train True
e 63 step 14950 loss 0.09591454 acc 0.96875 wl 0.00033935183 train True
e 63 step 15000 loss 0.06364181 acc 0.9765625 wl 0.000687983 train True
e 64 step 15050 loss 0.09981261 acc 0.97265625 wl 0.0007333836 train True
e 64 step 15100 loss 0.10853518 acc 0.95703125 wl 0.000774067 train True
e 64 step 15150 loss 0.15349233 acc 0.953125 wl 0.0005316926 train True
e 64 step 15200 loss 0.09143835 acc 0.96484375 wl 0.0007849626 train True
e 64 step 15250 loss 0.12625512 acc 0.96484375 wl 0.0006447494 train True
e 65 step 15300 loss 0.1334513 acc 0.95703125 wl 0.000694676 train True
e 65 step 15350 loss 0.1411387 acc 0.96484375 wl 0.00074101216 train True
e 65 step 15400 loss 0.08878629 acc 0.96875 wl 0.0007428907 train True
e 65 step 15450 loss 0.13921762 acc 0.95703125 wl 0.00040236715 train True
e 65 step 15500 loss 0.21076813 acc 0.9375 wl 0.0004128017 train True
e 66 step 15550 loss 0.123710886 acc 0.96875 wl 0.0008901301 train True
e 66 step 15600 loss 0.120639876 acc 0.95703125 wl 0.00035910137 train True
e 66 step 15650 loss 0.07143732 acc 0.97265625 wl 0.0006119008 train True
e 66 step 15700 loss 0.0970957 acc 0.97265625 wl 0.00059976475 train True
e 67 step 15750 loss 0.13352951 acc 0.96484375 wl 0.000599105 train True
e 67 step 15800 loss 0.093737476 acc 0.95703125 wl 0.00088742666 train True
e 67 step 15850 loss 0.07668237 acc 0.96875 wl 0.0007637596 train True
e 67 step 15900 loss 0.09275723 acc 0.97265625 wl 0.0005524857 train True
e 67 step 15950 loss 0.11213854 acc 0.96484375 wl 0.0005418403 train True
e 68 step 16000 loss 0.29180667 acc 0.93359375 wl 0.00080779253 train True
e 68 step 16050 loss 0.07842782 acc 0.9765625 wl 0.00045907823 train True
e 68 step 16100 loss 0.08659609 acc 0.96875 wl 0.0006898007 train True
e 68 step 16150 loss 0.110402286 acc 0.97265625 wl 0.0004353023 train True
e 68 step 16200 loss 0.16521074 acc 0.9609375 wl 0.00039164827 train True
e 69 step 16250 loss 0.08054794 acc 0.984375 wl 0.00048611945 train True
e 69 step 16300 loss 0.06387977 acc 0.98046875 wl 0.00056129746 train True
e 69 step 16350 loss 0.18648498 acc 0.93359375 wl 0.0007627051 train True
e 69 step 16400 loss 0.18873806 acc 0.94140625 wl 0.0007233833 train True
e 70 step 16450 loss 0.10274561 acc 0.96484375 wl 0.00044521855 train True
e 70 step 16500 loss 0.16496857 acc 0.9453125 wl 0.00066708634 train True
e 70 step 16550 loss 0.12477748 acc 0.96484375 wl 0.00067403936 train True
e 70 step 16600 loss 0.06937517 acc 0.98046875 wl 0.0006321967 train True
e 70 step 16650 loss 0.106434524 acc 0.97265625 wl 0.00071195257 train True
epoch 70 testing...
e -1 step 0 loss 0.10026036 acc 0.95703125 wl 0.00064470293 train False
test_true_total 9526.0 test_elements_total 10000
test loss mean 0.16033909 test acc 0.9526 pt 4912
e 71 step 16700 loss 0.063395165 acc 0.97265625 wl 0.0007124442 train True
e 71 step 16750 loss 0.09616713 acc 0.9765625 wl 0.0004380523 train True
e 71 step 16800 loss 0.09082002 acc 0.96875 wl 0.0006147151 train True
e 71 step 16850 loss 0.077202134 acc 0.984375 wl 0.000491882 train True
e 71 step 16900 loss 0.103157 acc 0.96875 wl 0.00040141295 train True
e 72 step 16950 loss 0.073234715 acc 0.9765625 wl 0.00044781907 train True
e 72 step 17000 loss 0.112732895 acc 0.96484375 wl 0.0006367246 train True
e 72 step 17050 loss 0.09382951 acc 0.97265625 wl 0.0005153116 train True
e 72 step 17100 loss 0.10207075 acc 0.9609375 wl 0.0005016507 train True
e 72 step 17150 loss 0.0097302925 acc 1.0 wl 0.0005408745 train True
e 73 step 17200 loss 0.16765007 acc 0.9453125 wl 0.0006157501 train True
e 73 step 17250 loss 0.13562423 acc 0.95703125 wl 0.0010768593 train True
e 73 step 17300 loss 0.07332246 acc 0.98046875 wl 0.0005238181 train True
e 73 step 17350 loss 0.047116168 acc 0.98046875 wl 0.00055821275 train True
e 74 step 17400 loss 0.11267119 acc 0.97265625 wl 0.00086810207 train True
e 74 step 17450 loss 0.09331223 acc 0.96484375 wl 0.0008957779 train True
e 74 step 17500 loss 0.12837653 acc 0.9609375 wl 0.0006522124 train True
e 74 step 17550 loss 0.07946303 acc 0.96875 wl 0.0007427323 train True
e 74 step 17600 loss 0.10287581 acc 0.96484375 wl 0.00061148126 train True
e 75 step 17650 loss 0.11278896 acc 0.97265625 wl 0.00063117134 train True
e 75 step 17700 loss 0.11181071 acc 0.9609375 wl 0.00042304976 train True
e 75 step 17750 loss 0.06680266 acc 0.97265625 wl 0.0005334458 train True
e 75 step 17800 loss 0.123519056 acc 0.9609375 wl 0.000642713 train True
e 75 step 17850 loss 0.20059174 acc 0.9375 wl 0.00038744754 train True
e 76 step 17900 loss 0.11409706 acc 0.9609375 wl 0.00084900204 train True
e 76 step 17950 loss 0.08147213 acc 0.9609375 wl 0.00031518936 train True
e 76 step 18000 loss 0.06282335 acc 0.984375 wl 0.00066761696 train True
e 76 step 18050 loss 0.08125431 acc 0.9765625 wl 0.0005188421 train True
e 77 step 18100 loss 0.11881387 acc 0.9609375 wl 0.0005765733 train True
e 77 step 18150 loss 0.078961976 acc 0.9609375 wl 0.0007025245 train True
e 77 step 18200 loss 0.06411711 acc 0.97265625 wl 0.0005610191 train True
e 77 step 18250 loss 0.06911189 acc 0.98046875 wl 0.00045249966 train True
e 77 step 18300 loss 0.10020049 acc 0.97265625 wl 0.0006480027 train True
e 78 step 18350 loss 0.19997302 acc 0.953125 wl 0.00063371635 train True
e 78 step 18400 loss 0.06105992 acc 0.97265625 wl 0.00052424567 train True
e 78 step 18450 loss 0.07824515 acc 0.9609375 wl 0.00040339955 train True
e 78 step 18500 loss 0.07932326 acc 0.9765625 wl 0.0005108115 train True
e 78 step 18550 loss 0.10380829 acc 0.96875 wl 0.00044426677 train True
e 79 step 18600 loss 0.042970642 acc 0.9921875 wl 0.00047475315 train True
e 79 step 18650 loss 0.05866535 acc 0.9765625 wl 0.00036227016 train True
e 79 step 18700 loss 0.1507014 acc 0.9453125 wl 0.0007742647 train True
e 79 step 18750 loss 0.21520412 acc 0.9296875 wl 0.0007260808 train True
e 80 step 18800 loss 0.087627664 acc 0.97265625 wl 0.00048922084 train True
e 80 step 18850 loss 0.16419314 acc 0.94140625 wl 0.00040894773 train True
e 80 step 18900 loss 0.09293734 acc 0.9765625 wl 0.00054561277 train True
e 80 step 18950 loss 0.04432623 acc 0.98828125 wl 0.00050991884 train True
e 80 step 19000 loss 0.096576035 acc 0.97265625 wl 0.00077789207 train True
epoch 80 testing...
e -1 step 0 loss 0.0806799 acc 0.9765625 wl 0.00044475988 train False
test_true_total 9595.0 test_elements_total 10000
test loss mean 0.13828969 test acc 0.9595 pt 4912
e 81 step 19050 loss 0.052485246 acc 0.97265625 wl 0.00070913765 train True
e 81 step 19100 loss 0.08621228 acc 0.9765625 wl 0.00070060394 train True
e 81 step 19150 loss 0.07769668 acc 0.97265625 wl 0.00057214906 train True
e 81 step 19200 loss 0.071824126 acc 0.9765625 wl 0.00047308384 train True
e 81 step 19250 loss 0.099649474 acc 0.9609375 wl 0.00044938194 train True
e 82 step 19300 loss 0.08384812 acc 0.9765625 wl 0.0005665927 train True
e 82 step 19350 loss 0.09115848 acc 0.9765625 wl 0.00054097874 train True
e 82 step 19400 loss 0.0998244 acc 0.97265625 wl 0.0004965884 train True
e 82 step 19450 loss 0.092587255 acc 0.96484375 wl 0.00038376206 train True
e 82 step 19500 loss 0.0076739974 acc 1.0 wl 0.00048512546 train True
e 83 step 19550 loss 0.15049522 acc 0.953125 wl 0.0002964947 train True
e 83 step 19600 loss 0.13022521 acc 0.96484375 wl 0.00079286564 train True
e 83 step 19650 loss 0.08917033 acc 0.96875 wl 0.00041335373 train True
e 83 step 19700 loss 0.04391714 acc 0.984375 wl 0.0005881188 train True
e 84 step 19750 loss 0.12494558 acc 0.96875 wl 0.00067799713 train True
e 84 step 19800 loss 0.07429946 acc 0.97265625 wl 0.00079384854 train True
e 84 step 19850 loss 0.09486757 acc 0.97265625 wl 0.0005433352 train True
e 84 step 19900 loss 0.072661236 acc 0.97265625 wl 0.0005101175 train True
e 84 step 19950 loss 0.081313185 acc 0.96875 wl 0.00066466175 train True
e 85 step 20000 loss 0.08896371 acc 0.98046875 wl 0.00065005897 train True
e 85 step 20050 loss 0.14501025 acc 0.96484375 wl 0.00063493266 train True
e 85 step 20100 loss 0.060528666 acc 0.9765625 wl 0.0005440129 train True
e 85 step 20150 loss 0.08662454 acc 0.9765625 wl 0.00042403792 train True
e 85 step 20200 loss 0.19042832 acc 0.9453125 wl 0.000491819 train True
e 86 step 20250 loss 0.09503065 acc 0.95703125 wl 0.0006436414 train True
e 86 step 20300 loss 0.06725566 acc 0.97265625 wl 0.00046670757 train True
e 86 step 20350 loss 0.053424083 acc 0.984375 wl 0.00057468 train True
e 86 step 20400 loss 0.08073992 acc 0.984375 wl 0.00049415044 train True
e 87 step 20450 loss 0.11606457 acc 0.96875 wl 0.0005872437 train True
e 87 step 20500 loss 0.08629928 acc 0.97265625 wl 0.0005704231 train True
e 87 step 20550 loss 0.060779054 acc 0.98046875 wl 0.0006413204 train True
e 87 step 20600 loss 0.062977664 acc 0.98046875 wl 0.00046275964 train True
e 87 step 20650 loss 0.11033788 acc 0.97265625 wl 0.00040147168 train True
e 88 step 20700 loss 0.17376088 acc 0.9609375 wl 0.0008832756 train True
e 88 step 20750 loss 0.04741466 acc 0.98046875 wl 0.0006357945 train True
e 88 step 20800 loss 0.0699669 acc 0.96875 wl 0.00044435778 train True
e 88 step 20850 loss 0.05426304 acc 0.98828125 wl 0.0006186944 train True
e 88 step 20900 loss 0.06740542 acc 0.98046875 wl 0.0005228467 train True
e 89 step 20950 loss 0.033729337 acc 0.9921875 wl 0.00046797417 train True
e 89 step 21000 loss 0.0559211 acc 0.98046875 wl 0.00096456014 train True
e 89 step 21050 loss 0.13032179 acc 0.9609375 wl 0.00057461887 train True
e 89 step 21100 loss 0.1712899 acc 0.94921875 wl 0.00047397203 train True
e 90 step 21150 loss 0.08636552 acc 0.96484375 wl 0.00042193528 train True
e 90 step 21200 loss 0.14734514 acc 0.953125 wl 0.0012620472 train True
e 90 step 21250 loss 0.08546093 acc 0.9765625 wl 0.0005787497 train True
e 90 step 21300 loss 0.039470997 acc 0.984375 wl 0.00044674164 train True
e 90 step 21350 loss 0.083875775 acc 0.97265625 wl 0.0004841218 train True
epoch 90 testing...
e -1 step 0 loss 0.082213804 acc 0.9609375 wl 0.00043463003 train False
test_true_total 9598.0 test_elements_total 10000
test loss mean 0.14257868 test acc 0.9598 pt 4912
e 91 step 21400 loss 0.069423564 acc 0.97265625 wl 0.00046860188 train True
e 91 step 21450 loss 0.10647491 acc 0.96875 wl 0.00065276533 train True
e 91 step 21500 loss 0.07022845 acc 0.96875 wl 0.0004281859 train True
e 91 step 21550 loss 0.07184321 acc 0.98046875 wl 0.0006619686 train True
e 91 step 21600 loss 0.08531995 acc 0.96875 wl 0.00039291295 train True
e 92 step 21650 loss 0.07372391 acc 0.9765625 wl 0.00051824766 train True
e 92 step 21700 loss 0.09934098 acc 0.9765625 wl 0.00075351435 train True
e 92 step 21750 loss 0.09084743 acc 0.9765625 wl 0.00031089605 train True
e 92 step 21800 loss 0.08371326 acc 0.9609375 wl 0.00043851772 train True
e 92 step 21850 loss 0.0056861434 acc 1.0 wl 0.00063279865 train True
e 93 step 21900 loss 0.13022974 acc 0.9609375 wl 0.0004281036 train True
e 93 step 21950 loss 0.09568447 acc 0.9609375 wl 0.0011217913 train True
e 93 step 22000 loss 0.053964775 acc 0.98828125 wl 0.0005529827 train True
e 93 step 22050 loss 0.027219638 acc 0.9921875 wl 0.00039386872 train True
e 94 step 22100 loss 0.10213802 acc 0.9765625 wl 0.00084782613 train True
e 94 step 22150 loss 0.07581018 acc 0.97265625 wl 0.000808112 train True
e 94 step 22200 loss 0.09185873 acc 0.96875 wl 0.0003320057 train True
e 94 step 22250 loss 0.07716894 acc 0.9765625 wl 0.00033125805 train True
e 94 step 22300 loss 0.08021018 acc 0.97265625 wl 0.0009980565 train True
e 95 step 22350 loss 0.06504634 acc 0.9765625 wl 0.00053918915 train True
e 95 step 22400 loss 0.11597212 acc 0.9609375 wl 0.00063335645 train True
e 95 step 22450 loss 0.052524164 acc 0.98046875 wl 0.00070780935 train True
e 95 step 22500 loss 0.09457504 acc 0.96484375 wl 0.0004592656 train True
e 95 step 22550 loss 0.1790458 acc 0.9375 wl 0.000533567 train True
e 96 step 22600 loss 0.1310407 acc 0.95703125 wl 0.00044468802 train True
e 96 step 22650 loss 0.058926325 acc 0.98828125 wl 0.00055012264 train True
e 96 step 22700 loss 0.048481394 acc 0.98046875 wl 0.00037730922 train True
e 96 step 22750 loss 0.0623182 acc 0.98828125 wl 0.00044972 train True
e 97 step 22800 loss 0.09783136 acc 0.97265625 wl 0.00045305648 train True
e 97 step 22850 loss 0.074819714 acc 0.96875 wl 0.0010099264 train True
e 97 step 22900 loss 0.05217635 acc 0.984375 wl 0.0005554094 train True
e 97 step 22950 loss 0.054965593 acc 0.984375 wl 0.0006586509 train True
e 97 step 23000 loss 0.08814426 acc 0.9765625 wl 0.0006002464 train True
e 98 step 23050 loss 0.14034675 acc 0.96484375 wl 0.00061355875 train True
e 98 step 23100 loss 0.035377726 acc 0.9921875 wl 0.0005803992 train True
e 98 step 23150 loss 0.061048567 acc 0.9765625 wl 0.00074784015 train True
e 98 step 23200 loss 0.03934624 acc 0.98828125 wl 0.00048761797 train True
e 98 step 23250 loss 0.10231939 acc 0.96875 wl 0.00079654175 train True
e 99 step 23300 loss 0.03453227 acc 0.98828125 wl 0.00062012026 train True
e 99 step 23350 loss 0.054194026 acc 0.98046875 wl 0.00074801885 train True
e 99 step 23400 loss 0.118075706 acc 0.96484375 wl 0.0004690436 train True
e 99 step 23450 loss 0.16231899 acc 0.94921875 wl 0.00036523983 train True
training done... testing ...
e -1 step 0 loss 0.07473683 acc 0.96875 wl 0.00041818598 train False
test_true_total 9637.0 test_elements_total 10000
test loss mean 0.12759838 test acc 0.9637 pt 4912
{'problem': 'MNIST', 'cell': 'WaveletGRU', 'hidden': 58, 'compression_mode': 'state_reset', 'batch_size': 256, 'lr': 0.001, 'clip': 1, 'epochs': 100, 'wave_dropout': 0.0}


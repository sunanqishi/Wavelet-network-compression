Namespace(batch_size=50, cell='WaveletGRU', compression_mode='gates', hidden=512, lr=0.001, n_test=10000, n_train=600000, problem='memory', time_steps=150)
Baseline is 0.12232009068704916
gates compression
Creating a Wavelet GRU, do not forget to add the wavelet-loss.
torch.Size([512])
torch.Size([545])
torch.Size([512])
torch.Size([6])
torch.Size([6])
torch.Size([6])
torch.Size([6])
torch.Size([512, 10])
torch.Size([512])
torch.Size([512])
torch.Size([545])
torch.Size([512])
torch.Size([6])
torch.Size([6])
torch.Size([6])
torch.Size([6])
torch.Size([512, 10])
torch.Size([512])
torch.Size([512, 512])
torch.Size([512, 10])
torch.Size([512])
torch.Size([10, 512])
torch.Size([10])
parameter total 287356
step 0 loss 2.430117 baseline: 0.12232009068704916 acc 0.118 wl 1.089228e-12 train True
step 50 loss 0.32614744 baseline: 0.12232009068704916 acc 0.0 wl 9.128235e-06 train True
step 100 loss 0.30967787 baseline: 0.12232009068704916 acc 0.0 wl 9.370123e-06 train True
step 150 loss 0.18312025 baseline: 0.12232009068704916 acc 0.0 wl 3.2544267e-05 train True
step 200 loss 0.29512265 baseline: 0.12232009068704916 acc 0.0 wl 4.3143453e-05 train True
step 250 loss 0.13340402 baseline: 0.12232009068704916 acc 0.096 wl 2.84829e-05 train True
step 300 loss 0.1255607 baseline: 0.12232009068704916 acc 0.118 wl 6.586346e-05 train True
step 350 loss 0.12396612 baseline: 0.12232009068704916 acc 0.142 wl 6.047275e-05 train True
step 400 loss 0.12364598 baseline: 0.12232009068704916 acc 0.114 wl 6.430778e-05 train True
step 450 loss 0.12328473 baseline: 0.12232009068704916 acc 0.14 wl 6.740469e-05 train True
step 500 loss 0.12295001 baseline: 0.12232009068704916 acc 0.128 wl 6.5814114e-05 train True
step 550 loss 0.12327302 baseline: 0.12232009068704916 acc 0.112 wl 6.410621e-05 train True
step 600 loss 0.12297836 baseline: 0.12232009068704916 acc 0.128 wl 6.14499e-05 train True
step 650 loss 0.12333736 baseline: 0.12232009068704916 acc 0.14 wl 6.3511005e-05 train True
step 700 loss 0.12288415 baseline: 0.12232009068704916 acc 0.104 wl 6.26703e-05 train True
step 750 loss 0.12282554 baseline: 0.12232009068704916 acc 0.134 wl 6.6837485e-05 train True
step 800 loss 0.124339186 baseline: 0.12232009068704916 acc 0.138 wl 5.7233054e-05 train True
step 850 loss 0.12376002 baseline: 0.12232009068704916 acc 0.13 wl 0.00014677108 train True
step 900 loss 0.123539135 baseline: 0.12232009068704916 acc 0.128 wl 5.4853466e-05 train True
step 950 loss 0.1228568 baseline: 0.12232009068704916 acc 0.122 wl 5.760442e-05 train True
step 1000 loss 0.12292332 baseline: 0.12232009068704916 acc 0.12 wl 6.927976e-05 train True
step 1050 loss 0.1228966 baseline: 0.12232009068704916 acc 0.112 wl 9.325576e-05 train True
step 1100 loss 0.12270363 baseline: 0.12232009068704916 acc 0.134 wl 0.000104619176 train True
step 1150 loss 0.12286377 baseline: 0.12232009068704916 acc 0.144 wl 0.0001216042 train True
step 1200 loss 0.12208433 baseline: 0.12232009068704916 acc 0.154 wl 0.000119226635 train True
step 1250 loss 0.12229676 baseline: 0.12232009068704916 acc 0.134 wl 0.00011370421 train True
step 1300 loss 0.12257409 baseline: 0.12232009068704916 acc 0.13 wl 0.000112319394 train True
step 1350 loss 0.17956081 baseline: 0.12232009068704916 acc 0.036 wl 1.3576089e-05 train True
step 1400 loss 0.12441129 baseline: 0.12232009068704916 acc 0.132 wl 6.794984e-06 train True
step 1450 loss 0.12340138 baseline: 0.12232009068704916 acc 0.128 wl 6.0744032e-06 train True
step 1500 loss 0.122997455 baseline: 0.12232009068704916 acc 0.132 wl 5.838598e-06 train True
step 1550 loss 0.12289218 baseline: 0.12232009068704916 acc 0.128 wl 1.18657135e-05 train True
step 1600 loss 0.12301899 baseline: 0.12232009068704916 acc 0.122 wl 2.6984831e-05 train True
step 1650 loss 0.12275471 baseline: 0.12232009068704916 acc 0.128 wl 5.0934894e-05 train True
step 1700 loss 0.1226734 baseline: 0.12232009068704916 acc 0.13 wl 8.6241685e-05 train True
step 1750 loss 0.122733295 baseline: 0.12232009068704916 acc 0.134 wl 8.7216e-05 train True
step 1800 loss 0.12289736 baseline: 0.12232009068704916 acc 0.126 wl 8.595421e-05 train True
step 1850 loss 0.12295887 baseline: 0.12232009068704916 acc 0.134 wl 8.992618e-05 train True
step 1900 loss 0.12255812 baseline: 0.12232009068704916 acc 0.14 wl 9.5408235e-05 train True
step 1950 loss 0.122890525 baseline: 0.12232009068704916 acc 0.136 wl 0.00010536563 train True
step 2000 loss 0.12240437 baseline: 0.12232009068704916 acc 0.128 wl 9.581828e-05 train True
step 2050 loss 0.12318026 baseline: 0.12232009068704916 acc 0.096 wl 9.0151814e-05 train True
step 2100 loss 0.12287872 baseline: 0.12232009068704916 acc 0.122 wl 5.254684e-06 train True
step 2150 loss 0.122743495 baseline: 0.12232009068704916 acc 0.102 wl 5.6048313e-05 train True
step 2200 loss 0.1230319 baseline: 0.12232009068704916 acc 0.114 wl 9.838425e-05 train True
step 2250 loss 0.122690976 baseline: 0.12232009068704916 acc 0.126 wl 0.0001469192 train True
step 2300 loss 0.12253811 baseline: 0.12232009068704916 acc 0.132 wl 0.00024095242 train True
step 2350 loss 0.122424975 baseline: 0.12232009068704916 acc 0.134 wl 0.00024098519 train True
step 2400 loss 0.12281591 baseline: 0.12232009068704916 acc 0.12 wl 0.00018009546 train True
step 2450 loss 0.12248534 baseline: 0.12232009068704916 acc 0.126 wl 0.00013461604 train True
step 2500 loss 0.122490734 baseline: 0.12232009068704916 acc 0.12 wl 0.00010578702 train True
step 2550 loss 0.2806755 baseline: 0.12232009068704916 acc 0.016 wl 0.00025219738 train True
step 2600 loss 0.23431538 baseline: 0.12232009068704916 acc 0.0 wl 0.0003415834 train True
step 2650 loss 0.3191808 baseline: 0.12232009068704916 acc 0.0 wl 0.00015874667 train True
step 2700 loss 0.29458538 baseline: 0.12232009068704916 acc 0.0 wl 0.00023061171 train True
step 2750 loss 0.12516797 baseline: 0.12232009068704916 acc 0.134 wl 0.0002023938 train True
step 2800 loss 0.1841028 baseline: 0.12232009068704916 acc 0.01 wl 0.00050518726 train True
step 2850 loss 0.12977232 baseline: 0.12232009068704916 acc 0.094 wl 0.00041881352 train True
step 2900 loss 0.14699343 baseline: 0.12232009068704916 acc 0.092 wl 0.0008132086 train True
step 2950 loss 0.12322467 baseline: 0.12232009068704916 acc 0.12 wl 0.00043250446 train True
step 3000 loss 0.12317996 baseline: 0.12232009068704916 acc 0.108 wl 0.00030185978 train True
step 3050 loss 0.12329626 baseline: 0.12232009068704916 acc 0.108 wl 0.00020766439 train True
step 3100 loss 0.123677246 baseline: 0.12232009068704916 acc 0.136 wl 0.00019290074 train True
step 3150 loss 0.122465216 baseline: 0.12232009068704916 acc 0.116 wl 0.0001428558 train True
step 3200 loss 0.12239421 baseline: 0.12232009068704916 acc 0.118 wl 0.00011028844 train True
step 3250 loss 0.12274602 baseline: 0.12232009068704916 acc 0.124 wl 0.000102184975 train True
step 3300 loss 0.12300476 baseline: 0.12232009068704916 acc 0.148 wl 0.00010169172 train True
step 3350 loss 0.12292847 baseline: 0.12232009068704916 acc 0.132 wl 0.00011078056 train True
step 3400 loss 0.12163466 baseline: 0.12232009068704916 acc 0.16 wl 0.00012473974 train True
step 3450 loss 0.12348315 baseline: 0.12232009068704916 acc 0.112 wl 0.0001226645 train True
step 3500 loss 0.12290438 baseline: 0.12232009068704916 acc 0.122 wl 0.00011537844 train True
step 3550 loss 0.12268526 baseline: 0.12232009068704916 acc 0.106 wl 9.4710005e-05 train True
step 3600 loss 0.12267591 baseline: 0.12232009068704916 acc 0.122 wl 0.00012677163 train True
step 3650 loss 0.12259744 baseline: 0.12232009068704916 acc 0.116 wl 0.000112771486 train True
step 3700 loss 0.12247153 baseline: 0.12232009068704916 acc 0.142 wl 9.806841e-05 train True
step 3750 loss 0.122763515 baseline: 0.12232009068704916 acc 0.124 wl 6.744499e-05 train True
step 3800 loss 0.12251298 baseline: 0.12232009068704916 acc 0.138 wl 7.6529745e-05 train True
step 3850 loss 0.122751236 baseline: 0.12232009068704916 acc 0.12 wl 8.3227045e-05 train True
step 3900 loss 0.12239788 baseline: 0.12232009068704916 acc 0.16 wl 7.6137745e-05 train True
step 3950 loss 0.122840285 baseline: 0.12232009068704916 acc 0.116 wl 7.3190524e-05 train True
step 4000 loss 0.122508675 baseline: 0.12232009068704916 acc 0.13 wl 8.1887854e-05 train True
step 4050 loss 0.122552745 baseline: 0.12232009068704916 acc 0.11 wl 0.00010788574 train True
step 4100 loss 0.12259366 baseline: 0.12232009068704916 acc 0.134 wl 0.00011221261 train True
step 4150 loss 0.1228701 baseline: 0.12232009068704916 acc 0.13 wl 9.616108e-05 train True
step 4200 loss 0.12231306 baseline: 0.12232009068704916 acc 0.128 wl 0.000114504306 train True
step 4250 loss 0.12235606 baseline: 0.12232009068704916 acc 0.142 wl 0.0001494468 train True
step 4300 loss 0.12495519 baseline: 0.12232009068704916 acc 0.13 wl 0.0037513378 train True
step 4350 loss 0.122682504 baseline: 0.12232009068704916 acc 0.114 wl 4.316617e-05 train True
step 4400 loss 0.12281514 baseline: 0.12232009068704916 acc 0.11 wl 5.689518e-05 train True
step 4450 loss 0.12289542 baseline: 0.12232009068704916 acc 0.116 wl 7.878335e-05 train True
step 4500 loss 0.122913875 baseline: 0.12232009068704916 acc 0.114 wl 0.00011371318 train True
step 4550 loss 0.12356857 baseline: 0.12232009068704916 acc 0.122 wl 8.3074745e-05 train True
step 4600 loss 0.12248139 baseline: 0.12232009068704916 acc 0.14 wl 9.544885e-05 train True
step 4650 loss 0.122926876 baseline: 0.12232009068704916 acc 0.138 wl 9.4626725e-05 train True
step 4700 loss 0.12265125 baseline: 0.12232009068704916 acc 0.106 wl 7.653631e-05 train True
step 4750 loss 0.12236334 baseline: 0.12232009068704916 acc 0.112 wl 6.57199e-05 train True
step 4800 loss 0.12237134 baseline: 0.12232009068704916 acc 0.154 wl 3.703659e-05 train True
step 4850 loss 0.12268153 baseline: 0.12232009068704916 acc 0.118 wl 0.00011901805 train True
step 4900 loss 0.122442454 baseline: 0.12232009068704916 acc 0.128 wl 9.459136e-05 train True
step 4950 loss 0.12241402 baseline: 0.12232009068704916 acc 0.11 wl 7.575163e-05 train True
step 5000 loss 0.12263804 baseline: 0.12232009068704916 acc 0.134 wl 7.264533e-05 train True
step 5050 loss 0.12248528 baseline: 0.12232009068704916 acc 0.12 wl 7.128974e-05 train True
step 5100 loss 0.12250214 baseline: 0.12232009068704916 acc 0.124 wl 9.7958255e-05 train True
step 5150 loss 0.12245552 baseline: 0.12232009068704916 acc 0.138 wl 1.3757104e-05 train True
step 5200 loss 0.12230704 baseline: 0.12232009068704916 acc 0.132 wl 1.1722454e-05 train True
step 5250 loss 0.12226676 baseline: 0.12232009068704916 acc 0.148 wl 1.0640799e-05 train True
step 5300 loss 0.12255759 baseline: 0.12232009068704916 acc 0.116 wl 3.923809e-05 train True
step 5350 loss 0.122408114 baseline: 0.12232009068704916 acc 0.132 wl 5.292481e-05 train True
step 5400 loss 0.122581415 baseline: 0.12232009068704916 acc 0.128 wl 5.687678e-05 train True
step 5450 loss 0.122410096 baseline: 0.12232009068704916 acc 0.132 wl 5.8597732e-05 train True
step 5500 loss 0.12253701 baseline: 0.12232009068704916 acc 0.12 wl 5.396475e-05 train True
step 5550 loss 0.12264434 baseline: 0.12232009068704916 acc 0.118 wl 5.614536e-05 train True
step 5600 loss 0.12277713 baseline: 0.12232009068704916 acc 0.134 wl 6.26152e-05 train True
step 5650 loss 0.19997959 baseline: 0.12232009068704916 acc 0.064 wl 0.001754336 train True
step 5700 loss 0.12249649 baseline: 0.12232009068704916 acc 0.126 wl 4.5872293e-06 train True
step 5750 loss 0.12266382 baseline: 0.12232009068704916 acc 0.13 wl 3.3392062e-06 train True
step 5800 loss 0.12246458 baseline: 0.12232009068704916 acc 0.142 wl 7.1978993e-06 train True
step 5850 loss 0.12239571 baseline: 0.12232009068704916 acc 0.112 wl 2.2903761e-05 train True
step 5900 loss 0.122482836 baseline: 0.12232009068704916 acc 0.12 wl 4.8633767e-05 train True
step 5950 loss 0.12278239 baseline: 0.12232009068704916 acc 0.126 wl 7.371604e-05 train True
step 6000 loss 0.12301292 baseline: 0.12232009068704916 acc 0.086 wl 7.72043e-05 train True
step 6050 loss 0.12248119 baseline: 0.12232009068704916 acc 0.096 wl 9.042808e-05 train True
step 6100 loss 0.12262115 baseline: 0.12232009068704916 acc 0.134 wl 0.000102410246 train True
step 6150 loss 0.12293211 baseline: 0.12232009068704916 acc 0.112 wl 8.918576e-05 train True
step 6200 loss 0.12269554 baseline: 0.12232009068704916 acc 0.126 wl 9.279461e-05 train True
step 6250 loss 0.12267281 baseline: 0.12232009068704916 acc 0.122 wl 9.2489725e-05 train True
step 6300 loss 0.122898795 baseline: 0.12232009068704916 acc 0.13 wl 9.7121054e-05 train True
step 6350 loss 0.1226355 baseline: 0.12232009068704916 acc 0.118 wl 0.0001071178 train True
step 6400 loss 0.122415684 baseline: 0.12232009068704916 acc 0.14 wl 9.4458694e-05 train True
step 6450 loss 0.12259513 baseline: 0.12232009068704916 acc 0.102 wl 0.00011856085 train True
step 6500 loss 0.12250956 baseline: 0.12232009068704916 acc 0.1 wl 8.027153e-05 train True
step 6550 loss 0.12266292 baseline: 0.12232009068704916 acc 0.118 wl 8.873362e-05 train True
step 6600 loss 0.12247424 baseline: 0.12232009068704916 acc 0.124 wl 8.3665116e-05 train True
step 6650 loss 0.1223914 baseline: 0.12232009068704916 acc 0.14 wl 9.696036e-05 train True
step 6700 loss 0.12277273 baseline: 0.12232009068704916 acc 0.142 wl 0.00011625073 train True
step 6750 loss 0.12273924 baseline: 0.12232009068704916 acc 0.104 wl 0.0001331651 train True
step 6800 loss 0.12246361 baseline: 0.12232009068704916 acc 0.132 wl 0.00011494352 train True
step 6850 loss 0.1224281 baseline: 0.12232009068704916 acc 0.122 wl 0.00010035059 train True
step 6900 loss 0.12270457 baseline: 0.12232009068704916 acc 0.12 wl 8.9113266e-05 train True
step 6950 loss 0.12245531 baseline: 0.12232009068704916 acc 0.126 wl 0.00013250433 train True
step 7000 loss 0.122799374 baseline: 0.12232009068704916 acc 0.094 wl 9.900106e-05 train True
step 7050 loss 0.12260511 baseline: 0.12232009068704916 acc 0.096 wl 3.0633135e-05 train True
step 7100 loss 0.1225979 baseline: 0.12232009068704916 acc 0.124 wl 1.6189311e-05 train True
step 7150 loss 0.122567065 baseline: 0.12232009068704916 acc 0.138 wl 1.2223469e-05 train True
step 7200 loss 0.12283568 baseline: 0.12232009068704916 acc 0.102 wl 9.659675e-05 train True
step 7250 loss 0.12217024 baseline: 0.12232009068704916 acc 0.14 wl 8.8260334e-05 train True
step 7300 loss 0.12238448 baseline: 0.12232009068704916 acc 0.144 wl 7.704772e-05 train True
step 7350 loss 0.12254819 baseline: 0.12232009068704916 acc 0.112 wl 7.352316e-05 train True
step 7400 loss 0.12238054 baseline: 0.12232009068704916 acc 0.108 wl 6.860955e-05 train True
step 7450 loss 0.12233723 baseline: 0.12232009068704916 acc 0.126 wl 6.422265e-05 train True
step 7500 loss 0.1224047 baseline: 0.12232009068704916 acc 0.12 wl 5.60733e-05 train True
step 7550 loss 0.12230385 baseline: 0.12232009068704916 acc 0.146 wl 5.3191652e-05 train True
step 7600 loss 0.12240921 baseline: 0.12232009068704916 acc 0.128 wl 6.829589e-05 train True
step 7650 loss 0.122477464 baseline: 0.12232009068704916 acc 0.14 wl 7.7352044e-05 train True
step 7700 loss 0.12255818 baseline: 0.12232009068704916 acc 0.124 wl 8.748897e-05 train True
step 7750 loss 0.122399546 baseline: 0.12232009068704916 acc 0.126 wl 7.884085e-05 train True
step 7800 loss 0.122480586 baseline: 0.12232009068704916 acc 0.106 wl 9.2220595e-05 train True
step 7850 loss 0.12243674 baseline: 0.12232009068704916 acc 0.13 wl 8.6963635e-05 train True
step 7900 loss 0.122468494 baseline: 0.12232009068704916 acc 0.114 wl 6.565558e-05 train True
step 7950 loss 0.12264702 baseline: 0.12232009068704916 acc 0.12 wl 6.726426e-05 train True
step 8000 loss 0.12246891 baseline: 0.12232009068704916 acc 0.114 wl 9.6569216e-05 train True
step 8050 loss 0.12263843 baseline: 0.12232009068704916 acc 0.116 wl 9.390168e-05 train True
step 8100 loss 0.12235 baseline: 0.12232009068704916 acc 0.11 wl 0.00011434116 train True
step 8150 loss 0.12234277 baseline: 0.12232009068704916 acc 0.12 wl 0.0001458829 train True
step 8200 loss 0.12231876 baseline: 0.12232009068704916 acc 0.12 wl 0.00011645953 train True
step 8250 loss 0.12228942 baseline: 0.12232009068704916 acc 0.152 wl 0.00014444595 train True
step 8300 loss 0.122638784 baseline: 0.12232009068704916 acc 0.12 wl 7.827225e-05 train True
step 8350 loss 0.122429445 baseline: 0.12232009068704916 acc 0.116 wl 8.983798e-05 train True
step 8400 loss 0.12237608 baseline: 0.12232009068704916 acc 0.104 wl 9.652751e-05 train True
step 8450 loss 0.12283514 baseline: 0.12232009068704916 acc 0.112 wl 0.00011050534 train True
step 8500 loss 0.122470275 baseline: 0.12232009068704916 acc 0.114 wl 6.5587556e-05 train True
step 8550 loss 0.12254903 baseline: 0.12232009068704916 acc 0.128 wl 6.3058615e-05 train True
step 8600 loss 0.12274196 baseline: 0.12232009068704916 acc 0.11 wl 8.601397e-05 train True
step 8650 loss 0.12257913 baseline: 0.12232009068704916 acc 0.13 wl 0.00010399994 train True
step 8700 loss 0.12229573 baseline: 0.12232009068704916 acc 0.138 wl 9.621538e-05 train True
step 8750 loss 0.12227115 baseline: 0.12232009068704916 acc 0.126 wl 9.452498e-05 train True
step 8800 loss 0.12244234 baseline: 0.12232009068704916 acc 0.126 wl 9.014121e-05 train True
step 8850 loss 0.1222942 baseline: 0.12232009068704916 acc 0.146 wl 7.003872e-05 train True
step 8900 loss 0.12251789 baseline: 0.12232009068704916 acc 0.122 wl 9.8307544e-05 train True
step 8950 loss 0.12232488 baseline: 0.12232009068704916 acc 0.134 wl 0.00011641608 train True
step 9000 loss 0.12233212 baseline: 0.12232009068704916 acc 0.11 wl 0.00010630075 train True
step 9050 loss 0.122636214 baseline: 0.12232009068704916 acc 0.118 wl 9.527331e-05 train True
step 9100 loss 0.122534536 baseline: 0.12232009068704916 acc 0.11 wl 1.3291441e-05 train True
step 9150 loss 0.122465774 baseline: 0.12232009068704916 acc 0.136 wl 6.383224e-06 train True
step 9200 loss 0.12247659 baseline: 0.12232009068704916 acc 0.118 wl 4.888067e-06 train True
step 9250 loss 0.12222197 baseline: 0.12232009068704916 acc 0.144 wl 2.8001843e-05 train True
step 9300 loss 0.12248101 baseline: 0.12232009068704916 acc 0.12 wl 4.358785e-05 train True
step 9350 loss 0.1224124 baseline: 0.12232009068704916 acc 0.148 wl 5.297696e-05 train True
step 9400 loss 0.12251074 baseline: 0.12232009068704916 acc 0.118 wl 6.279907e-05 train True
step 9450 loss 0.12238096 baseline: 0.12232009068704916 acc 0.134 wl 7.317852e-05 train True
step 9500 loss 0.12239972 baseline: 0.12232009068704916 acc 0.122 wl 8.841665e-05 train True
step 9550 loss 0.12271348 baseline: 0.12232009068704916 acc 0.11 wl 9.807982e-05 train True
step 9600 loss 0.122622 baseline: 0.12232009068704916 acc 0.148 wl 0.00010357807 train True
step 9650 loss 0.12235027 baseline: 0.12232009068704916 acc 0.128 wl 7.4972195e-05 train True
step 9700 loss 0.12242706 baseline: 0.12232009068704916 acc 0.136 wl 5.2727257e-05 train True
step 9750 loss 0.12247139 baseline: 0.12232009068704916 acc 0.124 wl 7.708707e-05 train True
step 9800 loss 0.12232577 baseline: 0.12232009068704916 acc 0.14 wl 6.959003e-05 train True
step 9850 loss 0.122388095 baseline: 0.12232009068704916 acc 0.146 wl 8.787798e-05 train True
step 9900 loss 0.12242005 baseline: 0.12232009068704916 acc 0.118 wl 8.4510866e-05 train True
step 9950 loss 0.1225407 baseline: 0.12232009068704916 acc 0.114 wl 6.340258e-05 train True
step 10000 loss 0.12240305 baseline: 0.12232009068704916 acc 0.142 wl 0.00014817229 train True
step 10050 loss 0.12243589 baseline: 0.12232009068704916 acc 0.12 wl 7.639233e-05 train True
step 10100 loss 0.122362465 baseline: 0.12232009068704916 acc 0.13 wl 9.6884876e-05 train True
step 10150 loss 0.12229782 baseline: 0.12232009068704916 acc 0.098 wl 0.000103299404 train True
step 10200 loss 0.12255474 baseline: 0.12232009068704916 acc 0.092 wl 0.00010070319 train True
step 10250 loss 0.12246282 baseline: 0.12232009068704916 acc 0.128 wl 8.6875516e-05 train True
step 10300 loss 0.12235942 baseline: 0.12232009068704916 acc 0.112 wl 7.123679e-05 train True
step 10350 loss 0.12245552 baseline: 0.12232009068704916 acc 0.106 wl 7.377007e-05 train True
step 10400 loss 0.12234203 baseline: 0.12232009068704916 acc 0.124 wl 6.164436e-05 train True
step 10450 loss 0.12236544 baseline: 0.12232009068704916 acc 0.164 wl 6.492524e-05 train True
step 10500 loss 0.12228484 baseline: 0.12232009068704916 acc 0.122 wl 5.79159e-05 train True
step 10550 loss 0.122549504 baseline: 0.12232009068704916 acc 0.09 wl 7.1968236e-05 train True
step 10600 loss 0.12243036 baseline: 0.12232009068704916 acc 0.108 wl 8.273221e-05 train True
step 10650 loss 0.12230848 baseline: 0.12232009068704916 acc 0.122 wl 7.9630314e-05 train True
step 10700 loss 0.12245637 baseline: 0.12232009068704916 acc 0.11 wl 8.1475475e-05 train True
step 10750 loss 0.12239064 baseline: 0.12232009068704916 acc 0.12 wl 8.0819475e-05 train True
step 10800 loss 0.12228939 baseline: 0.12232009068704916 acc 0.114 wl 7.70696e-05 train True
step 10850 loss 0.12244485 baseline: 0.12232009068704916 acc 0.136 wl 8.393428e-05 train True
step 10900 loss 0.12246496 baseline: 0.12232009068704916 acc 0.124 wl 9.776571e-05 train True
step 10950 loss 0.122297734 baseline: 0.12232009068704916 acc 0.136 wl 0.00012747172 train True
step 11000 loss 0.122272275 baseline: 0.12232009068704916 acc 0.138 wl 0.00016088903 train True
step 11050 loss 0.1223315 baseline: 0.12232009068704916 acc 0.128 wl 0.00011851848 train True
step 11100 loss 0.12225828 baseline: 0.12232009068704916 acc 0.112 wl 8.720961e-05 train True
step 11150 loss 0.12233238 baseline: 0.12232009068704916 acc 0.118 wl 0.00011316078 train True
step 11200 loss 0.12235047 baseline: 0.12232009068704916 acc 0.126 wl 0.000101500045 train True
step 11250 loss 0.12229399 baseline: 0.12232009068704916 acc 0.124 wl 8.56916e-05 train True
step 11300 loss 0.12227002 baseline: 0.12232009068704916 acc 0.138 wl 7.990462e-05 train True
step 11350 loss 0.12238337 baseline: 0.12232009068704916 acc 0.14 wl 0.00010496288 train True
step 11400 loss 0.12228349 baseline: 0.12232009068704916 acc 0.122 wl 9.547779e-05 train True
step 11450 loss 0.12206782 baseline: 0.12232009068704916 acc 0.152 wl 9.502983e-05 train True
step 11500 loss 0.122403264 baseline: 0.12232009068704916 acc 0.13 wl 9.173971e-05 train True
step 11550 loss 0.12242141 baseline: 0.12232009068704916 acc 0.134 wl 9.827311e-05 train True
step 11600 loss 0.122241154 baseline: 0.12232009068704916 acc 0.118 wl 7.230639e-05 train True
step 11650 loss 0.122238725 baseline: 0.12232009068704916 acc 0.12 wl 8.735926e-05 train True
step 11700 loss 0.12240661 baseline: 0.12232009068704916 acc 0.128 wl 9.126954e-05 train True
step 11750 loss 0.12232758 baseline: 0.12232009068704916 acc 0.13 wl 7.809342e-05 train True
step 11800 loss 0.12250738 baseline: 0.12232009068704916 acc 0.102 wl 7.639763e-05 train True
step 11850 loss 0.12255911 baseline: 0.12232009068704916 acc 0.106 wl 8.865894e-05 train True
step 11900 loss 0.12254887 baseline: 0.12232009068704916 acc 0.124 wl 8.1313054e-05 train True
step 11950 loss 0.12240075 baseline: 0.12232009068704916 acc 0.132 wl 8.6513144e-05 train True
training done... testing ...
step 0 loss 0.12241621 baseline: 0.12232009068704916 acc 0.14 wl 0.00010542919 train False
step 50 loss 0.12224806 baseline: 0.12232009068704916 acc 0.136 wl 0.00010542919 train False
step 100 loss 0.122269586 baseline: 0.12232009068704916 acc 0.14 wl 0.00010542919 train False
step 150 loss 0.12241423 baseline: 0.12232009068704916 acc 0.13 wl 0.00010542919 train False
test_el_total 100000.0 test_acc_sum 12873.0
test loss mean 0.122340165 test acc mean 0.12873 pt 287356
time: 2019-12-23 19:58:36.469406 experiment took 44909.27670741081 [s]

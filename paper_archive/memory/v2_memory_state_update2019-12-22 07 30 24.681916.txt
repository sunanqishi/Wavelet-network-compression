Namespace(batch_size=50, cell='WaveletGRU', compression_mode='state_update', hidden=512, lr=0.001, n_test=10000, n_train=600000, problem='memory', time_steps=150)
Baseline is 0.12232009068704916
state+update gate compression
Creating a Wavelet GRU, do not forget to add the wavelet-loss.
torch.Size([512])
torch.Size([545])
torch.Size([512])
torch.Size([6])
torch.Size([6])
torch.Size([6])
torch.Size([6])
torch.Size([512, 10])
torch.Size([512])
torch.Size([512, 512])
torch.Size([512, 10])
torch.Size([512])
torch.Size([512])
torch.Size([545])
torch.Size([512])
torch.Size([6])
torch.Size([6])
torch.Size([6])
torch.Size([6])
torch.Size([512, 10])
torch.Size([512])
torch.Size([10, 512])
torch.Size([10])
parameter total 287356
step 0 loss 2.4486253 baseline: 0.12232009068704916 acc 0.098 wl 1.089228e-12 train True
step 50 loss 0.34144405 baseline: 0.12232009068704916 acc 0.0 wl 7.8548765e-05 train True
step 100 loss 0.32132307 baseline: 0.12232009068704916 acc 0.0 wl 0.00014975629 train True
step 150 loss 0.28402022 baseline: 0.12232009068704916 acc 0.0 wl 0.0001460376 train True
step 200 loss 0.25158828 baseline: 0.12232009068704916 acc 0.0 wl 0.00014482757 train True
step 250 loss 0.1646757 baseline: 0.12232009068704916 acc 0.0 wl 0.001319653 train True
step 300 loss 0.13909845 baseline: 0.12232009068704916 acc 0.098 wl 0.00042969047 train True
step 350 loss 0.13662526 baseline: 0.12232009068704916 acc 0.076 wl 0.000109888264 train True
step 400 loss 0.13426314 baseline: 0.12232009068704916 acc 0.144 wl 0.000149668 train True
step 450 loss 0.12606741 baseline: 0.12232009068704916 acc 0.116 wl 0.00011233914 train True
step 500 loss 0.34295774 baseline: 0.12232009068704916 acc 0.0 wl 0.0018990776 train True
step 550 loss 0.12707958 baseline: 0.12232009068704916 acc 0.112 wl 0.00010651283 train True
step 600 loss 0.12630174 baseline: 0.12232009068704916 acc 0.138 wl 6.984944e-05 train True
step 650 loss 0.12676759 baseline: 0.12232009068704916 acc 0.144 wl 5.3700336e-05 train True
step 700 loss 0.12441551 baseline: 0.12232009068704916 acc 0.126 wl 5.914929e-05 train True
step 750 loss 0.12525763 baseline: 0.12232009068704916 acc 0.126 wl 6.730561e-05 train True
step 800 loss 0.12366224 baseline: 0.12232009068704916 acc 0.134 wl 0.00010367636 train True
step 850 loss 0.12436578 baseline: 0.12232009068704916 acc 0.106 wl 0.000117792355 train True
step 900 loss 0.124686524 baseline: 0.12232009068704916 acc 0.154 wl 8.003349e-05 train True
step 950 loss 0.12443624 baseline: 0.12232009068704916 acc 0.124 wl 3.851034e-05 train True
step 1000 loss 0.12331254 baseline: 0.12232009068704916 acc 0.116 wl 6.514831e-05 train True
step 1050 loss 0.12346417 baseline: 0.12232009068704916 acc 0.128 wl 9.8493714e-05 train True
step 1100 loss 0.12308365 baseline: 0.12232009068704916 acc 0.14 wl 0.000109311695 train True
step 1150 loss 0.12541908 baseline: 0.12232009068704916 acc 0.108 wl 0.00013230865 train True
step 1200 loss 0.12330162 baseline: 0.12232009068704916 acc 0.136 wl 0.00012045397 train True
step 1250 loss 0.122971766 baseline: 0.12232009068704916 acc 0.13 wl 0.00010845049 train True
step 1300 loss 0.12308871 baseline: 0.12232009068704916 acc 0.138 wl 0.00022500842 train True
step 1350 loss 0.12274517 baseline: 0.12232009068704916 acc 0.142 wl 4.682245e-05 train True
step 1400 loss 0.122835696 baseline: 0.12232009068704916 acc 0.128 wl 5.3437572e-05 train True
step 1450 loss 0.12279868 baseline: 0.12232009068704916 acc 0.116 wl 8.761399e-05 train True
step 1500 loss 0.12342156 baseline: 0.12232009068704916 acc 0.142 wl 0.00011583287 train True
step 1550 loss 0.12283266 baseline: 0.12232009068704916 acc 0.146 wl 8.10248e-05 train True
step 1600 loss 0.1226963 baseline: 0.12232009068704916 acc 0.134 wl 9.616815e-05 train True
step 1650 loss 0.122542165 baseline: 0.12232009068704916 acc 0.134 wl 0.00010663966 train True
step 1700 loss 0.123024195 baseline: 0.12232009068704916 acc 0.112 wl 7.728294e-05 train True
step 1750 loss 0.12278024 baseline: 0.12232009068704916 acc 0.126 wl 7.34427e-05 train True
step 1800 loss 0.12289656 baseline: 0.12232009068704916 acc 0.118 wl 0.00010171288 train True
step 1850 loss 0.122489706 baseline: 0.12232009068704916 acc 0.116 wl 8.651955e-05 train True
step 1900 loss 0.12241165 baseline: 0.12232009068704916 acc 0.134 wl 7.4842246e-05 train True
step 1950 loss 0.12200841 baseline: 0.12232009068704916 acc 0.156 wl 8.669171e-05 train True
step 2000 loss 0.12276577 baseline: 0.12232009068704916 acc 0.136 wl 0.011326145 train True
step 2050 loss 0.122744344 baseline: 0.12232009068704916 acc 0.096 wl 0.0019402885 train True
step 2100 loss 0.1224584 baseline: 0.12232009068704916 acc 0.114 wl 0.00037144055 train True
step 2150 loss 0.12278 baseline: 0.12232009068704916 acc 0.142 wl 7.105143e-05 train True
step 2200 loss 0.122238986 baseline: 0.12232009068704916 acc 0.132 wl 2.1017266e-05 train True
step 2250 loss 0.1225214 baseline: 0.12232009068704916 acc 0.112 wl 1.6687209e-05 train True
step 2300 loss 0.12285514 baseline: 0.12232009068704916 acc 0.112 wl 9.038726e-05 train True
step 2350 loss 0.122319885 baseline: 0.12232009068704916 acc 0.136 wl 7.334776e-05 train True
step 2400 loss 0.122532554 baseline: 0.12232009068704916 acc 0.132 wl 2.0041127e-05 train True
step 2450 loss 0.122905836 baseline: 0.12232009068704916 acc 0.102 wl 2.7363258e-05 train True
step 2500 loss 0.12260982 baseline: 0.12232009068704916 acc 0.112 wl 5.030393e-05 train True
step 2550 loss 0.122501045 baseline: 0.12232009068704916 acc 0.126 wl 7.342426e-05 train True
step 2600 loss 0.12281075 baseline: 0.12232009068704916 acc 0.138 wl 2.54822e-05 train True
step 2650 loss 0.123015724 baseline: 0.12232009068704916 acc 0.116 wl 3.3237608e-05 train True
step 2700 loss 0.12228948 baseline: 0.12232009068704916 acc 0.138 wl 4.340322e-05 train True
step 2750 loss 0.122516215 baseline: 0.12232009068704916 acc 0.134 wl 6.0326493e-05 train True
step 2800 loss 0.1228859 baseline: 0.12232009068704916 acc 0.116 wl 7.508851e-05 train True
step 2850 loss 0.123028494 baseline: 0.12232009068704916 acc 0.134 wl 8.5757754e-05 train True
step 2900 loss 0.12301808 baseline: 0.12232009068704916 acc 0.13 wl 7.7915945e-05 train True
step 2950 loss 0.12239503 baseline: 0.12232009068704916 acc 0.126 wl 9.1148555e-05 train True
step 3000 loss 0.12309761 baseline: 0.12232009068704916 acc 0.13 wl 9.030003e-05 train True
step 3050 loss 0.12240263 baseline: 0.12232009068704916 acc 0.134 wl 0.000120214754 train True
step 3100 loss 0.12285852 baseline: 0.12232009068704916 acc 0.112 wl 0.00010693532 train True
step 3150 loss 0.12258267 baseline: 0.12232009068704916 acc 0.102 wl 4.200705e-05 train True
step 3200 loss 0.1228025 baseline: 0.12232009068704916 acc 0.144 wl 0.00011599497 train True
step 3250 loss 0.12243265 baseline: 0.12232009068704916 acc 0.126 wl 9.768056e-05 train True
step 3300 loss 0.12245545 baseline: 0.12232009068704916 acc 0.12 wl 8.299766e-05 train True
step 3350 loss 0.12241896 baseline: 0.12232009068704916 acc 0.13 wl 0.0001081907 train True
step 3400 loss 0.12223089 baseline: 0.12232009068704916 acc 0.156 wl 9.2560214e-05 train True
step 3450 loss 0.12275553 baseline: 0.12232009068704916 acc 0.114 wl 8.112319e-05 train True
step 3500 loss 0.122715406 baseline: 0.12232009068704916 acc 0.132 wl 7.129941e-05 train True
step 3550 loss 0.12268224 baseline: 0.12232009068704916 acc 0.104 wl 7.046723e-05 train True
step 3600 loss 0.12271171 baseline: 0.12232009068704916 acc 0.116 wl 6.341763e-05 train True
step 3650 loss 0.12327881 baseline: 0.12232009068704916 acc 0.124 wl 7.689775e-05 train True
step 3700 loss 0.12283466 baseline: 0.12232009068704916 acc 0.126 wl 0.00012048562 train True
step 3750 loss 0.122183755 baseline: 0.12232009068704916 acc 0.134 wl 8.286869e-05 train True
step 3800 loss 0.12297271 baseline: 0.12232009068704916 acc 0.1 wl 0.00010814779 train True
step 3850 loss 0.12260126 baseline: 0.12232009068704916 acc 0.116 wl 0.00010897954 train True
step 3900 loss 0.12247787 baseline: 0.12232009068704916 acc 0.112 wl 9.428038e-05 train True
step 3950 loss 0.12276943 baseline: 0.12232009068704916 acc 0.122 wl 8.477882e-05 train True
step 4000 loss 0.122551456 baseline: 0.12232009068704916 acc 0.126 wl 7.659299e-05 train True
step 4050 loss 0.122372255 baseline: 0.12232009068704916 acc 0.134 wl 7.258959e-05 train True
step 4100 loss 0.122923456 baseline: 0.12232009068704916 acc 0.084 wl 0.0001646374 train True
step 4150 loss 0.12251887 baseline: 0.12232009068704916 acc 0.132 wl 0.00010149098 train True
step 4200 loss 0.122431785 baseline: 0.12232009068704916 acc 0.14 wl 9.8966455e-05 train True
step 4250 loss 0.12241735 baseline: 0.12232009068704916 acc 0.136 wl 0.000110629626 train True
step 4300 loss 0.12298607 baseline: 0.12232009068704916 acc 0.098 wl 0.00012966042 train True
step 4350 loss 0.12278942 baseline: 0.12232009068704916 acc 0.116 wl 0.00015114769 train True
step 4400 loss 0.122408934 baseline: 0.12232009068704916 acc 0.136 wl 7.553642e-05 train True
step 4450 loss 0.12255875 baseline: 0.12232009068704916 acc 0.116 wl 9.399532e-05 train True
step 4500 loss 0.12294013 baseline: 0.12232009068704916 acc 0.112 wl 9.585396e-05 train True
step 4550 loss 0.122645535 baseline: 0.12232009068704916 acc 0.118 wl 8.254216e-05 train True
step 4600 loss 0.12263395 baseline: 0.12232009068704916 acc 0.104 wl 0.000112990965 train True
step 4650 loss 0.122339085 baseline: 0.12232009068704916 acc 0.118 wl 8.6471846e-05 train True
step 4700 loss 0.12218667 baseline: 0.12232009068704916 acc 0.144 wl 0.000103292994 train True
step 4750 loss 0.12226404 baseline: 0.12232009068704916 acc 0.128 wl 8.283781e-05 train True
step 4800 loss 0.122688904 baseline: 0.12232009068704916 acc 0.122 wl 8.1943625e-05 train True
step 4850 loss 0.12258549 baseline: 0.12232009068704916 acc 0.1 wl 6.477786e-05 train True
step 4900 loss 0.12241099 baseline: 0.12232009068704916 acc 0.116 wl 9.39286e-05 train True
step 4950 loss 0.12255947 baseline: 0.12232009068704916 acc 0.128 wl 0.00011562761 train True
step 5000 loss 0.12242604 baseline: 0.12232009068704916 acc 0.146 wl 0.00012275408 train True
step 5050 loss 0.122347295 baseline: 0.12232009068704916 acc 0.12 wl 0.00012179959 train True
step 5100 loss 0.122590415 baseline: 0.12232009068704916 acc 0.126 wl 0.00010087593 train True
step 5150 loss 0.12253336 baseline: 0.12232009068704916 acc 0.118 wl 9.282744e-05 train True
step 5200 loss 0.12251024 baseline: 0.12232009068704916 acc 0.126 wl 8.836572e-05 train True
step 5250 loss 0.122338235 baseline: 0.12232009068704916 acc 0.122 wl 8.9524605e-05 train True
step 5300 loss 0.12249223 baseline: 0.12232009068704916 acc 0.124 wl 0.0001316246 train True
step 5350 loss 0.12226695 baseline: 0.12232009068704916 acc 0.132 wl 0.00010850745 train True
step 5400 loss 0.12230439 baseline: 0.12232009068704916 acc 0.106 wl 0.00014770447 train True
step 5450 loss 0.12224362 baseline: 0.12232009068704916 acc 0.13 wl 0.00013463342 train True
step 5500 loss 0.1225214 baseline: 0.12232009068704916 acc 0.118 wl 0.00011354584 train True
step 5550 loss 0.12246486 baseline: 0.12232009068704916 acc 0.116 wl 7.693266e-05 train True
step 5600 loss 0.12253404 baseline: 0.12232009068704916 acc 0.16 wl 0.00013505665 train True
step 5650 loss 0.12239607 baseline: 0.12232009068704916 acc 0.126 wl 9.9254605e-05 train True
step 5700 loss 0.12230941 baseline: 0.12232009068704916 acc 0.118 wl 0.00022628534 train True
step 5750 loss 0.12252598 baseline: 0.12232009068704916 acc 0.148 wl 0.00011928566 train True
step 5800 loss 0.12243841 baseline: 0.12232009068704916 acc 0.136 wl 0.00016575283 train True
step 5850 loss 0.12253408 baseline: 0.12232009068704916 acc 0.128 wl 7.494677e-05 train True
step 5900 loss 0.1225652 baseline: 0.12232009068704916 acc 0.118 wl 8.9888825e-05 train True
step 5950 loss 0.1226849 baseline: 0.12232009068704916 acc 0.122 wl 9.738283e-05 train True
step 6000 loss 0.12285412 baseline: 0.12232009068704916 acc 0.132 wl 9.211712e-05 train True
step 6050 loss 0.12271111 baseline: 0.12232009068704916 acc 0.106 wl 0.00011220407 train True
step 6100 loss 0.12223063 baseline: 0.12232009068704916 acc 0.13 wl 0.0001531432 train True
step 6150 loss 0.12284259 baseline: 0.12232009068704916 acc 0.092 wl 0.00013920807 train True
step 6200 loss 0.12239235 baseline: 0.12232009068704916 acc 0.142 wl 0.00012677329 train True
step 6250 loss 0.12251604 baseline: 0.12232009068704916 acc 0.14 wl 9.7439755e-05 train True
step 6300 loss 0.12237524 baseline: 0.12232009068704916 acc 0.14 wl 0.000116748226 train True
step 6350 loss 0.12272538 baseline: 0.12232009068704916 acc 0.1 wl 9.9165525e-05 train True
step 6400 loss 0.12231114 baseline: 0.12232009068704916 acc 0.144 wl 8.9476045e-05 train True
step 6450 loss 0.12247695 baseline: 0.12232009068704916 acc 0.114 wl 9.544619e-05 train True
step 6500 loss 0.12219711 baseline: 0.12232009068704916 acc 0.156 wl 9.2064496e-05 train True
step 6550 loss 0.12248053 baseline: 0.12232009068704916 acc 0.112 wl 9.1079695e-05 train True
step 6600 loss 0.12236677 baseline: 0.12232009068704916 acc 0.118 wl 7.160549e-05 train True
step 6650 loss 0.122259825 baseline: 0.12232009068704916 acc 0.128 wl 8.0487705e-05 train True
step 6700 loss 0.12245236 baseline: 0.12232009068704916 acc 0.104 wl 0.000112167574 train True
step 6750 loss 0.12235843 baseline: 0.12232009068704916 acc 0.1 wl 0.00011545492 train True
step 6800 loss 0.12274364 baseline: 0.12232009068704916 acc 0.078 wl 0.00011495616 train True
step 6850 loss 0.122351766 baseline: 0.12232009068704916 acc 0.122 wl 7.760186e-05 train True
step 6900 loss 0.122473635 baseline: 0.12232009068704916 acc 0.106 wl 7.473835e-05 train True
step 6950 loss 0.12245295 baseline: 0.12232009068704916 acc 0.12 wl 7.1820185e-05 train True
step 7000 loss 0.12234945 baseline: 0.12232009068704916 acc 0.124 wl 7.7216006e-05 train True
step 7050 loss 0.12282562 baseline: 0.12232009068704916 acc 0.12 wl 8.3593026e-05 train True
step 7100 loss 0.1221467 baseline: 0.12232009068704916 acc 0.168 wl 8.9269226e-05 train True
step 7150 loss 0.122485064 baseline: 0.12232009068704916 acc 0.116 wl 8.210406e-05 train True
step 7200 loss 0.12225052 baseline: 0.12232009068704916 acc 0.152 wl 7.622857e-05 train True
step 7250 loss 0.12252384 baseline: 0.12232009068704916 acc 0.098 wl 0.00010043616 train True
step 7300 loss 0.12243304 baseline: 0.12232009068704916 acc 0.126 wl 7.571377e-05 train True
step 7350 loss 0.12250592 baseline: 0.12232009068704916 acc 0.126 wl 0.00011780162 train True
step 7400 loss 0.12237639 baseline: 0.12232009068704916 acc 0.124 wl 9.346659e-05 train True
step 7450 loss 0.12229524 baseline: 0.12232009068704916 acc 0.134 wl 0.00010012767 train True
step 7500 loss 0.12249641 baseline: 0.12232009068704916 acc 0.134 wl 9.487131e-05 train True
step 7550 loss 0.122360125 baseline: 0.12232009068704916 acc 0.124 wl 0.00010049404 train True
step 7600 loss 0.122150995 baseline: 0.12232009068704916 acc 0.142 wl 0.00010058441 train True
step 7650 loss 0.12239896 baseline: 0.12232009068704916 acc 0.138 wl 9.002701e-05 train True
step 7700 loss 0.12217667 baseline: 0.12232009068704916 acc 0.126 wl 8.802768e-05 train True
step 7750 loss 0.122454405 baseline: 0.12232009068704916 acc 0.124 wl 8.101892e-05 train True
step 7800 loss 0.12222818 baseline: 0.12232009068704916 acc 0.136 wl 8.643007e-05 train True
step 7850 loss 0.12249841 baseline: 0.12232009068704916 acc 0.114 wl 9.264979e-05 train True
step 7900 loss 0.122305594 baseline: 0.12232009068704916 acc 0.118 wl 8.849404e-05 train True
step 7950 loss 0.12250836 baseline: 0.12232009068704916 acc 0.14 wl 6.386119e-05 train True
step 8000 loss 0.12237734 baseline: 0.12232009068704916 acc 0.144 wl 6.508915e-05 train True
step 8050 loss 0.122692496 baseline: 0.12232009068704916 acc 0.11 wl 6.0245005e-05 train True
step 8100 loss 0.12241887 baseline: 0.12232009068704916 acc 0.12 wl 6.8063164e-05 train True
step 8150 loss 0.12231216 baseline: 0.12232009068704916 acc 0.138 wl 7.285756e-05 train True
step 8200 loss 0.122404166 baseline: 0.12232009068704916 acc 0.122 wl 7.892444e-05 train True
step 8250 loss 0.12255733 baseline: 0.12232009068704916 acc 0.134 wl 8.890295e-05 train True
step 8300 loss 0.12230124 baseline: 0.12232009068704916 acc 0.138 wl 9.766724e-05 train True
step 8350 loss 0.12237321 baseline: 0.12232009068704916 acc 0.124 wl 0.00014082517 train True
step 8400 loss 0.122334905 baseline: 0.12232009068704916 acc 0.144 wl 0.00010895499 train True
step 8450 loss 0.12216399 baseline: 0.12232009068704916 acc 0.136 wl 6.2720566e-05 train True
step 8500 loss 0.1225345 baseline: 0.12232009068704916 acc 0.116 wl 8.273688e-05 train True
step 8550 loss 0.12240437 baseline: 0.12232009068704916 acc 0.108 wl 9.1249036e-05 train True
step 8600 loss 0.12229573 baseline: 0.12232009068704916 acc 0.118 wl 8.875134e-05 train True
step 8650 loss 0.122549966 baseline: 0.12232009068704916 acc 0.126 wl 0.00013709167 train True
step 8700 loss 0.12231592 baseline: 0.12232009068704916 acc 0.128 wl 9.431783e-05 train True
step 8750 loss 0.12221418 baseline: 0.12232009068704916 acc 0.144 wl 6.4616775e-05 train True
step 8800 loss 0.12295726 baseline: 0.12232009068704916 acc 0.106 wl 0.001981281 train True
step 8850 loss 0.12308964 baseline: 0.12232009068704916 acc 0.13 wl 0.00028609036 train True
step 8900 loss 0.12254666 baseline: 0.12232009068704916 acc 0.11 wl 8.339656e-05 train True
step 8950 loss 0.12223846 baseline: 0.12232009068704916 acc 0.122 wl 4.0668114e-05 train True
step 9000 loss 0.12226229 baseline: 0.12232009068704916 acc 0.148 wl 0.0001396717 train True
step 9050 loss 0.12245518 baseline: 0.12232009068704916 acc 0.142 wl 7.07082e-05 train True
step 9100 loss 0.12226074 baseline: 0.12232009068704916 acc 0.142 wl 6.1687606e-05 train True
step 9150 loss 0.12238708 baseline: 0.12232009068704916 acc 0.108 wl 7.049657e-05 train True
step 9200 loss 0.1222825 baseline: 0.12232009068704916 acc 0.126 wl 7.77849e-05 train True
step 9250 loss 0.12233528 baseline: 0.12232009068704916 acc 0.124 wl 7.22124e-05 train True
step 9300 loss 0.122571304 baseline: 0.12232009068704916 acc 0.108 wl 5.8962312e-05 train True
step 9350 loss 0.122185275 baseline: 0.12232009068704916 acc 0.126 wl 0.000112172376 train True
step 9400 loss 0.122177005 baseline: 0.12232009068704916 acc 0.18 wl 6.2266874e-05 train True
step 9450 loss 0.12241184 baseline: 0.12232009068704916 acc 0.148 wl 5.1337083e-05 train True
step 9500 loss 0.12224182 baseline: 0.12232009068704916 acc 0.132 wl 5.8619233e-05 train True
step 9550 loss 0.122459285 baseline: 0.12232009068704916 acc 0.122 wl 7.405095e-05 train True
step 9600 loss 0.12249782 baseline: 0.12232009068704916 acc 0.096 wl 9.762606e-05 train True
step 9650 loss 0.12260091 baseline: 0.12232009068704916 acc 0.09 wl 0.00010417752 train True
step 9700 loss 0.12254389 baseline: 0.12232009068704916 acc 0.126 wl 0.00010222434 train True
step 9750 loss 0.12216201 baseline: 0.12232009068704916 acc 0.146 wl 9.4659394e-05 train True
step 9800 loss 0.12251947 baseline: 0.12232009068704916 acc 0.09 wl 6.9513146e-05 train True
step 9850 loss 0.122457966 baseline: 0.12232009068704916 acc 0.114 wl 9.5938434e-05 train True
step 9900 loss 0.12224097 baseline: 0.12232009068704916 acc 0.13 wl 8.936142e-05 train True
step 9950 loss 0.12243454 baseline: 0.12232009068704916 acc 0.124 wl 0.0001541353 train True
step 10000 loss 0.12248254 baseline: 0.12232009068704916 acc 0.12 wl 9.0673566e-05 train True
step 10050 loss 0.12228536 baseline: 0.12232009068704916 acc 0.144 wl 0.00011041178 train True
step 10100 loss 0.1224564 baseline: 0.12232009068704916 acc 0.126 wl 0.00013984699 train True
step 10150 loss 0.12246252 baseline: 0.12232009068704916 acc 0.128 wl 0.0001145539 train True
step 10200 loss 0.12232724 baseline: 0.12232009068704916 acc 0.136 wl 0.0001036845 train True
step 10250 loss 0.12228958 baseline: 0.12232009068704916 acc 0.124 wl 0.00010176045 train True
step 10300 loss 0.12232975 baseline: 0.12232009068704916 acc 0.14 wl 0.00010387639 train True
step 10350 loss 0.12243579 baseline: 0.12232009068704916 acc 0.138 wl 0.00014168174 train True
step 10400 loss 0.12245722 baseline: 0.12232009068704916 acc 0.098 wl 8.550369e-05 train True
step 10450 loss 0.12231582 baseline: 0.12232009068704916 acc 0.116 wl 8.267307e-05 train True
step 10500 loss 0.12245057 baseline: 0.12232009068704916 acc 0.12 wl 9.5348885e-05 train True
step 10550 loss 0.12239322 baseline: 0.12232009068704916 acc 0.118 wl 0.00010523292 train True
step 10600 loss 0.12202278 baseline: 0.12232009068704916 acc 0.156 wl 0.00012728857 train True
step 10650 loss 0.12253238 baseline: 0.12232009068704916 acc 0.126 wl 0.00014562233 train True
step 10700 loss 0.12251686 baseline: 0.12232009068704916 acc 0.134 wl 0.00012700664 train True
step 10750 loss 0.12251278 baseline: 0.12232009068704916 acc 0.09 wl 7.991778e-05 train True
step 10800 loss 0.12248802 baseline: 0.12232009068704916 acc 0.114 wl 9.5267715e-05 train True
step 10850 loss 0.122356735 baseline: 0.12232009068704916 acc 0.136 wl 0.00018595428 train True
step 10900 loss 0.12254285 baseline: 0.12232009068704916 acc 0.116 wl 0.00010075825 train True
step 10950 loss 0.122546576 baseline: 0.12232009068704916 acc 0.116 wl 0.00012321032 train True
step 11000 loss 0.12238176 baseline: 0.12232009068704916 acc 0.132 wl 6.503274e-05 train True
step 11050 loss 0.122460596 baseline: 0.12232009068704916 acc 0.112 wl 6.583735e-05 train True
step 11100 loss 0.122432046 baseline: 0.12232009068704916 acc 0.142 wl 7.167453e-05 train True
step 11150 loss 0.122259066 baseline: 0.12232009068704916 acc 0.094 wl 8.281525e-05 train True
step 11200 loss 0.1224052 baseline: 0.12232009068704916 acc 0.106 wl 9.1166505e-05 train True
step 11250 loss 0.12218927 baseline: 0.12232009068704916 acc 0.134 wl 8.33972e-05 train True
step 11300 loss 0.12234602 baseline: 0.12232009068704916 acc 0.146 wl 8.171047e-05 train True
step 11350 loss 0.12253546 baseline: 0.12232009068704916 acc 0.122 wl 8.858965e-05 train True
step 11400 loss 0.12222 baseline: 0.12232009068704916 acc 0.142 wl 9.044084e-05 train True
step 11450 loss 0.12240483 baseline: 0.12232009068704916 acc 0.12 wl 0.00013918238 train True
step 11500 loss 0.122340105 baseline: 0.12232009068704916 acc 0.12 wl 9.29043e-05 train True
step 11550 loss 0.12230908 baseline: 0.12232009068704916 acc 0.132 wl 9.750931e-05 train True
step 11600 loss 0.12234286 baseline: 0.12232009068704916 acc 0.13 wl 0.00014169817 train True
step 11650 loss 0.122361846 baseline: 0.12232009068704916 acc 0.132 wl 0.00010046617 train True
step 11700 loss 0.12264118 baseline: 0.12232009068704916 acc 0.106 wl 0.00011729998 train True
step 11750 loss 0.12226909 baseline: 0.12232009068704916 acc 0.13 wl 9.313185e-05 train True
step 11800 loss 0.12251758 baseline: 0.12232009068704916 acc 0.1 wl 7.291889e-05 train True
step 11850 loss 0.122476436 baseline: 0.12232009068704916 acc 0.11 wl 8.0679194e-05 train True
step 11900 loss 0.1223775 baseline: 0.12232009068704916 acc 0.134 wl 8.962896e-05 train True
step 11950 loss 0.122341886 baseline: 0.12232009068704916 acc 0.118 wl 0.00010179257 train True
training done... testing ...
step 0 loss 0.122360714 baseline: 0.12232009068704916 acc 0.11 wl 0.00011418375 train False
step 50 loss 0.12218407 baseline: 0.12232009068704916 acc 0.178 wl 0.00011418375 train False
step 100 loss 0.12242281 baseline: 0.12232009068704916 acc 0.12 wl 0.00011418375 train False
step 150 loss 0.12230176 baseline: 0.12232009068704916 acc 0.14 wl 0.00011418375 train False
test_el_total 100000.0 test_acc_sum 12676.0
test loss mean 0.122338876 test acc mean 0.12676 pt 287356
time: 2019-12-22 19:58:39.158973 experiment took 44893.27928900719 [s]
